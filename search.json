[{"categories":["Algorithm","Study14"],"content":"`\n  22-8시 -\u003e 0~10시로 바꿔서 생각\n  5시 이전이고 300분 이상 남으면 야간 적용. 그 외 모든 경우는 1시간씩 빼면서 시간이 없어질 때까지 계속 요금을 더함\n   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38  import java.io.*; import java.util.*; public class Main { static int T; public static void main(String[] args) throws IOException { BufferedReader br = new BufferedReader(new InputStreamReader(System.in)); T = Integer.parseInt(br.readLine()); StringBuilder sb = new StringBuilder(); StringTokenizer st; while(T--\u003e0) { int ans=0; st = new StringTokenizer(br.readLine()); String time = st.nextToken(); int spd = Integer.parseInt(st.nextToken()); st = new StringTokenizer(time,\":\"); int h = (Integer.parseInt(st.nextToken())+2)%24; int m = Integer.parseInt(st.nextToken()); while(spd\u003e0) { if(h\u003c=4\u0026\u0026spd\u003e300) { spd-=(600-(h*60+m)); h=10; m=0; ans+=5000; }else { h = (h+1)%24; spd-=60; ans+=1000; } } sb.append(ans).append(\"\\n\"); } System.out.println(sb); } }   ","description":"","tags":null,"title":"[백준] 9080 PC방요금?","uri":"/posts/algorithm/study14/%EB%B0%B1%EC%A4%80_9080_pc%EB%B0%A9/"},{"categories":["Algorithm","Study14"],"content":"`\ndfs로 풀고 처음에 찾으면서 G, R을 같게 만듬\n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50  import java.io.*; import java.util.*; public class Main { static int N; static char[][] arr; static boolean[][] visit; static int[][] delta = {{1,0},{0,1},{-1,0},{0,-1}}; public static void main(String[] args) throws IOException { BufferedReader br = new BufferedReader(new InputStreamReader(System.in)); StringTokenizer st; StringBuilder sb = new StringBuilder(); N = Integer.parseInt(br.readLine()); arr = new char[N][N]; visit = new boolean[N][N]; for (int i = 0; i \u003c N; i++) { arr[i] = br.readLine().toCharArray(); } int[] r = new int[2]; for (int k = 0; k \u003c 2; k++) { for(int i=0;i\u003cN;i++) { for(int j=0;j\u003cN;j++) { if(!visit[i][j]) { r[k]++; dfs(i,j,arr[i][j]); } if(arr[i][j]=='G') arr[i][j]='R'; } } visit=new boolean[N][N]; } sb.append(r[0] + \" \"+r[1]); System.out.println(sb); } private static void dfs(int x, int y, char c) { visit[x][y]= true; for (int d = 0; d \u003c 4; d++) { int nx = x + delta[d][0]; int ny = y + delta[d][1]; if (ny \u003c 0 || nx \u003c 0 || ny \u003e= N || nx \u003e= N || visit[nx][ny] || arr[nx][ny] != c) continue; dfs(nx,ny,c); } } }   ","description":"","tags":null,"title":"[백준] 10026 적록색약?","uri":"/posts/algorithm/study14/%EB%B0%B1%EC%A4%80_10026_%EC%A0%81%EB%A1%9D/"},{"categories":["Algorithm","Study14"],"content":"`\n들어갈 수 있는 값을 구하고 뒤에서부터 비교함\n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38  import java.io.BufferedReader; import java.io.IOException; import java.io.InputStreamReader; import java.util.StringTokenizer; public class Main { static int N,M,next = Integer.MAX_VALUE; static int arr[]; public static void main(String[] args) throws IOException { BufferedReader br = new BufferedReader(new InputStreamReader(System.in)); StringTokenizer st = new StringTokenizer(br.readLine()); N = Integer.parseInt(st.nextToken()); M = Integer.parseInt(st.nextToken()); arr = new int[N+1]; st = new StringTokenizer(br.readLine()); for (int i = 1; i \u003c= N; i++) { arr[i] = Integer.parseInt(st.nextToken()); arr[i] = Math.min(next, arr[i]); next = arr[i]; } int left=0,right = N; st = new StringTokenizer(br.readLine()); for (int i = 0; i \u003c M; i++) { int now = Integer.parseInt(st.nextToken()); while(right\u003e0 \u0026\u0026 arr[right]\u003cnow) { right--; } right--; if(right\u003c0) break; } System.out.println(right\u003c0?0:right+1); } }   ","description":"","tags":null,"title":"[백준] 1756 피자굽기?","uri":"/posts/algorithm/study14/%EB%B0%B1%EC%A4%80_1756_%ED%94%BC%EC%9E%90/"},{"categories":["Algorithm","Study14"],"content":"`\n들어갈 수 있는 값을 구하고 뒤에서부터 비교함\n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38  import java.io.BufferedReader; import java.io.IOException; import java.io.InputStreamReader; import java.util.StringTokenizer; public class Main { static int N,M,next = Integer.MAX_VALUE; static int arr[]; public static void main(String[] args) throws IOException { BufferedReader br = new BufferedReader(new InputStreamReader(System.in)); StringTokenizer st = new StringTokenizer(br.readLine()); N = Integer.parseInt(st.nextToken()); M = Integer.parseInt(st.nextToken()); arr = new int[N+1]; st = new StringTokenizer(br.readLine()); for (int i = 1; i \u003c= N; i++) { arr[i] = Integer.parseInt(st.nextToken()); arr[i] = Math.min(next, arr[i]); next = arr[i]; } int left=0,right = N; st = new StringTokenizer(br.readLine()); for (int i = 0; i \u003c M; i++) { int now = Integer.parseInt(st.nextToken()); while(right\u003e0 \u0026\u0026 arr[right]\u003cnow) { right--; } right--; if(right\u003c0) break; } System.out.println(right\u003c0?0:right+1); } }   ","description":"","tags":null,"title":"[백준] 1756 피자굽기?","uri":"/posts/algorithm/study14/%EB%B0%B1%EC%A4%80_3524_%EA%B3%B5%ED%86%B5%EC%A1%B0%EC%83%81/"},{"categories":["Algorithm","Study14"],"content":"`\n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46  import java.io.BufferedReader; import java.io.IOException; import java.io.InputStreamReader; import java.util.Arrays; import java.util.StringTokenizer; public class Main { static int T, N,M; static int arr[][], dp[][], delta[][] = {{1,0},{0,1},{0,-1},{-1,0}}; public static void main(String[] args) throws IOException { // TODO Auto-generated method stub \tBufferedReader br = new BufferedReader(new InputStreamReader(System.in)); StringTokenizer st = new StringTokenizer(br.readLine()); //n,m input \tN = Integer.parseInt(st.nextToken()); M = Integer.parseInt(st.nextToken()); arr = new int[N][M]; // 산 배열 \tdp = new int[N][M]; for (int i = 0; i \u003c N; i++) { // 라인 별로 받아 산 배열 받기 \tst = new StringTokenizer(br.readLine()); for (int j = 0; j \u003c M; j++) { arr[i][j] = Integer.parseInt(st.nextToken()); } } for (int i = 0; i \u003c N; i++) { Arrays.fill(dp[i], -1); } System.out.println(dfs(0,0)); } public static int dfs(int x, int y) { if (x == N - 1 \u0026\u0026 y == M - 1) return 1; //재귀 탈출조건  if (dp[x][y] != -1) return dp[x][y]; dp[x][y] = 0; //방문처리  for (int i = 0; i \u003c 4; i++) { int nx = x + delta[i][0]; int ny = y + delta[i][1]; if (nx \u003c 0 || nx \u003e= N || ny \u003c 0 || ny \u003e= M) continue; if(arr[x][y] \u003e arr[nx][ny]) { dp[x][y] += dfs(nx, ny); 가지수가 이전꺼에 더해짐 } } return dp[x][y]; } }   ","description":"","tags":null,"title":"[백준] 1520 내리막길","uri":"/posts/algorithm/study14/%EB%B0%B1%EC%A4%80_1520-%EB%82%B4%EB%A6%AC%EB%A7%89%EA%B8%B8/"},{"categories":["Algorithm","Study13"],"content":"`\n효율적인 풀이를 계속 생각했으나 input size가 작은 편이고 시간도 2초나 주어져서 통과할 수 있었음.\n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42  import java.io.BufferedReader; import java.io.IOException; import java.io.InputStreamReader; import java.util.Arrays; import java.util.StringTokenizer; public class B20366 { static int N; static int arr[]; public static void main(String[] args) throws IOException { BufferedReader br = new BufferedReader(new InputStreamReader(System.in)); N = Integer.parseInt(br.readLine()); StringTokenizer st = new StringTokenizer(br.readLine()); arr = new int[N]; for (int i = 0; i \u003c N; i++) { arr[i] = Integer.parseInt(st.nextToken()); } Arrays.sort(arr); int ans = Integer.MAX_VALUE; for (int i = 0; i \u003c N - 3; i++){ for (int j = i+3; j \u003c N; j++){ int elja = arr[i] + arr[j]; int left = i + 1; int right = j - 1; while (left \u003c right){ int anna = arr[left] + arr[right]; if (anna \u003c elja) left++; // 합 늘리기 \telse right--; // 합 줄이기 \tans = Math.min(ans, Math.abs(elja - anna)); } } } System.out.println(ans); } }   ","description":"","tags":null,"title":"[백준] 20366 같이 눈사람 만들래?","uri":"/posts/algorithm/study13/%EB%B0%B1%EC%A4%80_20366_%EB%88%88%EC%82%AC%EB%9E%8C/"},{"categories":["Algorithm","Study13"],"content":"`\n단순히 정렬해서 2칸씩 값을 비교함. 아래와 같이 놓으면 최적이 될 것이라 생각함\n… 4 2 1 3 5 …\n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33  import java.io.BufferedReader; import java.io.IOException; import java.io.InputStreamReader; import java.util.Arrays; import java.util.StringTokenizer; public class B11497 { static int T,N; static int arr[]; public static void main(String[] args) throws IOException { BufferedReader br = new BufferedReader(new InputStreamReader(System.in)); StringBuilder sb = new StringBuilder(); StringTokenizer st; T = Integer.parseInt(br.readLine()); while(T--\u003e0) { N = Integer.parseInt(br.readLine()); st = new StringTokenizer(br.readLine()); arr = new int[N]; for (int i = 0; i \u003c N; i++) { arr[i] = Integer.parseInt(st.nextToken()); } Arrays.sort(arr); int max = 0; for (int i = 0; i \u003c N-2; i++) { max = Math.max(max, arr[i+2] - arr[i]); } sb.append(max).append(\"\\n\"); } System.out.println(sb); } }   ","description":"","tags":null,"title":"[백준] 11497 통나무 건너뛰기","uri":"/posts/algorithm/study13/%EB%B0%B1%EC%A4%80_11497_%ED%86%B5%EB%82%98%EB%AC%B4/"},{"categories":["Algorithm","Study13"],"content":"`\n처음에 시간초과가 나서 위치 메모이제이션을 해주어서 통과. 그래도 1000ms 정도 나옴..\n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52  import java.io.BufferedReader; import java.io.IOException; import java.io.InputStreamReader; import java.util.StringTokenizer; public class Main { static String a,b,c; static int N,as,bs,cs; static boolean flag; static boolean visit[][][]; public static void main(String[] args) throws IOException { BufferedReader br = new BufferedReader(new InputStreamReader(System.in)); StringBuilder sb = new StringBuilder(); StringTokenizer st; N = Integer.parseInt(br.readLine()); for (int i = 1; i \u003c= N; i++) { sb.append(\"Data set \").append(i).append(\": \"); st = new StringTokenizer(br.readLine()); a = st.nextToken(); b = st.nextToken(); c = st.nextToken(); as = a.length();bs = b.length();cs=c.length(); visit = new boolean[as+1][bs+1][cs+1]; flag = false; solve(0,0,0); sb.append(flag?\"yes\":\"no\").append(\"\\n\"); } System.out.println(sb); } private static void solve(int i, int j,int cnt) { if (flag) return; if(cnt==cs) { flag = true; return; } // 해당 위치 이미 탐색한 경우 \tif(visit[i][j][cnt]) return; // a와 b 비교하여 문자열 탐색 \tif(i\u003cas \u0026\u0026 a.charAt(i)==c.charAt(cnt)) { visit[i][j][cnt] = true; solve(i+1,j,cnt+1); } if(j\u003cbs \u0026\u0026b.charAt(j)==c.charAt(cnt)) { visit[i][j][cnt] = true; solve(i,j+1,cnt+1); } } }   아래는 좀 더 효율적으로 짜보려고 수정한 코드이다. 우선 생각해보니 방문체크는 2차원으로 충분했다. 그리고 문자열 비교하기 전에 방문체크를 하고 함수를 boolean으로 하여 return했더니 시간이 줄었다. c에 a와 b에 해당하는 문자가 없을 경우 위의 코드에선 방문체크를 하지 않아서 그런 것 같다…\n이렇게 하니 160정도 나왔다.\n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45  import java.io.BufferedReader; import java.io.IOException; import java.io.InputStreamReader; import java.util.StringTokenizer; public class B9177 { static String a,b,c; static int N,as,bs,cs; static boolean visit[][]; public static void main(String[] args) throws IOException { BufferedReader br = new BufferedReader(new InputStreamReader(System.in)); StringBuilder sb = new StringBuilder(); StringTokenizer st; N = Integer.parseInt(br.readLine()); for (int i = 1; i \u003c= N; i++) { sb.append(\"Data set \").append(i).append(\": \"); st = new StringTokenizer(br.readLine()); a = st.nextToken(); b = st.nextToken(); c = st.nextToken(); as = a.length();bs = b.length();cs=c.length(); visit = new boolean[as+1][bs+1]; sb.append(solve(0,0,0)?\"yes\":\"no\").append(\"\\n\"); } System.out.println(sb); } private static boolean solve(int i, int j,int cnt) { if(cnt==cs) return true; if(visit[i][j]) return false; visit[i][j] = true; boolean flag = false; if(i\u003cas \u0026\u0026 a.charAt(i)==c.charAt(cnt)) flag|=solve(i+1,j,cnt+1); if(j\u003cbs \u0026\u0026b.charAt(j)==c.charAt(cnt)) flag|=solve(i,j+1,cnt+1); return flag;\t} }   ","description":"","tags":null,"title":"[백준] 9177 단어 프즐","uri":"/posts/algorithm/study13/%EB%B0%B1%EC%A4%80_9177_%EB%8B%A8%EC%96%B4%ED%94%84%EC%A6%90/"},{"categories":["Algorithm","Study12"],"content":"` bfs를 활용한 시뮬레이션.\nstack을 이용해 블록을 아래로 내리는 법을 생각하다 좋은 코드가 나온 것 같다.\n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94  import java.io.BufferedReader; import java.io.IOException; import java.io.InputStreamReader; import java.util.ArrayList; import java.util.LinkedList; import java.util.Queue; import java.util.Stack; public class B11559 { static char arr[][] = new char[12][6]; static int[][] delta = {{1,0},{0,1},{-1,0},{0,-1}}; public static void main(String[] args) throws IOException { BufferedReader br = new BufferedReader(new InputStreamReader(System.in)); for (int i = 0; i \u003c 12; i++) { String temp = br.readLine(); for (int j = 0; j \u003c 6; j++) { arr[i][j] = temp.charAt(j); } } int count = 0; boolean flag = true; while (flag) { flag = false; for (int i = 0; i \u003c 12; i++) { for (int j = 0; j \u003c 6; j++) { if (arr[i][j] != '.') { ArrayList\u003cint[]\u003e list = find(i, j); if (list.size() \u003e= 4) { for (int k = 0; k \u003c list.size(); k++) { int[] ind = list.get(k); arr[ind[0]][ind[1]] = '.'; } flag = true; } } } } // 블록이 없어진 경우 \tif (flag) { count++; down(); } }\tSystem.out.println(count); } private static ArrayList\u003cint[]\u003e find(int x, int y) { // bfs로 찾은 블록을 list에 넣기 \tArrayList\u003cint[]\u003e list = new ArrayList\u003c\u003e(); Queue\u003cint[]\u003e q = new LinkedList\u003c\u003e(); q.add(new int[] {x,y}); char temp = arr[x][y]; boolean[][] check = new boolean[12][6]; check[x][y] = true; while (!q.isEmpty()) { int[] node = q.poll(); list.add(node); for (int i = 0; i \u003c 4; i++) { int nx = node[0] + delta[i][0]; int ny = node[1] + delta[i][1]; if (notin(nx, ny)) continue; if (arr[nx][ny] == temp \u0026\u0026 !check[nx][ny]) { q.add(new int[] {nx, ny}); check[nx][ny] = true; } } } return list; } private static void down() { // stack을 이용해 줄마다 처리 \tStack\u003cCharacter\u003e stack = new Stack\u003c\u003e(); for (int j = 0; j \u003c 6; j++) { for (int i = 0; i \u003c 12; i++) { if (arr[i][j] != '.') stack.push(arr[i][j]); } // 아래쪽부터 채우기 \tfor (int i = 11; i \u003e= 0; i--) { if (stack.isEmpty()) arr[i][j] = '.'; else arr[i][j] = stack.pop(); } } } private static boolean notin(int x, int y) { return x \u003c 0 || x \u003e= 12 || y \u003c 0 || y \u003e= 6; } }   ","description":"","tags":null,"title":"[백준] 11559 Puyo Puyo","uri":"/posts/algorithm/study12/%EB%B0%B1%EC%A4%80_11559puyo/"},{"categories":["Algorithm","Study12"],"content":"`\n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44  import java.io.BufferedReader; import java.io.IOException; import java.io.InputStreamReader; import java.util.Arrays; import java.util.StringTokenizer; public class B1477 { static int T,N,M,K; static int[] arr; public static void main(String[] args) throws IOException { BufferedReader br = new BufferedReader(new InputStreamReader(System.in)); StringTokenizer st= new StringTokenizer(br.readLine()); N = Integer.parseInt(st.nextToken()); M = Integer.parseInt(st.nextToken()); K = Integer.parseInt(st.nextToken()); arr = new int[N+2]; st = new StringTokenizer(br.readLine()); for (int i = 1; i \u003c= N; i++) { arr[i] = Integer.parseInt(st.nextToken()); } arr[0] = 0; arr[N+1] = K; Arrays.sort(arr); int left = 0; int right = K; while(left \u003c= right) { int mid = (left+right)/2; int sum = 0; // 나온 길이(mid)를 통해 세울 수 있는 휴게소 개수를 기준으로 이분 탐색 \tfor (int i = 1; i \u003c N+2; i++) { sum+=(arr[i] - arr[i-1]-1) / mid; } if(sum \u003c= M) { right = mid-1; }else { left = mid+1; } } System.out.println(left); } }   ","description":"","tags":null,"title":"[백준] 1744 휴게소 세우기","uri":"/posts/algorithm/study12/%EB%B0%B1%EC%A4%80_1744%ED%9C%B4%EA%B2%8C%EC%86%8C/"},{"categories":["Algorithm","Study12"],"content":"` 폴짝폴짝 돌을 던지자\n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51  import java.io.BufferedReader; import java.io.IOException; import java.io.InputStreamReader; import java.util.Arrays; import java.util.StringTokenizer; public class B17498 { static int N, M, D; static long min = Long.MIN_VALUE, max = Long.MIN_VALUE; static long[][] arr, dp; public static void main(String[] args) throws IOException { BufferedReader br = new BufferedReader(new InputStreamReader(System.in)); StringTokenizer st = new StringTokenizer(br.readLine()); N = Integer.parseInt(st.nextToken()); M = Integer.parseInt(st.nextToken()); D = Integer.parseInt(st.nextToken()); arr = new long[N][M]; dp = new long[N][M]; for (int i = 0; i \u003c N; i++) { st = new StringTokenizer(br.readLine()); for (int j = 0; j \u003c M; j++) { arr[i][j] = Integer.parseInt(st.nextToken()); } } for (int i = 1; i \u003c N; i++) { Arrays.fill(dp[i], min); } for(int i=0;i\u003cN;i++) { for (int j = 0; j \u003c M; j++) { for (int x = i+1; x \u003c= i+D; x++) { for (int y = j-D; y \u003c= j+D; y++) { if(x\u003c0||y\u003c0||x\u003e=N||y\u003e=M) continue; if(Math.abs(x-i) + Math.abs(y-j) \u003c= D) { dp[x][y] = Math.max(dp[x][y],dp[i][j] + arr[x][y]*arr[i][j]); } } } } } for (int i = 0; i \u003c M; i++) { max = Math.max(max, dp[N-1][i]); } System.out.println(max); } }   ","description":"","tags":null,"title":"[백준] 17498 폴짝게임","uri":"/posts/algorithm/study12/%EB%B0%B1%EC%A4%80_17498%ED%8F%B4%EC%A7%9D/"},{"categories":["Algorithm","Study11"],"content":"`\n-1을 곱하여 1과 -1이 반복되고 결과를 바로 계산할 수 있게 함.\n비트 마스킹을 잘 활용하거나 백트래킹을 하면 더 빠른 결과가 나올 거 같은데 더 공부해볼 예정…\n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95  import java.io.BufferedReader; import java.io.IOException; import java.io.InputStreamReader; import java.util.ArrayList; import java.util.StringTokenizer; public class B17453 { static int N,M; static int door[], switches[][]; static ArrayList\u003cInteger\u003e[] list; static boolean check[]; public static void main(String[] args) throws IOException { BufferedReader br = new BufferedReader(new InputStreamReader(System.in)); StringBuilder sb = new StringBuilder(); StringTokenizer st = new StringTokenizer(br.readLine()); N = Integer.parseInt(st.nextToken()); M = Integer.parseInt(st.nextToken()); door = new int[N]; switches = new int[M][N]; list = new ArrayList[2*N+1]; check = new boolean[2*N+1]; // 스위치 저장 리스트 \tfor (int i = 0; i \u003c 2*N+1; i++) { list[i] = new ArrayList\u003c\u003e(); } // -1과 1로 저장 \tString str = br.readLine(); for (int i = 0; i \u003c N; i++) { if(str.charAt(i)=='1') door[i] = 1; else door[i]=-1; } for (int i = 0; i \u003c M; i++) { str = br.readLine(); for (int j = 0; j \u003c N; j++) { if(str.charAt(j)=='0') switches[i][j] = 1; else switches[i][j]=-1; } } // 모든 경우 탐색 \tfor (int i = 0; i \u003c (1 \u003c\u003c M); i++) { ArrayList\u003cInteger\u003e subset = new ArrayList\u003c\u003e(); for (int j = 0; j \u003c M; j++) { if ((i \u0026 1 \u003c\u003c j) \u003e 0) { subset.add(j); } } find(subset); } for (int i = 0; i \u003c 2*N+1; i++) { if(!check[i]) sb.append(-1).append(\"\\n\"); else { sb.append(list[i].size()+\" \"); for (int j = 0; j \u003c list[i].size(); j++) { sb.append(list[i].get(j) +\" \"); } sb.append(\"\\n\"); } } System.out.println(sb); } static void find(ArrayList\u003cInteger\u003e subset) { int[] temp = new int[N]; temp = door.clone(); // 스위치 전환  for (int i = 0; i \u003c subset.size(); i++) { for (int j = 0; j \u003c temp.length; j++) { temp[j] *= switches[subset.get(i)][j]; } } int result = 0; for (int i = 0; i \u003c temp.length; i++) { result += temp[i]; } // 해당 결과가 없다면  if (!check[result + N]) { for (int i = 0; i \u003c subset.size(); i++) { // 결과에 스위치 번호 저장  list[result + N].add(subset.get(i) + 1); } check[result + N] = true; } } }   ","description":"","tags":null,"title":"[백준] 17453 두 개의 문","uri":"/posts/algorithm/study11/%EB%B0%B1%EC%A4%80_17453%EB%91%90%EA%B0%9C%EC%9D%98%EB%AC%B8/"},{"categories":["Algorithm","Study11"],"content":"`\n모든 문자의 경우의 수를 구한 다음에 입력받은 문자에 해당하는 경우의 수 출력\n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61  import java.io.BufferedReader; import java.io.IOException; import java.io.InputStreamReader; import java.util.HashMap; import java.util.StringTokenizer; public class B20166 { static int N,M,K; static char[][] arr; static String[] likestr; static int[][] delta = {{1,0},{1,1},{0,1},{-1,1},{-1,0},{-1,-1},{0,-1},{1,-1}}; static HashMap\u003cString, Integer\u003e map = new HashMap\u003c\u003e(); public static void main(String[] args) throws IOException { BufferedReader br = new BufferedReader(new InputStreamReader(System.in)); StringBuilder sb = new StringBuilder(); StringTokenizer st = new StringTokenizer(br.readLine()); N = Integer.parseInt(st.nextToken()); M = Integer.parseInt(st.nextToken()); K = Integer.parseInt(st.nextToken()); arr = new char[N][M]; likestr = new String[K]; for(int i=0;i\u003cN;i++) { arr[i] = br.readLine().toCharArray(); } for(int i=0;i\u003cN;i++) { for(int j=0;j\u003cM;j++) { String key = Character.toString(arr[i][j]); // key가 있으면 +1, 없으면 default로 생성 \tmap.put(key,map.getOrDefault(key,0) + 1); go(i,j,1,key); } } // 해당하는 문자의 경우 출력\t\tfor(int i=0;i\u003cK;i++) { sb.append(map.getOrDefault(br.readLine(), 0)).append(\"\\n\"); } System.out.println(sb); } private static void go(int x, int y, int depth, String key) { if(depth==5) return; for(int d=0;d\u003c8;d++) { int nx = x + delta[d][0]; int ny = y + delta[d][1]; // 범위 넘었을 때 처리 \tif (nx \u003c 0) nx = N-1; if (ny \u003c 0) ny = M-1; if (nx \u003e N-1) nx = 0; if (ny \u003e M-1) ny = 0; String newkey = key + arr[nx][ny]; // 새로운 문자열 count \tmap.put(newkey, map.getOrDefault(newkey, 0) + 1); go(nx,ny,depth+1,newkey); } } }   ","description":"","tags":null,"title":"[백준] 20166 호석의 문자열 지옥","uri":"/posts/algorithm/study11/%EB%B0%B1%EC%A4%80_20166%ED%98%B8%EC%84%9D%EB%AC%B8%EC%9E%90%EC%97%B4/"},{"categories":["Algorithm","Study11"],"content":"` dfs\n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57  import java.io.BufferedReader; import java.io.IOException; import java.io.InputStreamReader; import java.util.StringTokenizer; public class B17265 { static int N,max = Integer.MIN_VALUE, min = Integer.MAX_VALUE; static char arr[][]; public static void main(String[] args) throws IOException { BufferedReader br = new BufferedReader(new InputStreamReader(System.in)); StringTokenizer st; N = Integer.parseInt(br.readLine()); arr = new char[N][N]; for (int i = 0; i \u003cN; i++) { st = new StringTokenizer(br.readLine()); for (int j = 0; j \u003cN; j++) { arr[i][j] = st.nextToken().charAt(0); } } dfs(0, 0, arr[0][0]-'0', arr[0][0]); System.out.println(max + \" \" + min); } public static void dfs(int x, int y, int result, char oper) { int get = arr[x][y] - '0'; // 숫자일 경우 연산 \tif(get \u003e= 0 \u0026\u0026 get \u003c= 5) { if(oper == '+') result += get; else if(oper == '-') result -= get; else if(oper == '*') result *= get; } // 연산자일 경우 \telse { oper = arr[x][y]; } if(x == N-1 \u0026\u0026 y == N-1) { max = Math.max(result, max); min = Math.min(result, min); return; } if(x \u003c N-1) { dfs(x+1, y, result, oper); } if(y \u003c N-1) { dfs(x, y+1, result, oper); } } }   ","description":"","tags":null,"title":"[백준] 17265 나의 인생에는 수학과 함께","uri":"/posts/algorithm/study11/%EB%B0%B1%EC%A4%80_17265%EC%88%98%ED%95%99/"},{"categories":["Programming","SQL"],"content":"`\nDDL DDL: 데이터 형태 규정: create, alter, drop, rename, truncate\nunsigned : 0이상 양수\nauto increment : 자동 1 증가\ncheck : 값 범위\nTCL TCL: commit, rollback, savepoint\n1 2 3 4 5  # db 생성 create database testdb; # db사용 use testdb   ALTER 시 고려사항\n20자 입력할 수 있는 데이터\n크기를 늘리면 상관없지만 줄이게 되면 데이터 훼손이 일어날 수 있음.\nTransaction 데이터 처리의 한 단위( 개별 SQL 중심이 아닌 업무 중심)\nTransaction 시작과 종료\n TX의 시작 : DML(C,U,D)를 시작하면 시작 TX의 종료 : 명시적으로 commit(반영) 또는 rollback(취소)이 호출될 때  DDL(crate, alter, drop 등 구조 변경)이 실행될 때 –\u003e commit SQL 툴의 정상적인 종료 –\u003e commit, 비정상 종료 –\u003e rollback    TX가 종료(commit, rollback)되지 않았는데 다른 사용자가 조회 등을 하려고 하면 rock이 걸리게 되어 사용할 수 없는 상황이 발생하게 됨.\n DML INSERT INTO TABLE() VALUES ()\nUPDATE TABLE SET ~ WHERE CONDITION\nDELETE FROM TABLE WHERE CONDITION\nSELECT BETWEEN : 이상 이하\nLIKE %X% : X포함\n%X__ : 뒤에서 3번째가 X\nLimit 구문 limit 4, 5 : 앞의 네 개는 스킵하고 5번째부터\ncase ~ when 구문 1 2 3 4 5 6 7  select deptno, case when job='ALAYST' then sal end 'ALAYST', case when job='CLERK' then sal fend 'CLERK', case when job='MANAGER' then sal end 'MANAGER', case when job='PRESIDENT' then sal end 'PRESIDENT', case when job='SALESMAN' then sal end 'SALESMAN' from emp;   숫자 함수 FLOOR(값) : 값보다 작은 정수 중 가장 큰 수 (실수를 무조건 버림)\nTRUNCATE(값, 자릿수) : 소수점 이하 버리기\nROUND(값, 자릿수) : 반올림\n문자 함수 SUBSTRING(‘문자열’, 시작 위치, 개수) : 문자열 중 시작 위치부터 개수만큼 출력\nSUBSTR도 가능\nCONCAT(‘문자열1’, ‘문자열2’, ‘문자열3’ …) : 문자열 잇기\nUPPER(‘문자열’) : 대문자로\nREVERSE(‘문자열’) : 문자열을 반대로 나열\nLEFT(‘문자열’, 개수) : 왼쪽에서 개수만큼\nREPLACE(문자,바뀔거,새거)\nINSERT(문자, 시작위치, 길이, 새문자)\nTRIM(‘문자열’)\nLENGTH()는 바이트 수, char_length()는 글자 수\nINSTR(문자, 찾는문자) : 위치값 리턴\n날짜 함수 now() : 날짜, 시간\nsysdate() : 날짜, 시간\ncurdate() : 날짜\ncurtime() : 시간\nDATE_ADD, SUB\nDAYOFWEEK : 일요일 1 토요일 7\nWEEKDAY : 월요일 0 일요일 6\nsleep해서 재우면 sysdate()는 10초가 늘어남\nNULL은 논리연산시 NULL|TRUE = TRUE, NULL\u0026FALSE = FALSE 나머지 NULL\n JOIN OUTER JOIN\n한 쪽에는 데이터가 존재하는데 다른 쪽 테이블에는 없을 경우 검색되지 않는 문제 해결\nSub query 단일 행\n다중 행 → in, any, all\n=any → in\n SQL 실행 순서\n1 2 3 4 5 6  SELECT 5 FROM 1 WHERE 2 GROUP BY 3 HAVING 4 ORDER BY 6   Aggregation : sum, max, count 등\n 집계함수를 사용하지 않은 필드랑 같이 쓸 수 없음 → group by 사용  Having : group by 한 결과에 조건 추가(집계 조건)\nSET 연산\n select 절의 column의 개수, type이 일치해야 한다  union : 중복x\nunion all : 중복\nintersect : 교집합\nminus : 차집합\n Database Modeling Primary Key  후보키 중에서 선택한 주 키, not null, unique  alternate key : 후보키 중 기본 키 아님\ncomposite : 둘 이상 컬럼을 식별자로\nForeign Key  관계를 맺는 두 엔티티에서 서로 참조하는 릴레이션의 애트리뷰트로 지정되는 키 값  관계가 만족되지 않는 경우 optional(동그라미)\nMapping Rule 단순 엔티티 ⇒ 테이블\n속성 ⇒ 컬럼\n식별자 ⇒ 기본키\n관계 ⇒ 참조키. 테이블\n정규화 정규화가 제대로 이루어지지 않는다면 수정, 삽입, 삭제 과정에서 문제가 발생할 수 있음\n 하나를 수정할 때 여러 개를 수정, 삭제할 때 여러 개가 삭제  제1정규화  중복을 제거 : 각 row마다 컬럼의 값이 1개씩만 있어야 함 반복되는 그룹속성 : 같은 성격과 내용의 컬럼이 연속적으로 나타나는 컬럼  제2정규화  복합키에 전첵적으로 의존하지 않는 속성 제거 부분적 함수 종속 관계 : 기본키 중에 특정 칼럼에만 종속된 칼럼이 없어야 함  Student, Subject가 복합키고 age가 student에만 종속이면 (Student, Subject), (Student, age)로 나누기    제3정규화  이행적 함수 종속 제거 : 기본키 이외의 다른 컬럼이 그외 다른 컬럼을 결정할 수 없음 기본키에 의존하지 않고 일반 컬럼에 의존하는 칼럼 제거(기본키 이외 속성이 다른 칼럼을 제어)  역정규화 방법  데이터 중복 : 조인 프로세스를 줄이기 위함 테이블 분리 : 컬럼 기준으로 분리(컬럼 수), 레코드 기준으로 분리(레코드 양) 요약 테이블 생성 : 조회 프로세스를 줄이기 위해 정보만을 저장하는 테이블을 생성 테이블 통합 : 분리된 두 테이블이 시스템 성능에 영향을 끼칠 경우 고려  ","description":"","tags":null,"title":"SQL","uri":"/posts/programming/sql/sql/"},{"categories":["Algorithm","Study11"],"content":"` bfs\n3가지 경우를 확인하고 큐에 넣기\n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57  import java.io.BufferedReader; import java.io.IOException; import java.io.InputStreamReader; import java.util.LinkedList; import java.util.Queue; import java.util.StringTokenizer; public class B15558 { static int N,K; static char arr[][];\tstatic boolean visit[][]; public static void main(String[] args) throws IOException { BufferedReader br = new BufferedReader(new InputStreamReader(System.in)); StringTokenizer st = new StringTokenizer(br.readLine()); N = Integer.parseInt(st.nextToken()); K = Integer.parseInt(st.nextToken()); arr = new char[2][N]; visit = new boolean[2][N]; arr[0] = br.readLine().toCharArray(); arr[1] = br.readLine().toCharArray(); // 앞 뒤 점프  int dc[] = {-1,1,K}; boolean flag = false; // 갈 수 있는지 여부 \tQueue\u003cint[]\u003e q = new LinkedList\u003cint[]\u003e(); q.add(new int[] {0,0,0}); // 좌표와 시간 저장 \tvisit[0][0]=true; e:while(!q.isEmpty()) { int cur[]= q.poll(); for (int i = 0; i \u003c 3; i++) { int nc = cur[1]+dc[i]; int nr = cur[0]; int time = cur[2]; // 점프의 경우 \tif(i==2) { if(cur[0]==1) nr = 0; else nr = 1; } if(nc\u003e=N) { // 사이즈를 넘어가 게임 클리어 \tflag = true; break e; } // 방문 여부, 갈 수 있는지 체크 \tif(nc \u003c= time) continue; if(visit[nr][nc]) continue; if(arr[nr][nc]=='0') continue; visit[nr][nc]=true; q.add(new int[] {nr,nc,time+1}); } } System.out.println(flag?1:0); } }   ","description":"","tags":null,"title":"[백준] 15558 점프게임","uri":"/posts/algorithm/study11/%EB%B0%B1%EC%A4%80_15558%EC%A0%9A%ED%94%84%EA%B2%8C%EC%9E%84/"},{"categories":["Algorithm","Study11"],"content":"` 다익스트라\n그래프를 만들고 다익스트라 활용. 1-\u003en1-\u003en2-\u003en 과 1-\u003en2-\u003en1-\u003en 두 가지 구하기\n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90  import java.io.BufferedReader; import java.io.IOException; import java.io.InputStreamReader; import java.util.ArrayList; import java.util.Arrays; import java.util.List; import java.util.PriorityQueue; import java.util.StringTokenizer; public class B1504 { static int N,E , n1,n2; static final int INF = 200000000; static List\u003cint[]\u003e list[]; static boolean[] visit; static int[] dist; public static void main(String[] args) throws IOException { BufferedReader br = new BufferedReader(new InputStreamReader(System.in)); StringTokenizer st = new StringTokenizer(br.readLine()); N = Integer.parseInt(st.nextToken()); E = Integer.parseInt(st.nextToken()); list = new ArrayList[N + 1]; for(int i = 0; i \u003c= N; i++) list[i] = new ArrayList\u003c\u003e(); dist = new int[N + 1]; for(int i = 0 ; i \u003c E; i++){ st = new StringTokenizer(br.readLine()); int s = Integer.parseInt(st.nextToken()); int e = Integer.parseInt(st.nextToken()); int w = Integer.parseInt(st.nextToken()); list[s].add(new int[] {e,w}); list[e].add(new int[]{s, w}); } st = new StringTokenizer(br.readLine()); n1 = Integer.parseInt(st.nextToken()); n2 = Integer.parseInt(st.nextToken()); // 2가지 경우를 구해서 최소값이 답이 됨.  int ans1 = 0; int ans2 = 0; ans1 += dijkstra(1, n1); ans1 += dijkstra(n1, n2); ans1 += dijkstra(n2, N); ans2 += dijkstra(1, n2); ans2 += dijkstra(n2, n1); ans2 += dijkstra(n1, N); if (ans1 \u003e= INF \u0026\u0026 ans2 \u003e= INF) { System.out.println(-1); return; } System.out.println(Math.min(ans1, ans2)); } private static int dijkstra(int start, int end){ // 거리와 방문 여부 초기화 \tArrays.fill(dist, INF); visit = new boolean[N+1] ; // 우선 순위 큐를 활용한 다익스트라  PriorityQueue\u003cint []\u003e queue = new PriorityQueue\u003c\u003e((o1,o2) -\u003eo1[1]-o2[1]); queue.add(new int[] {start, 0}); dist[start] = 0; while (!queue.isEmpty()){ int[] cur = queue.poll(); int next = cur[0]; int cost = cur[1]; if(visit[next] == true) continue; visit[next] = true; for(int i = 0; i \u003c list[next].size(); i++){ int nextN = list[next].get(i)[0]; int nextW = list[next].get(i)[1]; if(!visit[nextN] \u0026\u0026 dist[nextN] \u003e cost + nextW){ dist[nextN] = cost + nextW; queue.add(new int[]{nextN, dist[nextN]}); } } } return dist[end]; } }    스터디 중 a로 갔다가 다시 1로 돌아오고 b로 가는 게 최단경로일 수 있지 않냐는 질문이 나옴. -\u003e a에서 b로 갈 때 이미 최단경로임이 보장됨.(즉 a와 b 사이에 1이 있을 수도 없을 수도 있지만 상관없이 최단경로)  ","description":"","tags":null,"title":"[백준] 1504_최단경로","uri":"/posts/algorithm/study11/%EB%B0%B1%EC%A4%80_1504_%ED%8A%B9%EC%A0%95%EC%B5%9C%EB%8B%A8/"},{"categories":["Algorithm","Study11"],"content":"`\n k=1일 때, 모든 경우에서 답은 1 k=2일 때, 답은 n+1 k=3까지 구해보면 조합이나 파스칼 삼각형 문제 형태를 가지고 있음   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27  import java.io.BufferedReader; import java.io.IOException; import java.io.InputStreamReader; import java.util.StringTokenizer; public class B1225 { public static void main(String[] args) throws IOException { BufferedReader br = new BufferedReader(new InputStreamReader(System.in)); StringTokenizer st = new StringTokenizer(br.readLine()); int N = Integer.parseInt(st.nextToken()); int K = Integer.parseInt(st.nextToken()); int[][] arr = new int[N+1][K+1]; for (int i = 1; i \u003c= K; i++) { arr[0][i] = 1; } for (int i = 1; i \u003c= K; i++) { for (int j = 1; j \u003c= N; j++) { arr[j][i] = (arr[j-1][i] + arr[j][i-1])%1000000000; } } System.out.println(arr[N][K]); } }   ","description":"","tags":null,"title":"[백준] 2225 합분해","uri":"/posts/algorithm/study11/%EB%B0%B1%EC%A4%80_2225%ED%95%A9%EB%B6%84%ED%95%B4/"},{"categories":["Algorithm","Study10"],"content":"`\n 이전 아이템 위치에서 다음 아이템 위치의 경우의 수를 구하고 답에 계속 곱해준다.   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71  import java.io.BufferedReader; import java.io.IOException; import java.io.InputStreamReader; import java.util.StringTokenizer; public class B2411 { static int N,M,A,B; static int[][] arr, dp; public static void main(String[] args) throws IOException { BufferedReader br = new BufferedReader(new InputStreamReader(System.in)); StringTokenizer st = new StringTokenizer(br.readLine()); N = Integer.parseInt(st.nextToken()); M = Integer.parseInt(st.nextToken()); A = Integer.parseInt(st.nextToken()); B = Integer.parseInt(st.nextToken()); arr = new int[N+1][M+1]; dp = new int[N+1][M+1]; int a=0,b=0; for (int i = 0; i \u003c A; i++) { st = new StringTokenizer(br.readLine()); a = Integer.parseInt(st.nextToken()); b = Integer.parseInt(st.nextToken()); arr[a][b] = 1; } for (int i = 0; i \u003c B; i++) { st = new StringTokenizer(br.readLine()); a = Integer.parseInt(st.nextToken()); b = Integer.parseInt(st.nextToken()); arr[a][b] = 2; } a=1; b=1; int cnt=1; for (int i = 1; i \u003c=N; i++) { for (int j = 1; j \u003c=M; j++) { // 아이템이면 이전 위치에서 올 수 있는 가지수 세기 \tif(arr[i][j]==1) { cnt*= go(i,j,a,b); a=i; b=j; } } } if(arr[N][M]!=1) //마지막 아이템 없을 경우 \tcnt*= go(N,M,a,b); System.out.println(cnt); } private static int go(int px, int py, int x, int y) { // 시작점 기준 1로 채우기 \tfor(int i = x;i\u003c=px;i++){ if(arr[i][y] == 2)break; dp[i][y] = 1; } for(int i = y;i\u003c=py;i++){ if(arr[x][i] == 2)break; dp[x][i] = 1; } // 오른쪽 위쪽 갈 수 있는 경우의 수 \tfor(int i = x+1;i\u003c=px;i++){ for(int j = y+1;j\u003c=py;j++){ if(arr[i][j] != 2) dp[i][j] = dp[i][j-1] + dp[i-1][j]; } } return dp[px][py]; } }   ","description":"","tags":null,"title":"[백준] 2411_아이템 먹기","uri":"/posts/algorithm/study10/%EB%B0%B1%EC%A4%80_2411_%EC%95%84%EC%9D%B4%ED%85%9C/"},{"categories":["Algorithm","Study10"],"content":"`\n5차원 dp를 만들어 방문 체크 여부 확인 후 문자열 만들기\n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47  import java.io.BufferedReader; import java.io.IOException; import java.io.InputStreamReader; public class B14238 { static boolean[][][][][] dp; static int[] abc = new int[3]; static boolean flag; public static void main(String[] args) throws IOException { BufferedReader br = new BufferedReader(new InputStreamReader(System.in)); char arr[] = br.readLine().toCharArray(); for (int i = 0; i \u003c arr.length; i++) { if(arr[i]=='A') abc[0]++; else if(arr[i]=='B') abc[1]++; else abc[2]++; } dp = new boolean[abc[0]+1][abc[1]+1][abc[2]+1][3][3]; search(abc[0],abc[1],abc[2],0,0, new String(\"\")); if(!flag) System.out.println(-1); } private static void search(int a, int b, int c, int i, int j, String str) { if(flag) return; if(a==0\u0026\u0026b==0\u0026\u0026c==0) { System.out.println(str); flag = true; return; } if(dp[a][b][c][i][j]) return; dp[a][b][c][i][j] = true; // c가 있고 이전값과 그전값 확인 \tif(c\u003e0\u0026\u0026i!=2 \u0026\u0026j!=2 ) search(a,b,c-1,j,2,str+\"C\"); // b가 있고 이전값 확인 \tif(b\u003e0\u0026\u0026j!=1 ) search(a,b-1,c,j,1,str + \"B\"); // a가 있을 때 \tif(a\u003e0) search(a-1,b,c,j,0,str + \"A\"); } }   ","description":"","tags":null,"title":"[백준] 14238 출근기록","uri":"/posts/algorithm/study10/%EB%B0%B1%EC%A4%80_14238_%EC%B6%9C%EA%B7%BC%EA%B8%B0%EB%A1%9D/"},{"categories":["Algorithm","Study10"],"content":"` 이분 탐색\n$O(N*NlogN)$의 시간복잡도여서 시간초과를 예상했으나 그렇진 않았다. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49  import java.io.BufferedReader; import java.io.IOException; import java.io.InputStreamReader; import java.util.Arrays; import java.util.StringTokenizer; public class B2473 { static int N; static long max = 3000000000L; static long[] arr , three = new long[3]; public static void main(String[] args) throws IOException { BufferedReader br = new BufferedReader(new InputStreamReader(System.in)); N = Integer.parseInt(br.readLine()); arr = new long[N]; StringTokenizer st = new StringTokenizer(br.readLine()); for (int i = 0; i \u003c N; i++) { arr[i] = Long.parseLong(st.nextToken()); } // 정렬해주기 \tArrays.sort(arr); //n-2번의 이분 탐색 \tfor(int i=0;i\u003cN-2;i++) { int left = i+1; int right = N-1; while(left \u003c right) { long sum = arr[i] + arr[left] + arr[right]; if(Math.abs(sum) \u003c max) { three[0] = arr[i]; three[1] = arr[left]; three[2] = arr[right]; max = Math.abs(sum); } if(sum\u003e0) right--; else left++; } } System.out.println(three[0]+\" \"+three[1]+\" \"+three[2]); } }   ","description":"","tags":null,"title":"[백준] 2473 세용액","uri":"/posts/algorithm/study10/%EB%B0%B1%EC%A4%80_2473_%EC%84%B8%EC%9A%A9%EC%95%A1/"},{"categories":["Algorithm","Study10"],"content":"`\n다른 분의 풀이를 보고 이전 값의 제곱 값에 $_{2^{i+1}-2} \\mathrm{C}_{2^i-1}$ 를 곱하는 원리 찾음\n해당하는 조합 숫자는 파스칼의 삼각형 원리 이용\n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31  import java.io.BufferedReader; import java.io.IOException; import java.io.InputStreamReader; public class B13912 { static final long R = 1000000007; public static void main(String[] args) throws IOException { BufferedReader br = new BufferedReader(new InputStreamReader(System.in)); int h = Integer.parseInt(br.readLine()); long[] dp = new long[11]; long[][] arr = new long[2048][2048]; arr[0][0] = 1; for(int i=1;i\u003c2048;i++) { // 삼각형 방식으로 값을 넣어 파스칼의 삼각형 생성 \tarr[i][0] = 1; for(int j=1;j\u003c=i;j++) { arr[i][j] = (arr[i-1][j] + arr[i-1][j-1])%R; } } dp[0] = 1; for(int i=1;i\u003c=h;i++) { dp[i] = (dp[i-1]*dp[i-1]) % R; // 제곱 후 새로운 값 곱해주기 \tdp[i] *= arr[(1\u003c\u003c(i+1))-2][(1\u003c\u003ci)-1]; dp[i] %=R; } System.out.println(dp[h]); } }   ","description":"","tags":null,"title":"[백준] 13912 외계생물","uri":"/posts/algorithm/study10/%EB%B0%B1%EC%A4%80_13912_%EC%99%B8%EA%B3%84/"},{"categories":["Algorithm","Study10"],"content":"`\nbfs + backtracking\n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92  import java.io.BufferedReader; import java.io.IOException; import java.io.InputStreamReader; import java.util.LinkedList; import java.util.Queue; import java.util.StringTokenizer; public class B16946 { static int N,M; static int[][] arr, dp, delta = {{1,0},{0,1},{-1,0},{0,-1}}; static boolean[][] visit, check; public static void main(String[] args) throws IOException { BufferedReader br = new BufferedReader(new InputStreamReader(System.in)); StringTokenizer st = new StringTokenizer(br.readLine()); N = Integer.parseInt(st.nextToken()); M = Integer.parseInt(st.nextToken()); arr = new int[N][M]; dp = new int[N][M]; visit = new boolean[N][M]; // 전체 체크 \tcheck = new boolean[N][M]; // 벽 체크 \tfor(int i=0;i\u003cN;i++) { String[] s = br.readLine().split(\"\"); for(int j=0;j\u003cM;j++) { arr[i][j] = Integer.parseInt(s[j]); } } for(int i=0;i\u003cN;i++) { for(int j=0;j\u003cM;j++) { if(arr[i][j]==0 \u0026\u0026 !visit[i][j]) { search(i,j); }else if(arr[i][j]==1) { dp[i][j]+=1; } } } StringBuilder sb = new StringBuilder(); for(int i = 0; i \u003c N; i++) { for(int j = 0; j \u003c M; j++) { sb.append(dp[i][j]%10); } sb.append(\"\\n\"); } System.out.println(sb); } private static void search(int x, int y) { Queue\u003cint []\u003e q1 = new LinkedList\u003c\u003e(); // 영역 찾기 큐 \tQueue\u003cint []\u003e q2 = new LinkedList\u003c\u003e(); // 영역에 인접한 벽 찾기 큐 \tq1.add(new int[] {x,y}); visit[x][y] = true; int cnt = 1; while(!q1.isEmpty()) { int[] point = q1.poll(); for(int d=0;d\u003c4;d++) { int nx = point[0] + delta[d][0]; int ny = point[1] + delta[d][1]; if(!inside(nx,ny) || visit[nx][ny]) continue; if(arr[nx][ny]==1) { if(!check[nx][ny]) { q2.add(new int[] {nx,ny}); // 주위에 벽 있고 check 아닌 경우 q2에 추가 \tcheck[nx][ny] = true; } continue; } cnt++; // 영역 넓이 \tvisit[nx][ny] = true; q1.add(new int[]{nx,ny}); } } while(!q2.isEmpty()) { // 벽에 영역 넓이를 더해줌 \tint[] point = q2.poll(); dp[point[0]][point[1]] +=cnt; check[point[0]][point[1]] = false; } } private static boolean inside(int x, int y) { return x \u003e= 0 \u0026\u0026 x \u003c N \u0026\u0026 y \u003e= 0 \u0026\u0026 y \u003c M; } }   ","description":"","tags":null,"title":"[백준] 16946 벽 부수고 이동하기4","uri":"/posts/algorithm/study10/%EB%B0%B1%EC%A4%80_16946_%EB%B2%BD%EB%B6%804/"},{"categories":["Data_Science","Machine_Learning"],"content":"Bike demand predict 1 2 3 4 5 6 7 8 9  import numpy as np import pandas as pd import matplotlib.pyplot as plt import seaborn as sns from sklearn.preprocessing import StandardScaler train = pd.read_csv(\"../input/bike-sharing-demand/train.csv\") test = pd.read_csv(\"../input/bike-sharing-demand/test.csv\") train.head()   1  test.info()   \u003cclass 'pandas.core.frame.DataFrame'\u003e RangeIndex: 6493 entries, 0 to 6492 Data columns (total 9 columns): datetime 6493 non-null object season 6493 non-null int64 holiday 6493 non-null int64 workingday 6493 non-null int64 weather 6493 non-null int64 temp 6493 non-null float64 atemp 6493 non-null float64 humidity 6493 non-null int64 windspeed 6493 non-null float64 dtypes: float64(3), int64(5), object(1) memory usage: 456.7+ KB  Range of variable in train and test is similar. So for now, i don’t remove outlier\n\nCreate variables and visualization create columns from datetime\n1 2 3 4 5 6 7 8 9  for df in [train, test]: df[\"datetime\"] = pd.DatetimeIndex(df[\"datetime\"]) df[\"hour\"] = [x.hour for x in df[\"datetime\"]] df[\"weekday\"] = [x.dayofweek for x in df[\"datetime\"]] df[\"month\"] = [x.month for x in df[\"datetime\"]] df[\"year\"] = [x.year for x in df[\"datetime\"]] df['year_season'] = df['year'].astype(str) + \"_\" + df['season'].astype(str) df[\"year\"] = df[\"year\"].map({2011:1, 2012:0}) df.drop('datetime',axis=1,inplace=True)   See variables’s distribution by distplot and countplot\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  sns.set_style(\"darkgrid\") plt.figure(figsize=(15,10)) plt.suptitle('variables distribution') plt.subplots_adjust(hspace = 0.5, wspace = 0.3) for i, col in enumerate(train.columns[:11]): plt.subplot(3,4,i+1) if str(train[col].dtypes)[:3]=='int': if len(train[col].unique()) \u003e 5: sns.distplot(train[col]) else: sns.countplot(train[col]) else: sns.distplot(train[col]) plt.ylabel(col)   see relation of categorical predictors and outcomes by countplot\n1 2 3 4 5 6 7 8 9 10  plt.figure(figsize=(13,20)) plt.suptitle('casual vs registered vs count') plt.subplots_adjust(hspace = 0.5, wspace = 0.3) col_list = [\"season\",\"holiday\",\"workingday\",\"weather\",\"year\",\"year_season\",\"month\",\"weekday\",\"hour\"] count_list = [\"casual\",\"registered\",\"count\"] for i, col in enumerate(col_list): for j, con in enumerate(count_list): plt.subplot(9,3,3*i+j+1) sns.barplot(train[col],train[con])   In count of holiday, workingday and weekday, there is no difference depending on categories. but in registered and casual, it depend of the categories. So need to look at this part differently.\nsee relationship between weekday and each count by workingday and holiday\n1 2 3 4 5  plt.figure(figsize=(15,6)) plt.subplot(121) sns.barplot(x=\"weekday\", y=\"casual\", hue=\"workingday\", data=train) plt.subplot(122) sns.barplot(x=\"weekday\", y=\"registered\", hue=\"workingday\", data=train)   \u003cmatplotlib.axes._subplots.AxesSubplot at 0x7fe7b371f940\u003e  There is no holiday in Tuesday and Thursday. And there is differences when Monday, Wednesday, and Friday.\nsee relationship between hour and each count by workingday and holiday\n1 2 3 4 5 6 7 8 9 10  plt.figure(figsize=(18,11)) plt.subplot(221) sns.pointplot(x=\"hour\", y=\"casual\", hue=\"workingday\", data=train) plt.subplot(222) sns.pointplot(x=\"hour\", y=\"casual\", hue=\"holiday\", data=train) plt.subplot(223) sns.pointplot(x=\"hour\", y=\"registered\", hue=\"workingday\", data=train) plt.subplot(224) sns.pointplot(x=\"hour\", y=\"registered\", hue=\"holiday\", data=train) # train.pivot_table(index=\"hour\", columns=\"workingday\", aggfunc=\"size\")   \u003cmatplotlib.axes._subplots.AxesSubplot at 0x7fe7b995a0b8\u003e  The number of registered and casual according to workingday and holiday show the opposite pattern. And there are differences in the number of registered according to workingday at the closing hour and the office-going hour. So many registered is can be expected to workers.\ncorrelation 1 2  plt.figure(figsize=(11,11)) sns.heatmap(train.corr(),annot=True,cmap=\"Blues\")   temp and atemp have high correlation and register and have too. And windspeed and outcomes have low correlation(\u003c=0.1) See scatterplot of temp and atemp.\n1 2 3  for i, df in enumerate([train,test]): plt.subplot(1,2,i+1) sns.scatterplot(x = 'temp', y = 'atemp',data = df)   In train data, there is strange pattern, but not in test. It seems to be haved wrong value in atemp. So based on correlation and scatterplot, judged to remove atemp\nBased on the above results, make new variable.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  df_list = {\"train\":None, \"test\" : None} for name, df in zip(df_list.keys(),[train, test]): df['windspeed'] = np.log(df['windspeed']+1) df[\"weekday_working\"] = df[\"weekday\"]*df[\"workingday\"] df[\"weekday_holiday\"] = df[\"weekday\"]*df[\"holiday\"] df['casual_workhour'] = df[['hour', 'workingday']].apply(lambda x: int(x['workingday'] == 0 and 10 \u003c= x['hour'] \u003c= 19), axis=1) df['casual_holi_hour'] = df[['hour', 'holiday']].apply(lambda x: int(x['holiday'] == 1 and 9 \u003c= x['hour'] \u003c= 22), axis=1) df['register_workhour'] = df[['hour', 'workingday']].apply( lambda x:int((x['workingday'] == 1 and (6 \u003c= x['hour'] \u003c= 8 or 17 \u003c= x['hour'] \u003c= 20)) or (x['workingday'] == 0 and 10 \u003c= x['hour'] \u003c= 15)), axis=1) df['register_holi_hour'] = df[['hour', 'holiday']].apply( lambda x:int(x['holiday'] == 0 and (7 \u003c= x['hour'] \u003c= 8 or 17 \u003c= x['hour'] \u003c= 18)), axis=1) df.drop('atemp',axis=1,inplace=True) by_season = train.groupby('year_season')[['count']].median() by_season.columns = ['count_season'] train1 = train.join(by_season, on='year_season').drop('year_season',axis=1) test1 = test.join(by_season, on='year_season').drop('year_season',axis=1)   Divide predictors and outcomes. And take logging outcomes to normalize. 1 2 3 4  from sklearn.model_selection import train_test_split y_list = [\"casual\",\"registered\",\"count\"] train_x = train1[[col for col in train1.columns if col not in ['casual','registered', 'count']]] train_y = np.log(train1[y_list]+1)   Modeling - 1. lightgbm + cross validation Use lightgbm model, and use cross-validation to prevent overfitting\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32  import lightgbm as lgb from sklearn.model_selection import KFold from sklearn.metrics import mean_squared_error folds = KFold(n_splits = 5, shuffle = True, random_state = 123) rms1,rms2 = [],[] models1,models2 = [], [] for n_fold, (trn_idx, val_idx) in enumerate(folds.split(train1)) : x_train, y_train = train_x.ix[trn_idx], train_y.ix[trn_idx] x_val, y_val = train_x.ix[val_idx], train_y.ix[val_idx] lgb_param = {'boosting_type':'gbdt', 'num_leaves': 45, 'max_depth': 30, 'learning_rate': 0.01, 'bagging_fraction' : 0.9, 'bagging_freq': 20, 'colsample_bytree': 0.9, 'metric': 'rmse', 'min_child_weight': 1, 'min_child_samples': 10, 'zero_as_missing': True, 'objective': 'regression', } train_set1 = lgb.Dataset(x_train, y_train[\"registered\"], silent=False) valid_set1 = lgb.Dataset(x_val, y_val[\"registered\"], silent=False) lgb_model1 = lgb.train(params = lgb_param, train_set = train_set1 , num_boost_round=5000, early_stopping_rounds=100,verbose_eval=500, valid_sets=valid_set1) train_set2 = lgb.Dataset(x_train, y_train[\"casual\"], silent=False) valid_set2 = lgb.Dataset(x_val, y_val[\"casual\"], silent=False) lgb_model2 = lgb.train(params = lgb_param, train_set = train_set2 , num_boost_round=5000, early_stopping_rounds=100,verbose_eval=500, valid_sets=valid_set2) models1.append(lgb_model1) models2.append(lgb_model2)   Training until validation scores don't improve for 100 rounds [500]\tvalid_0's rmse: 0.472853 [1000]\tvalid_0's rmse: 0.462003 Early stopping, best iteration is: [1388]\tvalid_0's rmse: 0.459316  see feature importance\n1 2 3 4 5 6  tmp = pd.DataFrame({'Feature': x_train.columns, 'Feature importance': lgb_model1.feature_importance()}) tmp = tmp.sort_values(by='Feature importance',ascending=False) plt.figure(figsize = (15,15)) plt.title('Features importance',fontsize=14) s = sns.barplot(x='Feature',y='Feature importance',data=tmp) s.set_xticklabels(s.get_xticklabels(),rotation=90)   1 2 3 4 5 6 7 8 9 10 11 12  preds = [] for model in models1: regi_pred = model.predict(test1) preds.append(regi_pred) fin_casual = np.mean(preds, axis=0) preds = [] for model in models2: casual_pred = model.predict(test1) preds.append(casual_pred) fin_regi = np.mean(preds, axis=0) count_pred1 = np.exp(fin_casual) + np.exp(fin_regi) - 2   - 3. randomforest and gradientboostingregressor 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor preds = {} regs = {\"gbdt\": GradientBoostingRegressor(random_state=0), \"rf\": RandomForestRegressor(random_state=0, n_jobs=-1)} for name, reg in regs.items(): if name == 'gbdt': reg.set_params(n_estimators=1500, min_samples_leaf=6) elif name == 'rf': reg.set_params(n_estimators=1500, min_samples_leaf=2) reg.fit(train_x, train_y['casual']) pred_casual = reg.predict(test1) pred_casual = np.exp(pred_casual) - 1 pred_casual[pred_casual \u003c 0] = 0 if name == 'gbdt': reg.set_params(n_estimators=1500, min_samples_leaf=6) elif name == 'rf': reg.set_params(n_estimators=1500, min_samples_leaf=2) reg.fit(train_x, train_y['registered']) pred_registered = reg.predict(test1) pred_registered = np.exp(pred_registered) - 1 pred_registered[pred_registered \u003c 0] = 0 preds[name] = pred_casual + pred_registered   1 2 3 4 5 6  tmp = pd.DataFrame({'Feature': x_train.columns, 'Feature importance': reg.feature_importances_}) tmp = tmp.sort_values(by='Feature importance',ascending=False) plt.figure(figsize = (15,15)) plt.title('Features importance',fontsize=14) s = sns.barplot(x='Feature',y='Feature importance',data=tmp) s.set_xticklabels(s.get_xticklabels(),rotation=90)   1 2 3 4  pred_mean = (count_pred1 + count_pred2 + preds['gbdt'] + preds['rf'])/4 sample = pd.read_csv(\"../input/bike-sharing-demand/sampleSubmission.csv\") sample[\"count\"] = pred_mean sample.to_csv(\"sample.csv\",index=False)   Result rmsle is 0.38081\n","description":"","tags":null,"title":"자전거 수요 예측","uri":"/posts/data_science/machine_learning/bike_demand/"},{"categories":["Data_Science","Data_Handling"],"content":"1 2 3 4  import pandas as pd import os df = pd.read_csv(\"car-good.csv\")   1 2 3  # 특징과 라벨 분리 X = df.drop('Class', axis = 1) Y = df['Class']   1 2 3  # 학습 데이터와 평가 데이터 분리 from sklearn.model_selection import train_test_split Train_X, Test_X, Train_Y, Test_Y = train_test_split(X, Y)   1 2 3  # 문자 라벨을 숫자로 치환  Train_Y.replace({\"negative\":-1, \"positive\":1}, inplace = True) Test_Y.replace({\"negative\":-1, \"positive\":1}, inplace = True)   1 2 3  # 자세한 범주형 변수 판별 =\u003e 모든 변수가 범주형임을 확인 for col in Train_X.columns: print(col, len(Train_X[col].unique()))   Buying 4 Maint 4 Doors 3 Persons 2 Lug_boot 3 Safety 3  더미화를 이용한 범주 변수 처리 1  Train_X = Train_X.astype(str) # 모든 변수가 범주이므로, 더미화를 위해 전부 string 타입으로 변환   1 2 3 4 5 6 7 8  from feature_engine.categorical_encoders import OneHotCategoricalEncoder as OHE dummy_model = OHE(variables = Train_X.columns.tolist(), drop_last = True) dummy_model.fit(Train_X) d_Train_X = dummy_model.transform(Train_X) d_Test_X = dummy_model.transform(Test_X)    res_values = method(rvalues)  1 2 3 4 5 6 7  # 더미화를 한 뒤의 모델 테스트 from sklearn.neighbors import KNeighborsClassifier as KNN model = KNN().fit(d_Train_X, Train_Y) pred_Y = model.predict(d_Test_X) from sklearn.metrics import f1_score f1_score(Test_Y, pred_Y)   0.0  연속형 변수로 치환 1 2 3 4 5  Train_df = pd.concat([Train_X, Train_Y], axis = 1) for col in Train_X.columns: # 보통은 범주 변수만 순회 temp_dict = Train_df.groupby(col)['Class'].mean().to_dict() # col에 따른 Class의 평균을 나타내는 사전 (replace를 쓰기 위해, 사전으로 만듦) Train_df[col] = Train_df[col].replace(temp_dict) # 변수 치환  Test_X[col] = Test_X[col].astype(str).replace(temp_dict) # 테스트 데이터도 같이 치환해줘야 함 (나중에 활용하기 위해서는 저장도 필요)   A value is trying to be set on a copy of a slice from a DataFrame. Try using .loc[row_indexer,col_indexer] = value instead See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy \"\"\"  1  Train_df.head()    .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; }  \n  Buying Maint Doors Persons Lug_boot Safety Class     810 -0.809524 -0.82716 -0.913462 -1.0 -0.921951 -1.000000 -1   471 -0.925466 -1.00000 -0.935185 -1.0 -0.926267 -1.000000 -1   381 -1.000000 -0.82716 -0.913462 -1.0 -0.926267 -1.000000 -1   80 -1.000000 -1.00000 -0.946429 -1.0 -0.946903 -0.869159 -1   637 -0.925466 -0.82716 -0.935185 -1.0 -0.946903 -0.924171 -1     1 2  Train_X = Train_df.drop('Class', axis = 1) Train_Y = Train_df['Class']   1 2 3 4 5 6 7 8  # 치환한 뒤의 모델 테스트 model = KNN().fit(Train_X, Train_Y) pred_Y = model.predict(Test_X) f1_score(Test_Y, pred_Y) # 라벨을 고려한 전처리이므로 더미화보다 좋은 결과가 나왔음 =\u003e 차원도 줄고 성능 상에 이점이 있으나,    0.20000000000000004 ","description":"","tags":null,"title":"범주형 변수 처리","uri":"/posts/data_science/data_handling/categorical/"},{"categories":["Data_Science","Data_Handling"],"content":"map\nSeries만\n1  df['winning_rate'] = df['team'].map(lambda x : total_record(x)[3])   apply\n복수 개의 컬럼\n1  df['winning_rate'] = df.apply(lambda x:relative_record(x['team'], x['against'])[3], axis=1)   ","description":"","tags":null,"title":"pandas 사용","uri":"/posts/data_science/data_handling/pandas2/"},{"categories":["Data_Science","Machine_Learning"],"content":"1 2 3 4 5 6 7 8 9 10 11 12 13  import os import numpy as np import pandas as pd from sklearn.linear_model import LogisticRegression from sklearn.model_selection import train_test_split from sklearn import metrics from sklearn.metrics import confusion_matrix from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve import statsmodels.api as sm import matplotlib.pyplot as plt import itertools import time ploan = pd.read_csv(\"./data/Personal Loan.csv\")   1 2  ploan_processed = ploan.dropna().drop(['ID','ZIP Code'], axis=1, inplace=False) ploan_processed = sm.add_constant(ploan_processed, has_constant='add')    설명변수(X), 타켓변수(Y) 분리 및 학습데이터와 평가데이터  1 2 3  feature_columns = list(ploan_processed.columns.difference([\"Personal Loan\"])) X = ploan_processed[feature_columns] y = ploan_processed['Personal Loan'] # 대출여부: 1 or 0   1 2  train_x, test_x, train_y, test_y = train_test_split(X, y, stratify=y,train_size=0.7,test_size=0.3,random_state=42) print(train_x.shape, test_x.shape, train_y.shape, test_y.shape)   (1750, 12) (750, 12) (1750,) (750,)  로지스틱회귀모형 모델링 y = f(x) 1 2  model = sm.Logit(train_y, train_x) results = model.fit(method='newton')   Optimization terminated successfully. Current function value: 0.131055 Iterations 9  1  results.summary()   Logit Regression Results  Dep. Variable: Personal Loan  No. Observations:   1750   Model: Logit  Df Residuals:   1738   Method: MLE  Df Model:   11   Date: Fri, 23 Aug 2019  Pseudo R-squ.:  0.6030   Time: 14:58:19  Log-Likelihood:   -229.35   converged: True  LL-Null:   -577.63        LLR p-value:  2.927e-142     coef std err z P|z| [0.025 0.975]   Age  0.0245  0.102  0.240  0.810  -0.175  0.224   CCAvg  0.0985  0.063  1.562  0.118  -0.025  0.222   CD Account  4.3726  0.568  7.703  0.000  3.260  5.485   CreditCard  -1.2374  0.337  -3.667  0.000  -1.899  -0.576   Education  1.5203  0.190  7.999  0.000  1.148  1.893   Experience  -0.0070  0.102  -0.069  0.945  -0.206  0.192   Family  0.7579  0.128  5.914  0.000  0.507  1.009   Income  0.0547  0.004  12.659  0.000  0.046  0.063   Mortgage  -0.0001  0.001  -0.144  0.885  -0.002  0.002   Online  -0.4407  0.263  -1.674  0.094  -0.957  0.075   Securities Account  -1.8520  0.561  -3.299  0.001  -2.952  -0.752   const  -13.9203  2.773  -5.021  0.000  -19.354  -8.486   1 2  # performance measure print(\"model AIC: \",\"{:.5f}\".format(results.aic))   model AIC: 482.69329  1  results.params   Age 0.024471 CCAvg 0.098468 CD Account 4.372577 CreditCard -1.237447 Education 1.520329 Experience -0.007032 Family 0.757911 Income 0.054695 Mortgage -0.000133 Online -0.440746 Securities Account -1.852006 const -13.920298 dtype: float64  1 2 3 4 5 6  ## 나이가 한살 많을수록록 대출할 확률이 1.024 높다. ## 수입이 1단위 높을소룩 대출할 확률이 1.05배 높다  ## 가족 구성원수가 1많을수록 대출할 확률이 2.13배 높다 ## 경력이 1단위 높을수록 대출할 확률이 0.99배 높다(귀무가설 채택) # Experience, Mortgage는 제외할 필요성이 있어보임 np.exp(results.params)   Age 1.024773e+00 CCAvg 1.103479e+00 CD Account 7.924761e+01 CreditCard 2.901239e-01 Education 4.573729e+00 Experience 9.929928e-01 Family 2.133814e+00 Income 1.056218e+00 Mortgage 9.998665e-01 Online 6.435563e-01 Securities Account 1.569221e-01 const 9.005163e-07 dtype: float64  1  pred_y = results.predict(test_x)   1 2 3 4 5 6 7  def cut_off(y,threshold): Y = y.copy() # copy함수를 사용하여 이전의 y값이 변화지 않게 함 Y[Y\u003ethreshold]=1 Y[Y\u003c=threshold]=0 return(Y.astype(int)) pred_Y = cut_off(pred_y,0.5)   1 2  cfmat = confusion_matrix(test_y,pred_Y) print(cfmat)   [[661 12] [ 28 49]]  1  (cfmat[0,0]+cfmat[1,1])/np.sum(cfmat) ## accuracy   0.9466666666666667  1 2 3  def acc(cfmat) : acc=(cfmat[0,0]+cfmat[1,1])/np.sum(cfmat) ## accuracy return(acc)   임계값(cut-off)에 따른 성능지표 비교 1 2 3 4 5 6 7 8 9  threshold = np.arange(0,1,0.1) table = pd.DataFrame(columns=['ACC']) for i in threshold: pred_Y = cut_off(pred_y,i) cfmat = confusion_matrix(test_y, pred_Y) table.loc[i] = acc(cfmat) table.index.name='threshold' table.columns.name='performance' table    .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; }  \n performance ACC   threshold      0.0 0.102667   0.1 0.908000   0.2 0.922667   0.3 0.933333   0.4 0.934667   0.5 0.946667   0.6 0.949333   0.7 0.946667   0.8 0.941333   0.9 0.937333     1 2 3 4 5 6 7 8 9 10 11  # sklearn ROC 패키지 제공 fpr, tpr, thresholds = metrics.roc_curve(test_y, pred_y, pos_label=1) # Print ROC curve plt.plot(fpr,tpr) # Print AUC auc = np.trapz(tpr,fpr) print('AUC:', auc)   AUC: 0.9463923891858513  1 2 3  feature_columns = list(ploan_processed.columns.difference([\"Personal Loan\",\"Experience\", \"Mortgage\"])) X = ploan_processed[feature_columns] y = ploan_processed['Personal Loan'] # 대출여부: 1 or 0   1 2  train_x2, test_x2, train_y, test_y = train_test_split(X, y, stratify=y,train_size=0.7,test_size=0.3,random_state=42) print(train_x.shape, test_x.shape, train_y.shape, test_y.shape)   (1750, 12) (750, 12) (1750,) (750,)  1 2  model = sm.Logit(train_y, train_x2) results2 = model.fit(method='newton')   Optimization terminated successfully. Current function value: 0.131062 Iterations 9  1  results2.summary()   Logit Regression Results  Dep. Variable: Personal Loan  No. Observations:   1750   Model: Logit  Df Residuals:   1740   Method: MLE  Df Model:   9   Date: Fri, 23 Aug 2019  Pseudo R-squ.:  0.6029   Time: 14:58:19  Log-Likelihood:   -229.36   converged: True  LL-Null:   -577.63        LLR p-value:  3.817e-144     coef std err z P|z| [0.025 0.975]   Age  0.0174  0.011  1.569  0.117  -0.004  0.039   CCAvg  0.0997  0.062  1.596  0.111  -0.023  0.222   CD Account  4.3699  0.567  7.705  0.000  3.258  5.481   CreditCard  -1.2350  0.337  -3.668  0.000  -1.895  -0.575   Education  1.5249  0.187  8.156  0.000  1.158  1.891   Family  0.7572  0.127  5.948  0.000  0.508  1.007   Income  0.0546  0.004  12.833  0.000  0.046  0.063   Online  -0.4418  0.263  -1.678  0.093  -0.958  0.074   Securities Account  -1.8526  0.561  -3.302  0.001  -2.952  -0.753   const  -13.7465  1.164  -11.814  0.000  -16.027  -11.466   1  results.summary()   Logit Regression Results  Dep. Variable: Personal Loan  No. Observations:   1750   Model: Logit  Df Residuals:   1738   Method: MLE  Df Model:   11   Date: Fri, 23 Aug 2019  Pseudo R-squ.:  0.6030   Time: 14:58:19  Log-Likelihood:   -229.35   converged: True  LL-Null:   -577.63        LLR p-value:  2.927e-142     coef std err z P|z| [0.025 0.975]   Age  0.0245  0.102  0.240  0.810  -0.175  0.224   CCAvg  0.0985  0.063  1.562  0.118  -0.025  0.222   CD Account  4.3726  0.568  7.703  0.000  3.260  5.485   CreditCard  -1.2374  0.337  -3.667  0.000  -1.899  -0.576   Education  1.5203  0.190  7.999  0.000  1.148  1.893   Experience  -0.0070  0.102  -0.069  0.945  -0.206  0.192   Family  0.7579  0.128  5.914  0.000  0.507  1.009   Income  0.0547  0.004  12.659  0.000  0.046  0.063   Mortgage  -0.0001  0.001  -0.144  0.885  -0.002  0.002   Online  -0.4407  0.263  -1.674  0.094  -0.957  0.075   Securities Account  -1.8520  0.561  -3.299  0.001  -2.952  -0.752   const  -13.9203  2.773  -5.021  0.000  -19.354  -8.486   1  pred_y = results2.predict(test_x2)   1  pred_Y = cut_off(pred_y,0.5)   1 2  cfmat = confusion_matrix(test_y,pred_Y) print(cfmat)   [[660 13] [ 29 48]]  1  acc(cfmat) ## accuracy   0.944  1 2 3 4 5 6 7 8 9  threshold = np.arange(0,1,0.1) table = pd.DataFrame(columns=['ACC']) for i in threshold: pred_Y = cut_off(pred_y,i) cfmat = confusion_matrix(test_y, pred_Y) table.loc[i] =acc(cfmat) table.index.name='threshold' table.columns.name='performance' table    .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; }  \n performance ACC   threshold      0.0 0.102667   0.1 0.908000   0.2 0.922667   0.3 0.932000   0.4 0.936000   0.5 0.944000   0.6 0.949333   0.7 0.946667   0.8 0.941333   0.9 0.937333     1 2 3 4 5 6 7 8 9 10  # sklearn ROC 패키지 제공 fpr, tpr, thresholds = metrics.roc_curve(test_y, pred_y, pos_label=1) # Print ROC curve plt.plot(fpr,tpr) # Print AUC auc = np.trapz(tpr,fpr) print('AUC:', auc)   AUC: 0.9465467667547905   변수선택법 1 2 3  feature_columns = list(ploan_processed.columns.difference([\"Personal Loan\"])) X = ploan_processed[feature_columns] y = ploan_processed['Personal Loan'] # 대출여부: 1 or 0   1 2  train_x, test_x, train_y, test_y = train_test_split(X, y, stratify=y,train_size=0.7,test_size=0.3,random_state=42) print(train_x.shape, test_x.shape, train_y.shape, test_y.shape)   (1750, 12) (750, 12) (1750,) (750,)  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116  def processSubset(X,y, feature_set): model = sm.Logit(y,X[list(feature_set)]) regr = model.fit() AIC = regr.aic return {\"model\":regr, \"AIC\":AIC} ''' 전진선택법 ''' def forward(X, y, predictors): # 데이터 변수들이 미리정의된 predictors에 있는지 없는지 확인 및 분류 remaining_predictors = [p for p in X.columns.difference(['const']) if p not in predictors] tic = time.time() results = [] for p in remaining_predictors: results.append(processSubset(X=X, y= y, feature_set=predictors+[p]+['const'])) # 데이터프레임으로 변환 models = pd.DataFrame(results) # AIC가 가장 낮은 것을 선택 best_model = models.loc[models['AIC'].argmin()] # index toc = time.time() print(\"Processed \", models.shape[0], \"models on\", len(predictors)+1, \"predictors in\", (toc-tic)) print('Selected predictors:',best_model['model'].model.exog_names,' AIC:',best_model[0] ) return best_model def forward_model(X,y): Fmodels = pd.DataFrame(columns=[\"AIC\", \"model\"]) tic = time.time() # 미리 정의된 데이터 변수 predictors = [] # 변수 1~10개 : 0~9 -\u003e 1~10 for i in range(1, len(X.columns.difference(['const'])) + 1): Forward_result = forward(X=X,y=y,predictors=predictors) if i \u003e 1: if Forward_result['AIC'] \u003e Fmodel_before: break Fmodels.loc[i] = Forward_result predictors = Fmodels.loc[i][\"model\"].model.exog_names Fmodel_before = Fmodels.loc[i][\"AIC\"] predictors = [ k for k in predictors if k != 'const'] toc = time.time() print(\"Total elapsed time:\", (toc - tic), \"seconds.\") return(Fmodels['model'][len(Fmodels['model'])]) ''' 후진소거법 ''' def backward(X,y,predictors): tic = time.time() results = [] # 데이터 변수들이 미리정의된 predictors 조합 확인 for combo in itertools.combinations(predictors, len(predictors) - 1): results.append(processSubset(X=X, y= y,feature_set=list(combo)+['const'])) models = pd.DataFrame(results) # 가장 낮은 AIC를 가진 모델을 선택 best_model = models.loc[models['AIC'].argmin()] toc = time.time() print(\"Processed \", models.shape[0], \"models on\", len(predictors) - 1, \"predictors in\", (toc - tic)) print('Selected predictors:',best_model['model'].model.exog_names,' AIC:',best_model[0] ) return best_model def backward_model(X, y): Bmodels = pd.DataFrame(columns=[\"AIC\", \"model\"], index = range(1,len(X.columns))) tic = time.time() predictors = X.columns.difference(['const']) Bmodel_before = processSubset(X,y,predictors)['AIC'] while (len(predictors) \u003e 1): Backward_result = backward(X=train_x, y= train_y, predictors = predictors) if Backward_result['AIC'] \u003e Bmodel_before: break Bmodels.loc[len(predictors) - 1] = Backward_result predictors = Bmodels.loc[len(predictors) - 1][\"model\"].model.exog_names Bmodel_before = Backward_result['AIC'] predictors = [ k for k in predictors if k != 'const'] toc = time.time() print(\"Total elapsed time:\", (toc - tic), \"seconds.\") return (Bmodels['model'].dropna().iloc[0]) ''' 단계적 선택법 ''' def Stepwise_model(X,y): Stepmodels = pd.DataFrame(columns=[\"AIC\", \"model\"]) tic = time.time() predictors = [] Smodel_before = processSubset(X,y,predictors+['const'])['AIC'] # 변수 1~10개 : 0~9 -\u003e 1~10 for i in range(1, len(X.columns.difference(['const'])) + 1): Forward_result = forward(X=X, y=y, predictors=predictors) # constant added print('forward') Stepmodels.loc[i] = Forward_result predictors = Stepmodels.loc[i][\"model\"].model.exog_names predictors = [ k for k in predictors if k != 'const'] Backward_result = backward(X=X, y=y, predictors=predictors) if Backward_result['AIC']\u003c Forward_result['AIC']: Stepmodels.loc[i] = Backward_result predictors = Stepmodels.loc[i][\"model\"].model.exog_names Smodel_before = Stepmodels.loc[i][\"AIC\"] predictors = [ k for k in predictors if k != 'const'] print('backward') if Stepmodels.loc[i]['AIC']\u003e Smodel_before: break else: Smodel_before = Stepmodels.loc[i][\"AIC\"] toc = time.time() print(\"Total elapsed time:\", (toc - tic), \"seconds.\") return (Stepmodels['model'][len(Stepmodels['model'])])   1  Forward_best_model = forward_model(X=train_x, y= train_y)   1  Backward_best_model = backward_model(X=train_x,y=train_y)   1  Stepwise_best_model = Stepwise_model(X=train_x,y=train_y)   Total elapsed time: 0.9743940830230713 seconds.  1 2 3 4  pred_y_full = results2.predict(test_x2) # full model pred_y_forward = Forward_best_model.predict(test_x[Forward_best_model.model.exog_names]) pred_y_backward = Backward_best_model.predict(test_x[Backward_best_model.model.exog_names]) pred_y_stepwise = Stepwise_best_model.predict(test_x[Stepwise_best_model.model.exog_names])   1 2 3 4  pred_Y_full= cut_off(pred_y_full,0.5) pred_Y_forward = cut_off(pred_y_forward,0.5) pred_Y_backward = cut_off(pred_y_backward,0.5) pred_Y_stepwise = cut_off(pred_y_stepwise,0.5)   1 2 3 4  cfmat_full = confusion_matrix(test_y, pred_Y_full) cfmat_forward = confusion_matrix(test_y, pred_Y_forward) cfmat_backward = confusion_matrix(test_y, pred_Y_backward) cfmat_stepwise = confusion_matrix(test_y, pred_Y_stepwise)   1 2 3 4 5  print(acc(cfmat_full)) print(acc(cfmat_forward)) print(acc(cfmat_backward)) print(acc(cfmat_stepwise))   0.944 0.944 0.944 0.944  1 2 3 4 5 6  fpr, tpr, thresholds = metrics.roc_curve(test_y, pred_y_full, pos_label=1) # Print ROC curve plt.plot(fpr,tpr) # Print AUC auc = np.trapz(tpr,fpr) print('AUC:', auc)   AUC: 0.9465467667547905  1 2 3 4 5 6  fpr, tpr, thresholds = metrics.roc_curve(test_y, pred_y_forward, pos_label=1) # Print ROC curve plt.plot(fpr,tpr) # Print AUC auc = np.trapz(tpr,fpr) print('AUC:', auc)   AUC: 0.9465467667547905  1 2 3 4 5 6  fpr, tpr, thresholds = metrics.roc_curve(test_y, pred_y_backward, pos_label=1) # Print ROC curve plt.plot(fpr,tpr) # Print AUC auc = np.trapz(tpr,fpr) print('AUC:', auc)   AUC: 0.9465467667547905  1 2 3 4 5 6  fpr, tpr, thresholds = metrics.roc_curve(test_y, pred_y_stepwise, pos_label=1) # Print ROC curve plt.plot(fpr,tpr) # Print AUC auc = np.trapz(tpr,fpr) print('AUC:', auc)   AUC: 0.9465467667547905  1  ###성능면에서는 네 모델이 큰 차이가 없음   Lasso \u0026 RIdge 1  from sklearn.linear_model import Ridge, Lasso, ElasticNet   1 2 3 4 5 6 7 8 9  ploan_processed = ploan.dropna().drop(['ID','ZIP Code'], axis=1, inplace=False) feature_columns = list(ploan_processed.columns.difference([\"Personal Loan\"])) X = ploan_processed[feature_columns] y = ploan_processed['Personal Loan'] # 대출여부: 1 or 0 train_x, test_x, train_y, test_y = train_test_split(X, y, stratify=y,train_size=0.7,test_size=0.3,random_state=42) print(train_x.shape, test_x.shape, train_y.shape, test_y.shape)   (1750, 11) (750, 11) (1750,) (750,)  1 2 3  ll =Lasso(alpha=0.01) ## lasso ll.fit(train_x,train_y)   Lasso(alpha=0.01, copy_X=True, fit_intercept=True, max_iter=1000, normalize=False, positive=False, precompute=False, random_state=None, selection='cyclic', tol=0.0001, warm_start=False)  1  ll.coef_   array([ 0.00000000e+00, 2.04783983e-03, 1.14390390e-01, -0.00000000e+00, 6.58342418e-02, 4.76625359e-04, 3.13396711e-02, 3.55393865e-03, 1.31719530e-05, 0.00000000e+00, -0.00000000e+00])  1  results.summary()   Logit Regression Results  Dep. Variable: Personal Loan  No. Observations:   1750   Model: Logit  Df Residuals:   1738   Method: MLE  Df Model:   11   Date: Fri, 23 Aug 2019  Pseudo R-squ.:  0.6030   Time: 14:58:38  Log-Likelihood:   -229.35   converged: True  LL-Null:   -577.63        LLR p-value:  2.927e-142     coef std err z P|z| [0.025 0.975]   Age  0.0245  0.102  0.240  0.810  -0.175  0.224   CCAvg  0.0985  0.063  1.562  0.118  -0.025  0.222   CD Account  4.3726  0.568  7.703  0.000  3.260  5.485   CreditCard  -1.2374  0.337  -3.667  0.000  -1.899  -0.576   Education  1.5203  0.190  7.999  0.000  1.148  1.893   Experience  -0.0070  0.102  -0.069  0.945  -0.206  0.192   Family  0.7579  0.128  5.914  0.000  0.507  1.009   Income  0.0547  0.004  12.659  0.000  0.046  0.063   Mortgage  -0.0001  0.001  -0.144  0.885  -0.002  0.002   Online  -0.4407  0.263  -1.674  0.094  -0.957  0.075   Securities Account  -1.8520  0.561  -3.299  0.001  -2.952  -0.752   const  -13.9203  2.773  -5.021  0.000  -19.354  -8.486   1 2 3 4 5  pred_y_lasso = ll.predict(test_x) # full model pred_Y_lasso= cut_off(pred_y_lasso,0.5) cfmat = confusion_matrix(test_y, pred_Y_lasso) print(acc(cfmat))   0.936  1 2 3 4 5 6  fpr, tpr, thresholds = metrics.roc_curve(test_y, pred_y_lasso, pos_label=1) # Print ROC curve plt.plot(fpr,tpr) # Print AUC auc = np.trapz(tpr,fpr) print('AUC:', auc)   AUC: 0.9439995368672932  1 2 3  rr =Ridge(alpha=0.01) ## lasso rr.fit(train_x,train_y)   Ridge(alpha=0.01, copy_X=True, fit_intercept=True, max_iter=None, normalize=False, random_state=None, solver='auto', tol=0.001)  1  rr.coef_ ## ridge result   array([-3.71283678e-03, 7.37570775e-03, 3.54973975e-01, -5.28579506e-02, 7.83404224e-02, 4.12823466e-03, 3.62504712e-02, 3.27385112e-03, 1.73105480e-06, -1.91297381e-02, -8.77388670e-02])  1  ll.coef_ ## lasso result   array([ 0.00000000e+00, 2.04783983e-03, 1.14390390e-01, -0.00000000e+00, 6.58342418e-02, 4.76625359e-04, 3.13396711e-02, 3.55393865e-03, 1.31719530e-05, 0.00000000e+00, -0.00000000e+00])  1 2 3 4 5  pred_y_ridge = rr.predict(test_x) # full model pred_Y_ridge= cut_off(pred_y_ridge,0.5) cfmat = confusion_matrix(test_y, pred_Y_lasso) print(acc(cfmat))   0.936  1 2 3 4 5 6  fpr, tpr, thresholds = metrics.roc_curve(test_y, pred_y_ridge, pos_label=1) # Print ROC curve plt.plot(fpr,tpr) # Print AUC auc = np.trapz(tpr,fpr) print('AUC:', auc)   AUC: 0.9494992377607533  1 2  alpha = np.logspace(-3, 1, 5) alpha   array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01])  1 2 3 4 5 6 7 8 9 10 11 12 13 14  data = [] acc_table=[] for i, a in enumerate(alpha): lasso = Lasso(alpha=a).fit(train_x, train_y) data.append(pd.Series(np.hstack([lasso.intercept_, lasso.coef_]))) pred_y = lasso.predict(test_x) # full model pred_y= cut_off(pred_y,0.5) cfmat = confusion_matrix(test_y, pred_y) acc_table.append((acc(cfmat))) df_lasso = pd.DataFrame(data, index=alpha).T df_lasso acc_table_lasso = pd.DataFrame(acc_table, index=alpha).T   1  df_lasso    .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right;  1  acc_table_lasso    .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; }  \n  0.001 0.01 0.1 1.0 10.0     0 0.932 0.936 0.894667 0.897333 0.897333     1 2 3 4 5 6 7 8 9 10 11 12 13  data = [] acc_table=[] for i, a in enumerate(alpha): ridge = Ridge(alpha=a).fit(train_x, train_y) data.append(pd.Series(np.hstack([ridge.intercept_, ridge.coef_]))) pred_y = ridge.predict(test_x) # full model pred_y= cut_off(pred_y,0.5) cfmat = confusion_matrix(test_y, pred_y) acc_table.append((acc(cfmat))) df_ridge = pd.DataFrame(data, index=alpha).T acc_table_ridge = pd.DataFrame(acc_table, index=alpha).T   1  df_ridge    .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; }  \n  0.001 0.01 0.1 1.0 10.0     0 -0.289557 -0.289565 -0.289645 -0.290438 -0.297581   1 -0.003713 -0.003713 -0.003713 -0.003716 -0.003723   2 0.007376 0.007376 0.007376 0.007378 0.007388   3 0.355019 0.354974 0.354529 0.350141 0.311781   4 -0.052866 -0.052858 -0.052782 -0.052037 -0.045541   5 0.078340 0.078340 0.078341 0.078347 0.078316   6 0.004128 0.004128 0.004129 0.004136 0.004175   7 0.036250 0.036250 0.036254 0.036289 0.036578   8 0.003274 0.003274 0.003274 0.003278 0.003313   9 0.000002 0.000002 0.000002 0.000002 0.000004   10 -0.019134 -0.019130 -0.019086 -0.018655 -0.014925   11 -0.087756 -0.087739 -0.087569 -0.085897 -0.071545     1  acc_table_ridge    .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; }  \n  0.001 0.01 0.1 1.0 10.0     0 0.932 0.932 0.932 0.932 0.932     labmda값의 변화에 따른 회귀계수 축소 시각화 1 2 3 4 5 6 7 8 9 10 11  import matplotlib.pyplot as plt ax1 = plt.subplot(121) plt.semilogx(df_ridge.T) plt.xticks(alpha) ax2 = plt.subplot(122) plt.semilogx(df_lasso.T) plt.xticks(alpha) plt.title(\"Lasso\") plt.show()   ","description":"","tags":null,"title":"변수 선택법, 회귀 계수 축소","uri":"/posts/data_science/machine_learning/regress_variable/"},{"categories":["Data_Science","Machine_Learning"],"content":"1 2  from sklearn import datasets from sklearn.decomposition import PCA   ` PCA 함수를 활용하여 PC를 얻어냄. 아래의 경우 PC 2개를 뽑아냄.\n1 2  pca=PCA(n_components=2) pca.fit(X)   PCA(copy=True, iterated_power='auto', n_components=2, random_state=None, svd_solver='auto', tol=0.0, whiten=False)   아래와 같이 PC score를 얻어냄. 아래의 PC score를 이용하여, 회귀분석에 활용할 수 있음.  1 2  PCscore=pca.transform(X) PCscore[0:5]   array([[-2.4608061 , -0.24553253], [-2.53956302, -0.06169198], [-2.71024021, 0.08277011], [-2.56577812, 0.2534473 ], [-2.50018456, -0.15361226]])  1 2  eigens_v=pca.components_.transpose() print(eigens_v)   [[ 0.39378459 -0.91920275] [ 0.91920275 0.39378459]]  1 2 3 4  mX=np.matrix(X) for i in range(X.shape[1]): mX[:,i]=mX[:,i]-np.mean(X[:,i]) dfmX=pd.DataFrame(mX)   1  (mX*eigens_v)[0:5]   matrix([[-2.4608061 , -0.24553253], [-2.53956302, -0.06169198], [-2.71024021, 0.08277011], [-2.56577812, 0.2534473 ], [-2.50018456, -0.15361226]])  1 2 3 4  plt.scatter(dfmX[0],dfmX[1]) origin = [0], [0] # origin point plt.quiver(*origin, eigens_v[0,:], eigens_v[1,:], color=['r','b'], scale=3) plt.show()   PC를 활용한 회귀분석  이번에는 모든 독립변수를 활용하여 PC를 뽑아냄.  1 2 3  X2 = iris.data pca2 = PCA(n_components=4) pca2.fit(X2)   PCA(copy=True, iterated_power='auto', n_components=4, random_state=None, svd_solver='auto', tol=0.0, whiten=False)  1  pca2.explained_variance_   array([ 4.19667516, 0.24062861, 0.07800042, 0.02352514])  1  PCs=pca2.transform(X2)[:,0:2]   1 2  from sklearn.linear_model import LogisticRegression from sklearn.metrics import confusion_matrix    모델의 복잡성으로 인하여 기존 자료를 이용한 분석은 수렴하지 않는 모습.  1  clf = LogisticRegression(solver=\"sag\",multi_class=\"multinomial\").fit(X2,y)   d:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\sag.py:286: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge \"the coef_ did not converge\", ConvergenceWarning)   PC 2개 만을 뽑아내여 분석한 경우 모델이 수렴.  1  clf2 = LogisticRegression(solver=\"sag\",multi_class=\"multinomial\").fit(PCs,y)   1  confusion_matrix(y,clf2.predict(PCs))   array([[50, 0, 0], [ 0, 47, 3], [ 0, 2, 48]])   임의로 변수 2개 만을 뽑아내여 분석한 경우 모델의 퍼포먼스가 하락함.  1 2  clf = LogisticRegression(solver='sag', max_iter=1000, random_state=0, multi_class=\"multinomial\").fit(X2[:,0:2], y)   1  confusion_matrix(y, clf.predict(X2[:,0:2]))   array([[50, 0, 0], [ 0, 37, 13], [ 0, 14, 36]])   위와 같이, 차원축소를 통하여 모델의 복잡성을 줄이는 동시에 최대한 많은 정보를 활용하여 분석할 수 있음.  ","description":"","tags":null,"title":"PCA","uri":"/posts/data_science/machine_learning/pca/"},{"categories":["Data_Science","Text_mining"],"content":"자연어 처리 konply : 한국어 처리 scikit-learn - feature_extraction.text : 문서 전처리\napply review 데이터와 사전 데이터 가져오기 1 2 3 4 5 6 7 8 9 10 11 12  k = [] with open('data/영화 기생충_review.txt','r') as f: for _ in f.readlines(): k.append(_.split('\\n')[0]) d= [] with open('data/영화 기생충_사전.txt','r') as g: for _ in g.readlines(): d.append(_.split('\\n')[0]) data = pd.Series(k) data.head()   0 별1개 준 사람들은 나베당임 1 역쉬 2 영화가 끝나고 가슴이 먹먹하고 답답햇습니다 너무나 충격적이었습니다.. 3 지금까지 나온 감독의 모든 작품이 압축되어있다는 느낌을 받음. Bomb!!! 4 대단한 영화. 몰입력 장난아님. 후아 dtype: object  1 2  from string import punctuation punctuation   '!\"#$%\u0026\\'()*+,-./:;\u003c=\u003e?@[\\\\]^_`{|}~'  1 2 3 4 5 6  import re data = data.str.lower() # 소문자 data = data.str.replace(r'[0-9]','') # 숫자 제거 data = data.str.replace('[' + punctuation + ']','') # 구두점 제거 data = data.str.strip() data.head()   0 별개 준 사람들은 나베당임 1 역쉬 2 영화가 끝나고 가슴이 먹먹하고 답답햇습니다 너무나 충격적이었습니다 3 지금까지 나온 감독의 모든 작품이 압축되어있다는 느낌을 받음 bomb 4 대단한 영화 몰입력 장난아님 후아 dtype: object  1 2 3  from sklearn.feature_extraction.text import CountVectorizer cv = CountVectorizer(max_features=1000) tdm = cv.fit_transform(data)   1 2 3  from konlpy.tag import Okt ma = Okt().nouns(' '.join([_ for _ in data])) ok = Okt().pos(' '.join([_ for _ in data]))   1 2 3 4 5 6 7  # 동사, 명사, 형용사 뽑기 list = [] for du in ok: if du[1] in ['Noun','Verb','Adjective']: list.append(du[0]) list   series로 바꾸고 value_counts로 개수 세기\n1 2 3 4 5 6 7 8 9 10 11 12 13  from sklearn.feature_extraction.text import CountVectorizer docs = ['why hello there', 'omg hello pony', 'she went there? omg'] vec = CountVectorizer() X = vec.fit_transform(data) df = pd.DataFrame(X.toarray(), columns=vec.get_feature_names()) df1 = df.sum(axis=0) ```python df2 = df1[df1.index.isin(d)] df2   기생충 17 기정 1 박사장 1 박소담 2 봉준호 78 송강호 29 이선균 10 이정은 3 장혜진 1 조여정 10 최우식 4 dtype: int64  1  '|'.join([_ for _ in d])   '기생충봉준호송강호기택이선균박사장조여정연교최우식기우박소담기정장혜진충숙이정은이지혜박서준'  1 2 3 4  from wordcloud import WordCloud import matplotlib.pyplot as plt wordcloud = WordCloud(font_path='font/NanumGothic.ttf', background_color='white').generate(' '.join([_ for _ in data])) plt.imshow(wordcloud, interpolation='bilinear')   1 2 3 4  from wordcloud import STOPWORDS wordcloud = WordCloud(font_path='font/NanumGothic.ttf', background_color='white').generate_from_frequencies(df2.to_dict()) plt.imshow(wordcloud, interpolation='bilinear') # 외국어면 stopwords = STOPWORDS 설정, countvector에서도 설정 가능    tfidf\n1 2 3 4 5 6 7 8 9  from sklearn.feature_extraction.text import TfidfVectorizer corpus = [ 'you know I want your love', 'I like you', 'what should I do', ] tfidfv = TfidfVectorizer().fit(corpus) print(tfidfv.transform(corpus).toarray()) print(tfidfv.vocabulary_)   [[0. 0.46735098 0. 0.46735098 0. 0.46735098 0. 0.35543247 0.46735098] [0. 0. 0.79596054 0. 0. 0. 0. 0.60534851 0. ] [0.57735027 0. 0. 0. 0.57735027 0. 0.57735027 0. 0. ]] {'you': 7, 'know': 1, 'want': 5, 'your': 8, 'love': 3, 'like': 2, 'what': 6, 'should': 4, 'do': 0}   영어\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  word_tokens = nltk.word_tokenize(cleaned_content) tokens_pos = nltk.pos_tag(word_tokens) NN_words = [] for word, pos in tokens_pos: if 'NN' in pos: NN_words.append(word) # 형용사 RB, 동사 VB for word in unique_NN_words: if word in stopwords_list: while word in final_NN_words: final_NN_words.remove(word) # 빈도 from collections import Counter c = Counter(final_NN_words) # input type should be a list of words (or tokens) print(c) k = 20 print(c.most_common(k)) # 빈도수 기준 상위 k개 단어 출력   ","description":"","tags":null,"title":"Text mining","uri":"/posts/data_science/text_mining/text/"},{"categories":["Data_Science","Text_mining"],"content":"1. 정규표현식(re) 에 대한 이해 및 숙지  정규표현식   regular expression 특정한 패턴과 일치하는 문자열를 ‘검색’, ‘치환’, ‘제거’ 하는 기능을 지원 정규표현식의 도움없이 패턴을 찾는 작업(Rule 기반)은 불완전 하거나, 작업의 cost가 높음 e.g) 이메일 형식 판별, 전화번호 형식 판별, 숫자로만 이루어진 문자열 등   raw string   문자열 앞에 r이 붙으면 해당 문자열이 구성된 그대로 문자열로 변환  `기본 패턴\n  a, X, 9 등등 문자 하나하나의 character들은 정확히 해당 문자와 일치\n e.g) 패턴 test는 test 문자열과 일치 대소문자의 경우 기본적으로 구별하나, 구별하지 않도록 설정 가능    몇몇 문자들에 대해서는 예외가 존재하는데, 이들은 틀별한 의미로 사용 됨\n . ^ $ * + ? { } \\ | ( )    . (마침표) - 어떤 한개의 character와 일치 (newline(엔터) 제외)\n  \\w - 문자 character와 일치 [a-zA-Z0-9_]\n  \\s - 공백문자와 일치\n  \\t, \\n, \\r - tab, newline, return\n  \\d - 숫자 character와 일치 [0-9]\n  ^ = 시작, $ = 끝 각각 문자열의 시작과 끝을 의미\n  \\가 붙으면 스페셜한 의미가 없어짐. 예를들어 \\.는 .자체를 의미 \\\\는 \\를 의미\n  자세한 내용은 링크 참조 https://docs.python.org/3/library/re.html\n  search method  첫번째로 패턴을 찾으면 match 객체를 반환 패턴을 찾지 못하면 None 반환  1  import re   1 2  m = re.search(r'abc', '123abdef') m   1 2  m = re.search(r'\\d\\d\\d\\w', '112abcdef119') m   \u003cre.Match object; span=(0, 4), match='112a'\u003e  1 2  m = re.search(r'..\\w\\w', '@#$%ABCDabcd') m   \u003cre.Match object; span=(2, 6), match='$%AB'\u003e  metacharacters (메타 캐릭터) [] 문자들의 범위를 나타내기 위해 사용  [] 내부의 메타 캐릭터는 캐릭터 자체를 나타냄 e.g) [abck] : a or b or c or k [abc.^] : a or b or c or . or ^ [a-d] : -와 함께 사용되면 해당 문자 사이의 범위에 속하는 문자 중 하나 [0-9] : 모든 숫자 [a-z] : 모든 소문자 [A-Z] : 모든 대문자 [a-zA-Z0-9] : 모든 알파벳 문자 및 숫자 [^0-9] : ^가 맨 앞에 사용 되는 경우 해당 문자 패턴이 아닌 것과 매칭  1  re.search(r'[cbm]at', 'aat')   1  re.search(r'[0-4]haha', '7hahah')   1  re.search(r'[abc.^]aron', 'daron')   1  re.search(r'[^abc]aron', '0aron')   \u003cre.Match object; span=(0, 5), match='0aron'\u003e  \\  다른 문자와 함께 사용되어 특수한 의미를 지님   \\d : 숫자를 [0-9]와 동일 \\D : 숫자가 아닌 문자 [^0-9]와 동일 \\s : 공백 문자(띄어쓰기, 탭, 엔터 등) \\S : 공백이 아닌 문자 \\w : 알파벳대소문자, 숫자 [0-9a-zA-Z]와 동일 \\W : non alpha-numeric 문자 [^0-9a-zA-Z]와 동일  메타 캐릭터가 캐릭터 자체를 표현하도록 할 경우 사용   \\. , \\\\  1  re.search(r'\\Sand', 'apple land banana')   \u003cre.Match object; span=(6, 10), match='land'\u003e  1  re.search(r'\\.and', '.and')   \u003cre.Match object; span=(0, 4), match='.and'\u003e  .  모든 문자를 의미  1  re.search(r'p.g', 'pig')   \u003cre.Match object; span=(0, 3), match='pig'\u003e  반복패턴  패턴 뒤에 위치하는 *, +, ?는 해당 패턴이 반복적으로 존재하는지 검사  ‘+’ -\u003e 1번 이상의 패턴이 발생 ‘*’ -\u003e 0번 이상의 패턴이 발생 ‘?’ -\u003e 0 혹은 1번의 패턴이 발생   반복을 패턴의 경우 greedy하게 검색 함, 즉 가능한 많은 부분이 매칭되도록 함 e.g) a[bcd]*b 패턴을 abcbdccb에서 검색하는 경우  ab, abcb, abcbdccb 전부 가능 하지만 최대한 많은 부분이 매칭된 abcbdccb가 검색된 패턴    1  re.search(r'a[bcd]*b', 'abcbdccb')   \u003cre.Match object; span=(0, 8), match='abcbdccb'\u003e  1  re.search(r'b\\w+a', 'banana')   \u003cre.Match object; span=(0, 6), match='banana'\u003e  1  re.search(r'i+', 'piigiii')   \u003cre.Match object; span=(1, 3), match='ii'\u003e  1  re.search(r'pi+g', 'pg')   1  re.search(r'pi*g', 'pg')   \u003cre.Match object; span=(0, 2), match='pg'\u003e  1  re.search(r'https?', 'http://www.naver.com')   \u003cre.Match object; span=(0, 4), match='http'\u003e  ^, $  ^ 문자열의 맨 앞부터 일치하는 경우 검색 $ 문자열의 맨 뒤부터 일치하는 경우 검색  1  re.search(r'b\\w+a', 'cabana')   \u003cre.Match object; span=(2, 6), match='bana'\u003e  1  re.search(r'^b\\w+a', 'cabana')   1  re.search(r'^b\\w+a', 'babana')   \u003cre.Match object; span=(0, 6), match='babana'\u003e  1  re.search(r'b\\w+a$', 'cabana')   \u003cre.Match object; span=(2, 6), match='bana'\u003e  1  re.search(r'b\\w+a$', 'cabanap')   grouping  ()을 사용하여 그루핑 매칭 결과를 각 그룹별로 분리 가능 패턴 명시 할 때, 각 그룹을 괄호() 안에 넣어 분리하여 사용  1 2 3 4  m = re.search(r'(\\w+)@(.+)', 'test@gmail.com') print(m.group(1)) print(m.group(2)) print(m.group(0))   test gmail.com test@gmail.com  {}  *, +, ?을 사용하여 반복적인 패턴을 찾는 것이 가능하나, 반복의 횟수 제한은 불가 패턴뒤에 위치하는 중괄호{}에 숫자를 명시하면 해당 숫자 만큼의 반복인 경우에만 매칭 {4} - 4번 반복 {3,4} - 3 ~ 4번 반복  1  re.search('pi{3,5}g', 'piiiiig')   \u003cre.Match object; span=(0, 7), match='piiiiig'\u003e  미니멈 매칭(non-greedy way)  기본적으로 *, +, ?를 사용하면 greedy(맥시멈 매칭)하게 동작함 *?, +?을 이용하여 해당 기능을 구현  1  re.search(r'\u003c.+\u003e', '\u003chtml\u003ehaha\u003c/html\u003e')   \u003cre.Match object; span=(0, 17), match='\u003chtml\u003ehaha\u003c/html\u003e'\u003e  1  re.search(r'\u003c.+?\u003e', '\u003chtml\u003ehaha\u003c/html\u003e')   \u003cre.Match object; span=(0, 6), match='\u003chtml\u003e'\u003e  {}?  {m,n}의 경우 m번 에서 n번 반복하나 greedy하게 동작 {m,n}?로 사용하면 non-greedy하게 동작. 즉, 최소 m번만 매칭하면 만족  1  re.search(r'a{3,5}', 'aaaaa')   \u003cre.Match object; span=(0, 5), match='aaaaa'\u003e  1  re.search(r'a{3,5}?', 'aaaaa')   \u003cre.Match object; span=(0, 3), match='aaa'\u003e  match  search와 유사하나, 주어진 문자열의 시작부터 비교하여 패턴이 있는지 확인 시작부터 해당 패턴이 존재하지 않다면 None 반환  1  re.match(r'\\d\\d\\d', 'my number is 123')   1  re.match(r'\\d\\d\\d', '123 is my number')   \u003cre.Match object; span=(0, 3), match='123'\u003e  1  re.search(r'^\\d\\d\\d', '123 is my number')   \u003cre.Match object; span=(0, 3), match='123'\u003e  findall  search가 최초로 매칭되는 패턴만 반환한다면, findall은 매칭되는 전체의 패턴을 반환 매칭되는 모든 결과를 리스트 형태로 반환  1  re.findall(r'[\\w-]+@[\\w.]+', 'test@gmail.com haha test2@gmail.com nice test test')   ['test@gmail.com', 'test2@gmail.com']  sub  주어진 문자열에서 일치하는 모든 패턴을 replace 그 결과를 문자열로 다시 반환함 두번째 인자는 특정 문자열이 될 수도 있고, 함수가 될 수 도 있음 count가 0인 경우는 전체를, 1이상이면 해당 숫자만큼 치환 됨  1  re.sub(r'[\\w-]+@[\\w.]+', 'great', 'test@gmail.com haha test2@gmail.com nice test test', count=1)   'great haha test2@gmail.com nice test test'  compile  동일한 정규표현식을 매번 다시 쓰기 번거로움을 해결 compile로 해당표현식을 re.RegexObject 객체로 저장하여 사용가능  1 2 3  email_reg = re.compile(r'[\\w-]+@[\\w.]+') email_reg.search('test@gmail.com haha good') # email_reg.findall()   \u003cre.Match object; span=(0, 14), match='test@gmail.com'\u003e  연습문제  아래 뉴스에서 이메일 주소를 추출해 보세요 다음중 올바른 (http, https) 웹페이지만 찾으시오  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  import requests from bs4 import BeautifulSoup # 위의 두 모듈이 없는 경우에는 pip install requests bs4 실행 def get_news_content(url): response = requests.get(url) content = response.text soup = BeautifulSoup(content, 'html5lib') div = soup.find('div', attrs = {'id' : 'harmonyContainer'}) content = '' for paragraph in div.find_all('p'): content += paragraph.get_text() return content news1 = get_news_content('https://news.v.daum.net/v/20190617073049838') print(news1)   (로스앤젤레스=연합뉴스) 옥철 특파원 = 팀 쿡 애플 최고경영자(CEO)가 16일(현지시간) 실리콘밸리 앞마당 격인 미국 서부 명문 스탠퍼드대학 학위수여식에서 테크기업들을 향해 쓴소리를 쏟아냈다.쿡은 이날 연설에서 실리콘밸리 테크기업들은 자신들이 만든 혼란에 대한 책임을 질 필요가 있다고 경고했다.근래 IT 업계의 가장 큰 이슈인 개인정보 침해, 사생활 보호 문제를 콕 집어 라이벌인 구글, 페이스북 등 IT 공룡을 겨냥한 발언이라는 해석이 나왔다.쿡은 \"최근 실리콘밸리 산업은 고귀한 혁신과는 점점 더 거리가 멀어지는 것으로 알려져 있다. 책임을 받아들이지 않고도 신뢰를 얻을 수 있다는 그런 믿음 말이다\"라고 꼬집었다.개인정보 유출 사건으로 미 의회 청문회에 줄줄이 불려 나간 경쟁사 CEO들을 향해 일침을 가한 것으로 보인다.그는 또 실리콘밸리에서 희대의 사기극을 연출한 바이오벤처 스타트업 테라노스(Theranos)를 직격했다.쿡은 \"피 한 방울로 거짓된 기적을 만들 수 있다고 믿었느냐\"면서 \"이런 식으로 혼돈의 공장을 만든다면 그 책임에서 절대 벗어날 수 없다\"라고 비난했다.테라노스는 손가락 끝을 찔러 극미량의 혈액 샘플만 있으면 각종 의학정보 분석은 물론 거의 모든 질병 진단이 가능한 바이오헬스 기술을 개발했다고 속여 월가 큰손들로부터 거액의 투자를 유치했다가 해당 기술이 사기인 것으로 드러나 청산한 기업이다.쿡은 애플의 경우 프라이버시(사생활) 보호에 초점을 맞춘 새로운 제품 기능들로 경쟁사들에 맞서고 있다며 자사의 데이터 보호 정책을 은근히 홍보하기도 했다.oakchul@yna.co.kr저작권자(c)연합뉴스. 무단전재-재배포금지  1 2  email_reg = re.compile(r'[\\w-]+@[\\w.]+\\w+') email_reg.search(news1)   \u003cre.Match object; span=(774, 795), match='oakchul@yna.co.kr저작권자'\u003e  1 2 3 4 5 6 7 8 9  webs = ['http://www.test.co.kr', 'https://www.test1.com', 'http://www.test.com', 'ftp://www.test.com', 'http:://www.test.com', 'htp://www.test.com', 'http://www.google.com', 'https://www.homepage.com.']   1 2  web_reg = re.compile(r'https?://[\\w.]+\\w+$') list(map(lambda w:web_reg.search(w) != None, webs))   [True, True, True, False, False, False, True, False]  ","description":"","tags":null,"title":"정규 표현식","uri":"/posts/data_science/text_mining/re/"},{"categories":["Data_Science","Machine_Learning"],"content":"`Randomforest의 데이터 활용\n1 2 3 4 5  feature_columns = list(data.columns.difference(['target'])) X = data[feature_columns] y = after_mapping_target train_x, test_x, train_y, test_y = train_test_split(X, y, test_size = 0.2, random_state = 42) print(train_x.shape, test_x.shape, train_y.shape, test_y.shape)   (49502, 93) (12376, 93) (49502,) (12376,)  1. XGBoost 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  # !pip install xgboost import xgboost as xgb import time start = time.time() xgb_dtrain = xgb.DMatrix(data = train_x, label = train_y) # 학습 데이터를 XGBoost 모델에 맞게 변환 xgb_dtest = xgb.DMatrix(data = test_x) # 평가 데이터를 XGBoost 모델에 맞게 변환 xgb_param = {'max_depth': 10, # 트리 깊이 'learning_rate': 0.01, # Step Size 'n_estimators': 100, # Number of trees, 트리 생성 개수 'objective': 'multi:softmax', # 목적 함수 'num_class': len(set(train_y)) + 1} # 파라미터 추가, Label must be in [0, num_class) -\u003e num_class보다 1 커야한다. xgb_model = xgb.train(params = xgb_param, dtrain = xgb_dtrain) # 학습 진행 xgb_model_predict = xgb_model.predict(xgb_dtest) # 평가 데이터 예측 print(\"Accuracy: %.2f\" % (accuracy_score(test_y, xgb_model_predict) * 100), \"%\") # 정확도 % 계산 print(\"Time: %.2f\" % (time.time() - start), \"seconds\") # 코드 실행 시간 계산   Accuracy: 76.67 % Time: 6.35 seconds  1  xgb_model_predict   array([5., 3., 6., ..., 9., 2., 7.], dtype=float32)  2. LightGBM 1 2 3 4 5 6 7 8 9 10 11 12 13  # !pip install lightgbm import lightgbm as lgb start = time.time() # 시작 시간 지정 lgb_dtrain = lgb.Dataset(data = train_x, label = train_y) # 학습 데이터를 LightGBM 모델에 맞게 변환 lgb_param = {'max_depth': 10, # 트리 깊이 'learning_rate': 0.01, # Step Size 'n_estimators': 100, # Number of trees, 트리 생성 개수 'objective': 'multiclass', # 목적 함수 'num_class': len(set(train_y)) + 1} # 파라미터 추가, Label must be in [0, num_class) -\u003e num_class보다 1 커야한다. lgb_model = lgb.train(params = lgb_param, train_set = lgb_dtrain) # 학습 진행 lgb_model_predict = np.argmax(lgb_model.predict(test_x), axis = 1) # 평가 데이터 예측, Softmax의 결과값 중 가장 큰 값의 Label로 예측 print(\"Accuracy: %.2f\" % (accuracy_score(test_y, lgb_model_predict) * 100), \"%\") # 정확도 % 계산 print(\"Time: %.2f\" % (time.time() - start), \"seconds\") # 코드 실행 시간 계산   Accuracy: 73.57 % Time: 4.08 seconds  3. Catboost 1 2 3 4 5 6 7 8 9 10 11 12 13  # !pip install catboost import catboost as cb start = time.time() # 시작 시간 지정 cb_dtrain = cb.Pool(data = train_x, label = train_y) # 학습 데이터를 Catboost 모델에 맞게 변환 cb_param = {'max_depth': 10, # 트리 깊이 'learning_rate': 0.01, # Step Size 'n_estimators': 100, # Number of trees, 트리 생성 개수 'eval_metric': 'Accuracy', # 평가 척도 'loss_function': 'MultiClass'} # 손실 함수, 목적 함수 cb_model = cb.train(pool = cb_dtrain, params = cb_param) # 학습 진행 cb_model_predict = np.argmax(cb_model.predict(test_x), axis = 1) + 1 # 평가 데이터 예측, Softmax의 결과값 중 가장 큰 값의 Label로 예측, 인덱스의 순서를 맞추기 위해 +1 print(\"Accuracy: %.2f\" % (accuracy_score(test_y, cb_model_predict) * 100), \"%\") # 정확도 % 계산 print(\"Time: %.2f\" % (time.time() - start), \"seconds\") # 코드 실행 시간 계산   0:\tlearn: 0.6114702\ttotal: 412ms\tremaining: 40.8s 1:\tlearn: 0.6235304\ttotal: 760ms\tremaining: 37.2s 2:\tlearn: 0.6410246\ttotal: 1.12s\tremaining: 36.1s 3:\tlearn: 0.6410650\ttotal: 1.47s\tremaining: 35.3s 4:\tlearn: 0.6442770\ttotal: 1.81s\tremaining: 34.5s 5:\tlearn: 0.6455901\ttotal: 2.18s\tremaining: 34.1s 6:\tlearn: 0.6468224\ttotal: 2.55s\tremaining: 33.8s 7:\tlearn: 0.6484991\ttotal: 2.88s\tremaining: 33.2s 8:\tlearn: 0.6512666\ttotal: 3.23s\tremaining: 32.6s 9:\tlearn: 0.6491859\ttotal: 3.56s\tremaining: 32s 10:\tlearn: 0.6517716\ttotal: 3.9s\tremaining: 31.6s 11:\tlearn: 0.6526807\ttotal: 4.25s\tremaining: 31.2s 12:\tlearn: 0.6531655\ttotal: 4.59s\tremaining: 30.8s 13:\tlearn: 0.6537918\ttotal: 4.93s\tremaining: 30.3s 14:\tlearn: 0.6566603\ttotal: 5.25s\tremaining: 29.8s 15:\tlearn: 0.6563573\ttotal: 5.6s\tremaining: 29.4s 16:\tlearn: 0.6582966\ttotal: 5.93s\tremaining: 29s 17:\tlearn: 0.6591047\ttotal: 6.27s\tremaining: 28.6s 18:\tlearn: 0.6597309\ttotal: 6.62s\tremaining: 28.2s 19:\tlearn: 0.6603572\ttotal: 7s\tremaining: 28s 20:\tlearn: 0.6593067\ttotal: 7.38s\tremaining: 27.8s 21:\tlearn: 0.6603976\ttotal: 7.77s\tremaining: 27.5s 22:\tlearn: 0.6602966\ttotal: 8.13s\tremaining: 27.2s 23:\tlearn: 0.6606804\ttotal: 8.48s\tremaining: 26.8s 24:\tlearn: 0.6612258\ttotal: 8.85s\tremaining: 26.5s 25:\tlearn: 0.6604178\ttotal: 9.21s\tremaining: 26.2s 26:\tlearn: 0.6616702\ttotal: 9.57s\tremaining: 25.9s 27:\tlearn: 0.6636904\ttotal: 9.91s\tremaining: 25.5s 28:\tlearn: 0.6640540\ttotal: 10.3s\tremaining: 25.1s 29:\tlearn: 0.6648620\ttotal: 10.6s\tremaining: 24.7s 30:\tlearn: 0.6652660\ttotal: 10.9s\tremaining: 24.4s 31:\tlearn: 0.6653469\ttotal: 11.3s\tremaining: 24s 32:\tlearn: 0.6663165\ttotal: 11.6s\tremaining: 23.6s 33:\tlearn: 0.6674478\ttotal: 11.9s\tremaining: 23.2s 34:\tlearn: 0.6675084\ttotal: 12.3s\tremaining: 22.8s 35:\tlearn: 0.6675488\ttotal: 12.6s\tremaining: 22.4s 36:\tlearn: 0.6690033\ttotal: 12.9s\tremaining: 22s 37:\tlearn: 0.6692659\ttotal: 13.3s\tremaining: 21.7s 38:\tlearn: 0.6702759\ttotal: 13.6s\tremaining: 21.3s 39:\tlearn: 0.6704982\ttotal: 14s\tremaining: 20.9s 40:\tlearn: 0.6707608\ttotal: 14.3s\tremaining: 20.6s 41:\tlearn: 0.6712052\ttotal: 14.6s\tremaining: 20.2s 42:\tlearn: 0.6714274\ttotal: 15s\tremaining: 19.8s 43:\tlearn: 0.6715082\ttotal: 15.3s\tremaining: 19.5s 44:\tlearn: 0.6715890\ttotal: 15.6s\tremaining: 19.1s 45:\tlearn: 0.6718112\ttotal: 16s\tremaining: 18.7s 46:\tlearn: 0.6716900\ttotal: 16.3s\tremaining: 18.4s 47:\tlearn: 0.6719324\ttotal: 16.6s\tremaining: 18s 48:\tlearn: 0.6730839\ttotal: 17s\tremaining: 17.6s 49:\tlearn: 0.6735889\ttotal: 17.3s\tremaining: 17.3s 50:\tlearn: 0.6738314\ttotal: 17.6s\tremaining: 16.9s 51:\tlearn: 0.6740940\ttotal: 18s\tremaining: 16.6s 52:\tlearn: 0.6746192\ttotal: 18.3s\tremaining: 16.2s 53:\tlearn: 0.6750434\ttotal: 18.6s\tremaining: 15.9s 54:\tlearn: 0.6750636\ttotal: 19s\tremaining: 15.5s 55:\tlearn: 0.6753465\ttotal: 19.3s\tremaining: 15.2s 56:\tlearn: 0.6760939\ttotal: 19.6s\tremaining: 14.8s 57:\tlearn: 0.6768615\ttotal: 20s\tremaining: 14.5s 58:\tlearn: 0.6769019\ttotal: 20.3s\tremaining: 14.1s 59:\tlearn: 0.6777908\ttotal: 20.6s\tremaining: 13.8s 60:\tlearn: 0.6780534\ttotal: 21s\tremaining: 13.4s 61:\tlearn: 0.6791241\ttotal: 21.3s\tremaining: 13.1s 62:\tlearn: 0.6796089\ttotal: 21.7s\tremaining: 12.7s 63:\tlearn: 0.6798715\ttotal: 22s\tremaining: 12.4s 64:\tlearn: 0.6802351\ttotal: 22.3s\tremaining: 12s 65:\tlearn: 0.6805180\ttotal: 22.6s\tremaining: 11.7s 66:\tlearn: 0.6803361\ttotal: 23s\tremaining: 11.3s 67:\tlearn: 0.6812048\ttotal: 23.3s\tremaining: 11s 68:\tlearn: 0.6817906\ttotal: 23.6s\tremaining: 10.6s 69:\tlearn: 0.6819320\ttotal: 24s\tremaining: 10.3s 70:\tlearn: 0.6827805\ttotal: 24.3s\tremaining: 9.92s 71:\tlearn: 0.6829219\ttotal: 24.6s\tremaining: 9.58s 72:\tlearn: 0.6827401\ttotal: 25s\tremaining: 9.23s 73:\tlearn: 0.6831239\ttotal: 25.3s\tremaining: 8.89s 74:\tlearn: 0.6833057\ttotal: 25.6s\tremaining: 8.54s 75:\tlearn: 0.6841340\ttotal: 26s\tremaining: 8.2s 76:\tlearn: 0.6846390\ttotal: 26.3s\tremaining: 7.87s 77:\tlearn: 0.6854471\ttotal: 26.7s\tremaining: 7.53s 78:\tlearn: 0.6862551\ttotal: 27s\tremaining: 7.18s 79:\tlearn: 0.6872450\ttotal: 27.4s\tremaining: 6.84s 80:\tlearn: 0.6875278\ttotal: 27.7s\tremaining: 6.5s 81:\tlearn: 0.6883560\ttotal: 28s\tremaining: 6.15s 82:\tlearn: 0.6879722\ttotal: 28.4s\tremaining: 5.81s 83:\tlearn: 0.6887196\ttotal: 28.7s\tremaining: 5.47s 84:\tlearn: 0.6889419\ttotal: 29s\tremaining: 5.12s 85:\tlearn: 0.6893459\ttotal: 29.4s\tremaining: 4.78s 86:\tlearn: 0.6894671\ttotal: 29.7s\tremaining: 4.44s 87:\tlearn: 0.6896691\ttotal: 30s\tremaining: 4.09s 88:\tlearn: 0.6900327\ttotal: 30.4s\tremaining: 3.75s 89:\tlearn: 0.6903963\ttotal: 30.7s\tremaining: 3.41s 90:\tlearn: 0.6911236\ttotal: 31s\tremaining: 3.07s 91:\tlearn: 0.6913054\ttotal: 31.4s\tremaining: 2.73s 92:\tlearn: 0.6913458\ttotal: 31.7s\tremaining: 2.39s 93:\tlearn: 0.6919720\ttotal: 32s\tremaining: 2.04s 94:\tlearn: 0.6920326\ttotal: 32.4s\tremaining: 1.7s 95:\tlearn: 0.6926185\ttotal: 32.7s\tremaining: 1.36s 96:\tlearn: 0.6929619\ttotal: 33s\tremaining: 1.02s 97:\tlearn: 0.6932245\ttotal: 33.3s\tremaining: 681ms 98:\tlearn: 0.6937093\ttotal: 33.7s\tremaining: 340ms 99:\tlearn: 0.6940124\ttotal: 34s\tremaining: 0us Accuracy: 69.49 % Time: 34.71 seconds   Ensemble의 Ensemble 1 2 3 4 5 6 7 8 9 10 11 12 13 14  import random bagging_predict_result = [] # 빈 리스트 생성 for _ in range(10): data_index = [data_index for data_index in range(train_x.shape[0])] # 학습 데이터의 인덱스를 리스트로 변환 random_data_index = np.random.choice(data_index, train_x.shape[0]) # 데이터의 1/10 크기만큼 랜덤 샘플링, // 는 소수점을 무시하기 위함 print(len(set(random_data_index))) lgb_dtrain = lgb.Dataset(data = train_x.iloc[random_data_index,], label = train_y.iloc[random_data_index,]) # 학습 데이터를 LightGBM 모델에 맞게 변환 lgb_param = {'max_depth': 14, # 트리 깊이 'learning_rate': 0.01, # Step Size 'n_estimators': 500, # Number of trees, 트리 생성 개수 'objective': 'regression'} # 파라미터 추가, Label must be in [0, num_class) -\u003e num_class보다 1 커야한다. lgb_model = lgb.train(params = lgb_param, train_set = lgb_dtrain) # 학습 진행 predict1 = lgb_model.predict(test_x) # 테스트 데이터 예측 bagging_predict_result.append(predict1) # 반복문이 실행되기 전 빈 리스트에 결과 값 저장   9615 C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:118: UserWarning: Found `n_estimators` in params. Will use it instead of argument warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias)) 9602 9601 9563 9468 9509 9601 9571 9480 9640  1  bagging_predict_result   [array([ 531170.32964683, 610437.80671003, 935793.13124286, ..., 331964.44594363, 1009790.22112937, 451345.9132272 ]), array([495196.13568546, 646054.39267815, 986365.56528169, ..., 331252.38335085, 907530.55639732, 468913.77372686]), array([512873.63822953, 654969.90479597, 998836.27669227, ..., 327405.4302911 , 876943.02927024, 470934.42959936]), array([493825.84400474, 636737.39852681, 932594.32632075, ..., 346914.54108486, 897040.92609115, 464065.61545808]), array([ 498631.77754482, 607710.21423254, 1020882.76294162, ..., 335199.49778924, 936386.22238716, 424294.62431666]), array([506096.98682302, 669609.23719954, 940485.52597156, ..., 345055.0638638 , 918021.10680715, 463670.6100106 ]), array([547657.77823348, 642343.41762371, 915100.66250346, ..., 344643.67265125, 901723.62349688, 455516.83615459]), array([ 499624.58304481, 610091.26845662, 967500.51799746, ..., 359938.28070706, 1006753.92094141, 465745.17602589]), array([525700.21446436, 653616.11499674, 997807.51664587, ..., 346147.47470565, 979679.06092606, 478183.00379786]), array([504600.39478621, 651596.55745818, 952472.76765985, ..., 334430.63067946, 905250.88060499, 443070.41117399])]  1 2 3 4 5 6 7  # Bagging을 바탕으로 예측한 결과값에 대한 평균을 계산 bagging_predict = [] # 빈 리스트 생성 for lst2_index in range(test_x.shape[0]): # 테스트 데이터 개수만큼의 반복 temp_predict = [] # 임시 빈 리스트 생성 (반복문 내 결과값 저장) for lst_index in range(len(bagging_predict_result)): # Bagging 결과 리스트 반복 temp_predict.append(bagging_predict_result[lst_index][lst2_index]) # 각 Bagging 결과 예측한 값 중 같은 인덱스를 리스트에 저장 bagging_predict.append(np.mean(temp_predict)) # 해당 인덱스의 30개의 결과값에 대한 평균을 최종 리스트에 추가   1 2 3  # 예측한 결과값들의 평균을 계산하여 실제 테스트 데이트의 타겟변수와 비교하여 성능 평가 print(\"RMSE: {}\".format(sqrt(mean_squared_error(bagging_predict, test_y)))) # RMSE   RMSE: 210563.02109308538  ","description":"","tags":null,"title":"Ensemble","uri":"/posts/data_science/machine_learning/ensemble/"},{"categories":["Data_Science","Machine_Learning"],"content":"1 2 3 4  import os import pandas as pd import numpy as np from sklearn.model_selection import train_test_split   1 2 3  # 데이터 불러오기 data = pd.read_csv(\"./data/otto_train.csv\") # Product Category data.head() # 데이터 확인    .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; }  \n  id feat_1 feat_2 feat_3 feat_4 feat_5 feat_6 feat_7 feat_8 feat_9 ... feat_85 feat_86 feat_87 feat_88 feat_89 feat_90 feat_91 feat_92 feat_93 target     0 1 1 0 0 0 0 0 0 0 0 ... 1 0 0 0 0 0 0 0 0 Class_1   1 2 0 0 0 0 0 0 0 1 0 ... 0 0 0 0 0 0 0 0 0 Class_1   2 3 0 0 0 0 0 0 0 1 0 ... 0 0 0 0 0 0 0 0 0 Class_1   3 4 1 0 0 1 6 1 5 0 0 ... 0 1 2 0 0 0 0 0 0 Class_1   4 5 0 0 0 0 0 0 0 0 0 ... 1 0 0 0 0 1 0 0 0 Class_1     1 2 3 4 5  ''' id: 고유 아이디 feat_1 ~ feat_93: 설명변수 target: 타겟변수 (1~9) '''   '\\nid: 고유 아이디\\nfeat_1 ~ feat_93: 설명변수\\ntarget: 타겟변수 (1~9)\\n'  1 2 3  nCar = data.shape[0] # 데이터 개수 nVar = data.shape[1] # 변수 개수 print('nCar: %d' % nCar, 'nVar: %d' % nVar )   nCar: 61878 nVar: 95  1  data = data.drop(['id'], axis = 1) # id 제거   `타겟 변수의 문자열을 숫자로 변환\n1 2 3 4 5 6 7 8 9 10  mapping_dict = {\"Class_1\": 1, \"Class_2\": 2, \"Class_3\": 3, \"Class_4\": 4, \"Class_5\": 5, \"Class_6\": 6, \"Class_7\": 7, \"Class_8\": 8, \"Class_9\": 9} after_mapping_target = data['target'].apply(lambda x: mapping_dict[x])   설명변수와 타겟변수를 분리, 학습데이터와 평가데이터 분리\n1 2 3 4 5  feature_columns = list(data.columns.difference(['target'])) X = data[feature_columns] y = after_mapping_target train_x, test_x, train_y, test_y = train_test_split(X, y, test_size = 0.2, random_state = 42) print(train_x.shape, test_x.shape, train_y.shape, test_y.shape)   (49502, 93) (12376, 93) (49502,) (12376,)   학습 데이터를 랜덤포레스트 모형에 적합 후 평가 데이터로 검증  1 2 3 4 5 6 7 8  from sklearn.ensemble import RandomForestClassifier from sklearn.metrics import accuracy_score random_forest_model1 = RandomForestClassifier(n_estimators = 20, max_depth = 5, random_state = 42) model1 = random_forest_model1.fit(train_x, train_y) predict1 = model1.predict(test_x) print(\"Accuracy: %.2f\" % (accuracy_score(test_y, predict1) * 100), \"%\")   Accuracy: 60.16 %  estimators 증가\n1 2 3 4 5 6  random_forest_model2 = RandomForestClassifier(n_estimators = 300, max_depth = 5, random_state = 42) model2 = random_forest_model2.fit(train_x, train_y) predict2 = model2.predict(test_x) print(\"Accuracy: %.2f\" % (accuracy_score(test_y, predict2) * 100), \"%\")   Accuracy: 61.73 %  트리의 깊이\n1 2 3 4 5 6  random_forest_model3 = RandomForestClassifier(n_estimators = 300, max_depth = 20, random_state = 42) model3 = random_forest_model3.fit(train_x, train_y) predict3 = model3.predict(test_x) print(\"Accuracy: %.2f\" % (accuracy_score(test_y, predict3) * 100), \"%\")   Accuracy: 78.09 %  트리의 깊이를 최대\n1 2 3 4 5 6  random_forest_model4 = RandomForestClassifier(n_estimators = 300, max_depth = 100, random_state = 42) model4 = random_forest_model4.fit(train_x, train_y) predict4 = model4.predict(test_x) # 평가 데이터 예측 print(\"Accuracy: %.2f\" % (accuracy_score(test_y, predict4) * 100), \"%\")   Accuracy: 81.23 %  ","description":"","tags":null,"title":"RandomForest","uri":"/posts/data_science/machine_learning/randomforest/"},{"categories":["Data_Science","Machine_Learning"],"content":"`model의 복잡도에 따른 퍼포먼스 비교\n1 2 3 4  import numpy as np import pandas as pd from matplotlib import pyplot as plt from matplotlib.colors import ListedColormap   1 2 3 4  from sklearn.model_selection import train_test_split from sklearn.preprocessing import StandardScaler from sklearn.datasets import make_moons, make_circles, make_classification from sklearn.neural_network import MLPClassifier    설정할 parameter들을 입력. h는 시각화를 얼마나 자세하게 할 것인가에 대한 위한 임의의 값.  1 2 3  h = .02 alphas = np.logspace(-5, 3, 5) names = ['alpha ' + str(i) for i in alphas]   1  alphas   array([ 1.00000000e-05, 1.00000000e-03, 1.00000000e-01, 1.00000000e+01, 1.00000000e+03])  1  names   ['alpha 1e-05', 'alpha 0.001', 'alpha 0.1', 'alpha 10.0', 'alpha 1000.0']  1 2 3 4  classifiers = [] for i in alphas: classifiers.append(MLPClassifier(solver='lbfgs', alpha=i, random_state=1, hidden_layer_sizes=[100, 100]))    데이터 생성  1 2  X, y = make_classification(n_features=2, n_redundant=0, n_informative=2, random_state=0, n_clusters_per_class=1)   1  pd.DataFrame(X).head()     .dataframe thead tr:only-child th { text-align: right; } .dataframe thead th { text-align: left; } .dataframe tbody tr th { vertical-align: top; }  \n  0 1     0 -0.605416 1.296708   1 1.354900 -0.046877   2 1.780375 1.099858   3 1.436615 0.807641   4 0.721669 1.168160     1  pd.DataFrame(y).head()     .dataframe thead tr:only-child th { text-align: right; } .dataframe thead th { text-align: left; } .dataframe tbody tr th { vertical-align: top; }  \n  0     0 1   1 0   2 1   3 1   4 1     1 2 3  rng = np.random.RandomState(2) X += 2 * rng.uniform(size=X.shape) linearly_separable = (X, y)    여러 모양의 추가 데이터셋 생성  1 2 3 4 5 6  datasets = [make_moons(noise=0.3, random_state=0), make_circles(noise=0.2, factor=0.5, random_state=1), linearly_separable] figure = plt.figure(figsize=(17, 9)) i = 1   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59  for X, y in datasets: # preprocess dataset, split into training and test part X = StandardScaler().fit_transform(X) X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.4) x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5 y_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5 xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h)) # just plot the dataset first cm = plt.cm.RdBu cm_bright = ListedColormap(['#FF0000', '#0000FF']) ax = plt.subplot(len(datasets), len(classifiers) + 1, i) # Plot the training points ax.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap=cm_bright) # and testing points ax.scatter(X_test[:, 0], X_test[:, 1], c=y_test, cmap=cm_bright, alpha=0.6) ax.set_xlim(xx.min(), xx.max()) ax.set_ylim(yy.min(), yy.max()) ax.set_xticks(()) ax.set_yticks(()) i += 1 # iterate over classifiers for name, clf in zip(names, classifiers): ax = plt.subplot(len(datasets), len(classifiers) + 1, i) clf.fit(X_train, y_train) score = clf.score(X_test, y_test) # Plot the decision boundary. For that, we will assign a color to each # point in the mesh [x_min, x_max]x[y_min, y_max]. if hasattr(clf, \"decision_function\"): Z = clf.decision_function(np.c_[xx.ravel(), yy.ravel()]) else: Z = clf.predict_proba(np.c_[xx.ravel(), yy.ravel()])[:, 1] # Put the result into a color plot Z = Z.reshape(xx.shape) ax.contourf(xx, yy, Z, cmap=cm, alpha=.8) # Plot also the training points ax.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap=cm_bright, edgecolors='black', s=25) # and testing points ax.scatter(X_test[:, 0], X_test[:, 1], c=y_test, cmap=cm_bright, alpha=0.6, edgecolors='black', s=25) ax.set_xlim(xx.min(), xx.max()) ax.set_ylim(yy.min(), yy.max()) ax.set_xticks(()) ax.set_yticks(()) ax.set_title(name) ax.text(xx.max() - .3, yy.min() + .3, ('%.2f' % score).lstrip('0'), size=15, horizontalalignment='right') i += 1 figure.subplots_adjust(left=.02, right=.98) plt.show()   ","description":"","tags":null,"title":"신경망 모형","uri":"/posts/data_science/machine_learning/neural/"},{"categories":["Data_Science","Machine_Learning"],"content":"1 2 3 4 5  from sklearn import tree X = [[0, 0], [1, 1]] Y = [0, 1] clf = tree.DecisionTreeClassifier() clf = clf.fit(X, Y)   1  clf.predict([[1, 1]])   1 2 3  from sklearn.datasets import load_iris from sklearn import tree iris=load_iris()   의사결정나무 구축 및 시각화  트리 구축  1 2  clf=tree.DecisionTreeClassifier() clf=clf.fit(iris.data,iris.target)    트리의 시각화  1 2 3 4 5 6 7  dot_data=tree.export_graphviz(clf,out_file=None, feature_names=iris.feature_names, class_names=iris.target_names, filled=True, rounded=True, special_characters=True ) graph=graphviz.Source(dot_data)   \\\n Confusion Matrix 구하기  1 2  from sklearn.metrics import confusion_matrix confusion_matrix(iris.target,clf.predict(iris.data))   array([[50, 0, 0], [ 0, 50, 0], [ 0, 0, 50]])  ","description":"","tags":null,"title":"Decision Tree","uri":"/posts/data_science/machine_learning/decision/"},{"categories":["Data_Science","Machine_Learning"],"content":"Support Vector Machine `가장 가까운 K개 점을 선택헤 분류 및 예측\n1 2  import numpy as np import matplotlib.pyplot as plt    함수 불러오기  1 2 3 4 5 6 7 8  from sklearn import svm, datasets iris=datasets.load_iris() X=iris.data[:,:2] y=iris.target C=1 clf=svm.SVC(kernel='linear',C=C) clf.fit(X,y)   SVC(C=1, cache_size=200, class_weight=None, coef0=0.0, decision_function_shape=None, degree=3, gamma='auto', kernel='linear', max_iter=-1, probability=False, random_state=None, shrinking=True, tol=0.001, verbose=False)  1 2 3  from sklearn.metrics import confusion_matrix y_pred=clf.predict(X) confusion_matrix(y,y_pred)   array([[50, 0, 0], [ 0, 38, 12], [ 0, 15, 35]])  2. kernel SVM 적합 및 비교  LinearSVC  1 2 3 4  clf=svm.LinearSVC(C=C,max_iter=10000) clf.fit(X,y) y_pred=clf.predict(X) confusion_matrix(y,y_pred)   array([[49, 1, 0], [ 2, 30, 18], [ 0, 9, 41]])   radial basis function  1 2 3 4  clf=svm.SVC(kernel='rbf',gamma=0.7,C=C,max_iter=10000) clf.fit(X,y) y_pred=clf.predict(X) confusion_matrix(y,y_pred)   array([[50, 0, 0], [ 0, 37, 13], [ 0, 13, 37]])   polynomial kernel  1 2 3 4  clf=svm.SVC(kernel='poly',degree=3,C=C,gamma='auto') clf.fit(X,y) y_pred=clf.predict(X) confusion_matrix(y,y_pred)   array([[50, 0, 0], [ 0, 38, 12], [ 0, 16, 34]])    시각적 비교\n  함수 정의\n  1 2 3 4 5 6 7 8 9 10 11 12 13  def make_meshgrid(x, y, h=.02): x_min, x_max = x.min() - 1, x.max() + 1 y_min, y_max = y.min() - 1, y.max() + 1 xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h)) return xx, yy def plot_contours(ax, clf, xx, yy, **params): Z = clf.predict(np.c_[xx.ravel(), yy.ravel()]) Z = Z.reshape(xx.shape) out = ax.contourf(xx, yy, Z, **params) return out    데이터 불러오기  1 2 3 4  iris = datasets.load_iris() X = iris.data[:, :2] y = iris.target    모델정의 및 피팅  1 2 3 4 5 6  C = 1.0 #Regularization parameter models = (svm.SVC(kernel='linear', C=C), svm.LinearSVC(C=C, max_iter=10000), svm.SVC(kernel='rbf', gamma=0.7, C=C), svm.SVC(kernel='poly', degree=3, gamma='auto', C=C)) models = (clf.fit(X, y) for clf in models)   1 2 3 4  titles = ('SVC with linear kernel', 'LinearSVC (linear kernel)', 'SVC with RBF kernel', 'SVC with polynomial (degree 3) kernel')   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  fig, sub = plt.subplots(2, 2) plt.subplots_adjust(wspace=0.4, hspace=0.4) X0, X1 = X[:, 0], X[:, 1] xx, yy = make_meshgrid(X0, X1) for clf, title, ax in zip(models, titles, sub.flatten()): plot_contours(ax, clf, xx, yy, cmap=plt.cm.coolwarm, alpha=0.8) ax.scatter(X0, X1, c=y, cmap=plt.cm.coolwarm, s=20, edgecolors='k') ax.set_xlim(xx.min(), xx.max()) ax.set_ylim(yy.min(), yy.max()) ax.set_xlabel('Sepal length') ax.set_ylabel('Sepal width') ax.set_xticks(()) ax.set_yticks(()) ax.set_title(title) plt.show()   ","description":"","tags":null,"title":"SVM","uri":"/posts/data_science/machine_learning/svm/"},{"categories":["Data_Science","Machine_Learning"],"content":"KNN `가장 가까운 K개 점을 선택헤 분류 및 예측\niris datasets으로 KNN 적용  모델 예측 및 confusion matrix 보기  1 2 3 4  from sklearn import neighbors, datasets import numpy as np import matplotlib.pyplot as plt from matplotlib.colors import ListedColormap   1 2 3 4  iris = datasets.load_iris() X = iris.data[:, :2] y = iris.target    모델 구축  1 2  clf = neighbors.KNeighborsClassifier(5) clf.fit(X,y)   KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski', metric_params=None, n_jobs=None, n_neighbors=5, p=2, weights='uniform')  1  y_pred=clf.predict(X)   1 2  from sklearn.metrics import confusion_matrix confusion_matrix(y,y_pred)   array([[49, 1, 0], [ 0, 38, 12], [ 0, 12, 38]], dtype=int64)  2.Cross-validation을 활용한 최적의 k찾기 1  from sklearn.model_selection import cross_val_score    CV 진행  1 2 3 4 5 6 7  k_range = range(1,100) k_scores= [] for k in k_range: knn=neighbors.KNeighborsClassifier(k) scores=cross_val_score(knn,X,y,cv=10,scoring=\"accuracy\") k_scores.append(scores.mean())   1 2 3 4  plt.plot(k_range, k_scores) plt.xlabel('Value of K for KNN') plt.ylabel('Cross-validated accuracy') plt.show()   가중치를 준 KNN 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33  n_neighbors = 40 h = .02 # step size in the mesh cmap_light = ListedColormap(['#FFAAAA', '#AAFFAA', '#AAAAFF']) cmap_bold = ListedColormap(['#FF0000', '#00FF00', '#0000FF']) for weights in ['uniform', 'distance']: clf = neighbors.KNeighborsClassifier(n_neighbors, weights=weights) clf.fit(X, y) # Plot the decision boundary. For that, we will assign a color to each # point in the mesh [x_min, x_max]x[y_min, y_max]. x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1 y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1 xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h)) Z = clf.predict(np.c_[xx.ravel(), yy.ravel()]) # Put the result into a color plot Z = Z.reshape(xx.shape) plt.figure() plt.pcolormesh(xx, yy, Z, cmap=cmap_light) # Plot also the training points plt.scatter(X[:, 0], X[:, 1], c=y, cmap=cmap_bold, edgecolor='k', s=20) plt.xlim(xx.min(), xx.max()) plt.ylim(yy.min(), yy.max()) plt.title(\"3-Class classification (k = %i, weights = '%s')\" % (n_neighbors, weights)) plt.show()   ","description":"","tags":null,"title":"KNN","uri":"/posts/data_science/machine_learning/knn/"},{"categories":["Data_Science","Cluster"],"content":"DBSCAN ` 밀도 기반 군집\n 초기값에 민감하고 이상치 민감한 K-means 문제 해결  방법  eps-neighbors : epsilon 거리 이내의 데이터들을 한 군집으로 구성 minPts : minPts보다 같거나 많은 데이터로 구성, minPts보다 적은 수의 데이터가 eps를 형성하면 noise로 취급 -\u003e -1  hyper parameter 정하기 minPts\n 보통 3 이상으로 설정  eps\n 값을 변경하며 찾아도 되지만 KNN의 distance를 그래프로 나타내고 거리가 급격하게 증가하는 지점을 eps로 설정하는 게 좋음.   apply 1 2 3 4 5 6 7 8 9  import numpy as np import matplotlib.pyplot as plt import seaborn as sns import sklearn.cluster as cluster import time %matplotlib inline sns.set_context('poster') sns.set_color_codes() plot_kwds = {'alpha' : 0.25, 's' : 80, 'linewidths':0}   1  data = np.load('./data/clusterable_data.npy')   1 2 3 4  plt.scatter(data.T[0], data.T[1], c='b', **plot_kwds) frame = plt.gca() frame.axes.get_xaxis().set_visible(False) frame.axes.get_yaxis().set_visible(False)   1 2 3 4 5 6 7 8 9 10 11 12  def plot_clusters(data, algorithm, args, kwds): start_time = time.time() labels = algorithm(*args, **kwds).fit_predict(data) end_time = time.time() palette = sns.color_palette('deep', np.unique(labels).max() + 1) colors = [palette[x] if x \u003e= 0 else (0.0, 0.0, 0.0) for x in labels] plt.scatter(data.T[0], data.T[1], c=colors, **plot_kwds) frame = plt.gca() frame.axes.get_xaxis().set_visible(False) frame.axes.get_yaxis().set_visible(False) plt.title('Clusters found by {}'.format(str(algorithm.__name__)), fontsize=24) plt.text(-0.5, 0.7, 'Clustering took {:.2f} s'.format(end_time - start_time), fontsize=14)   1  plot_clusters(data, cluster.KMeans, (), {'n_clusters':3})   1  plot_clusters(data, cluster.KMeans, (), {'n_clusters':4})   1  plot_clusters(data, cluster.KMeans, (), {'n_clusters':5})   1  plot_clusters(data, cluster.DBSCAN, (), {'eps':0.020})   1  plot_clusters(data, cluster.DBSCAN, (), {'eps':0.03})   1 2 3  dbs = DBSCAN(eps=0.03) dbs2=dbs.fit(data)   1  dbs2.labels_   array([ 0, 0, 0, ..., -1, -1, 0], dtype=int64)  HDBSCAN DBSCAN의 발전, hyper parameter에 덜 민감하다.\n1  import hdbscan   1  plot_clusters(data, hdbscan.HDBSCAN, (), {'min_cluster_size':45})   ","description":"","tags":null,"title":"DBSCAN","uri":"/posts/data_science/cluster/cluster3/"},{"categories":["Data_Science","Cluster"],"content":"K-means Clustering ` 각 군집에 할당된 포인트들의 평균 좌표를 이용해 중심점을 반복적으로 업데이트\n 각 데이터에 대해 가까운 데이터 찾고 새로 할당된 군집 기반으로 새로운 중심 계산 클러스터 할당이 바뀌지 않을 때까지 반복   거리는 Manhattan이나 Euclidean  K 설정 문제 최적화되 k를 찾기 어려움 -\u003e Silhouette method 사용 - 객체와 그 객체가 속한 군집의 데이터들과의 비 유사성을 계산\n a(i) : i와 i가 속한 군집 데이터들과의 비 유사성 b(i) : i가 속하지 않은 다른 군집의 모든 데이터들과의 비 유사성의 최솟값(가장 가까운 군집) s(i) = $(b(i) - a(i)) / max{a(i), b(i)}  s(i)의 값이 1에 가까울수록 올바른 클러스터에 분류된 것이라 할 수 있음. k를 증가시키며 평균 s(i), silhouette coefficient가 최대가 되는 k를 선택    K-means의 또 다른 문제는 이상치에 민감하다는 것인데 이를 해결하기 위해 K-medoids(중간점)를 사용 평균 대신 중앙값을 구한다고 생각하면 된다.  apply Iris 데이터를 활용하여 Kmeans clustering\n1 2 3 4 5  from sklearn import datasets import matplotlib.pyplot as plt import pandas as pd from sklearn.cluster import KMeans iris = datasets.load_iris()   1 2  X = iris.data[:, :2] y = iris.target   1 2 3  plt.scatter(X[:,0], X[:,1], c=y, cmap='gist_rainbow') plt.xlabel('Spea1 Length', fontsize=18) plt.ylabel('Sepal Width', fontsize=18)   1 2  km = KMeans(n_clusters = 3, n_jobs = 4, random_state=21) km.fit(X)   KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300, n_clusters=3, n_init=10, n_jobs=4, precompute_distances='auto', random_state=21, tol=0.0001, verbose=0)  각 군집의 center 보기\n1 2  centers = km.cluster_centers_ print(centers)   [[5.77358491 2.69245283] [5.006 3.418 ] [6.81276596 3.07446809]]  실제 분류된 값과 군집으로 분류된 값 비교\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  new_labels = km.labels_ fig, axes = plt.subplots(1, 2, figsize=(16,8)) axes[0].scatter(X[:, 0], X[:, 1], c=y, cmap='gist_rainbow', edgecolor='k', s=150) axes[1].scatter(X[:, 0], X[:, 1], c=new_labels, cmap='jet', edgecolor='k', s=150) axes[0].set_xlabel('Sepal length', fontsize=18) axes[0].set_ylabel('Sepal width', fontsize=18) axes[1].set_xlabel('Sepal length', fontsize=18) axes[1].set_ylabel('Sepal width', fontsize=18) axes[0].tick_params(direction='in', length=10, width=5, colors='k', labelsize=20) axes[1].tick_params(direction='in', length=10, width=5, colors='k', labelsize=20) axes[0].set_title('Actual', fontsize=18) axes[1].set_title('Predicted', fontsize=18)   2차원의 가상 데이터에 Kmeans clustering 1 2 3 4 5 6 7  from sklearn.datasets import make_blobs # create dataset X, y = make_blobs( n_samples=150, n_features=2, centers=3, cluster_std=0.5, shuffle=True, random_state=0 )   1 2 3 4 5 6 7  km = KMeans( n_clusters=3, init='random', n_init=10, max_iter=300, tol=1e-04, random_state=0 ) y_km = km.fit_predict(X) y_km   array([1, 0, 0, 0, 1, 0, 0, 1, 2, 0, 1, 2, 2, 0, 0, 2, 2, 1, 2, 1, 0, 1, 0, 0, 2, 1, 1, 0, 2, 1, 2, 2, 2, 2, 0, 1, 1, 1, 0, 0, 2, 2, 0, 1, 1, 1, 2, 0, 2, 0, 1, 0, 0, 1, 1, 2, 0, 1, 2, 0, 2, 2, 2, 2, 0, 2, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 2, 2, 0, 1, 1, 0, 0, 1, 1, 1, 2, 2, 1, 1, 0, 1, 0, 1, 0, 2, 2, 1, 1, 1, 1, 2, 1, 1, 0, 2, 0, 0, 0, 2, 0, 1, 2, 0, 2, 0, 0, 2, 2, 0, 1, 0, 0, 1, 1, 2, 1, 2, 2, 2, 2, 1, 2, 2, 2, 0, 2, 1, 2, 0, 0, 1, 1, 2, 2, 2, 2, 1, 1])  군집 분류 시각화\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32  plt.scatter( X[y_km == 0, 0], X[y_km == 0, 1], s=50, c='lightgreen', marker='s', edgecolor='black', label='cluster 1' ) plt.scatter( X[y_km == 1, 0], X[y_km == 1, 1], s=50, c='orange', marker='o', edgecolor='black', label='cluster 2' ) plt.scatter( X[y_km == 2, 0], X[y_km == 2, 1], s=50, c='lightblue', marker='v', edgecolor='black', label='cluster 3' ) # plot the centroids plt.scatter( km.cluster_centers_[:, 0], km.cluster_centers_[:, 1], s=250, marker='*', c='red', edgecolor='black', label='centroids' ) plt.legend(scatterpoints=1) plt.grid() plt.show()   k 를 4로 할경우 1 2 3 4 5 6  km = KMeans( n_clusters=4, init='random', n_init=10, max_iter=300, tol=1e-04, random_state=0 ) y_km = km.fit_predict(X)   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41  plt.scatter( X[y_km == 0, 0], X[y_km == 0, 1], s=50, c='lightgreen', marker='s', edgecolor='black', label='cluster 1' ) plt.scatter( X[y_km == 1, 0], X[y_km == 1, 1], s=50, c='orange', marker='o', edgecolor='black', label='cluster 2' ) plt.scatter( X[y_km == 2, 0], X[y_km == 2, 1], s=50, c='lightblue', marker='v', edgecolor='black', label='cluster 3' ) plt.scatter( X[y_km == 3, 0], X[y_km == 3, 1], s=50, c='lightblue', marker='d', edgecolor='black', label='cluster 4' ) # plot the centroids plt.scatter( km.cluster_centers_[:, 0], km.cluster_centers_[:, 1], s=250, marker='*', c='red', edgecolor='black', label='centroids' ) plt.legend(scatterpoints=1) plt.grid() plt.show()   한 군집이 2개로 나눠진 것처럼 보임. K=3 일 때가 더 명확하게 나온 것 같지만 K값을 변화시켜 최적의 K를 찾아보는 게 좋다.\n최적의 K 찾기 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  from sklearn.metrics import silhouette_score distortions = [] for i in range(2, 11): km = KMeans( n_clusters=i, init='random', n_init=10, max_iter=300, tol=1e-04, random_state=0 ) km.fit(X) distortions.append(silhouette_score(X,km.predict(X), metric='euclidean')) plt.plot(range(2, 11), distortions, marker='o') plt.xlabel('Number of clusters') plt.ylabel('Distortion') plt.show()   간단하게는 kmeans 클래스의 inertia_를 이용해 최적의 k를 찾을 수 있다.\n","description":"","tags":null,"title":"K-means","uri":"/posts/data_science/cluster/cluster2/"},{"categories":["Data_Science","Cluster"],"content":"군집 분석 ` 각 데이터의 유사성을 측정하여 높은 대상 집단을 분류하고 군집 간에 상이성을 규명\n K-means : 사용자가 지정한 k개의 군집으로 나누기 Hierarchical : 나무 모양의 계층 구조를 형성해 나감. DBSCAN : 밀도 기반 군집, K개 설정 필요없음.  Hierarchical Clustering  가까운 집단부터 계층적으로 묶어나감 dendogram을 통해 시각화 가능 군집의 개수를 정하지 않아도 되나 데이터가 많을 경우 시각화나 많은 계층으로 나누기가 힘들어 데이터가 적으면 보기 좋음.  방법  모든 개체들 사이의 유사도 행렬 계산 거리가 인접한 관측치끼리 cluster 형성 유사도 행렬 update  아래와 같이 A와D가 같은 군집으로 묶이면 AD로 묶임  유사도 계산은 cluster 거리의 최소, 최대를 기준으로 하거나 평균, centroid 기준으로 계산됨. 주로 ward 연결법이 쓰인다.  apply 1 2  customer_data = pd.read_csv('./data/shopping-data.csv') customer_data.head()    .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; }  \n  CustomerID Genre Age Annual Income (k$) Spending Score (1-100)     0 1 Male 19 15 39   1 2 Male 21 15 81   2 3 Female 20 16 6   3 4 Female 23 16 77   4 5 Female 31 17 40     1  data = customer_data.iloc[:, 3:5].values   덴드로그램 보기\n1 2 3 4 5 6  import scipy.cluster.hierarchy as shc plt.figure(figsize=(10, 7)) plt.title(\"Customer Dendograms\") # ward가 기준 dend = shc.dendrogram(shc.linkage(data, method='ward'))   군집 시각화 1 2 3 4  from sklearn.cluster import AgglomerativeClustering cluster = AgglomerativeClustering(n_clusters=5, affinity='euclidean', linkage='ward') cluster.fit_predict(data)   array([4, 3, 4, 3, 4, 3, 4, 3, 4, 3, 4, 3, 4, 3, 4, 3, 4, 3, 4, 3, 4, 3, 4, 3, 4, 3, 4, 3, 4, 3, 4, 3, 4, 3, 4, 3, 4, 3, 4, 3, 4, 3, 4, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 2, 0, 2, 0, 2, 1, 2, 0, 2, 0, 2, 0, 2, 0, 2, 1, 2, 0, 2, 1, 2, 0, 2, 0, 2, 0, 2, 0, 2, 0, 2, 0, 2, 1, 2, 0, 2, 0, 2, 0, 2, 0, 2, 0, 2, 0, 2, 0, 2, 0, 2, 0, 2, 0, 2, 0, 2, 0, 2, 0, 2, 0, 2, 0, 2, 0, 2, 0, 2, 0, 2, 0, 2], dtype=int64)  1 2  plt.figure(figsize=(10, 7)) plt.scatter(data[:,0], data[:,1], c=cluster.labels_, cmap='rainbow')   ","description":"","tags":null,"title":"Clustering 소개, Hierarchical clustering","uri":"/posts/data_science/cluster/cluster1/"},{"categories":["Data_Science","Machine_Learning"],"content":"1 2 3 4 5 6 7 8 9 10 11 12  import pandas as pd import numpy as np import matplotlib.pyplot as plt import seaborn as sns from scipy import stats import statsmodels.api as sm from sklearn.model_selection import train_test_split from sklearn.metrics import mean_squared_error plt.style.use('fivethirtyeight') sales = pd.read_csv('Album_sales_2.txt',sep='\\t') sales    .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; }  \n  adverts sales airplay attract     0 10.256 330 43 10   1 985.685 120 28 7   2 1445.563 360 35 7   3 1188.193 270 33 7   4 574.513 220 44 5   ... ... ... ... ...   195 910.851 190 26 7   196 888.569 240 14 6   197 800.615 250 34 6   198 1500.000 230 11 8   199 785.694 110 20 9      advers : 광고비 sales: 판매량 airplay : 음반 출시전 한 주 동안 노래들이 라디오1에 방송된 횟수 attract : 밴드 매력(0~10)  1. EDA 1  sales.info()   \u003cclass 'pandas.core.frame.DataFrame'\u003e RangeIndex: 200 entries, 0 to 199 Data columns (total 4 columns): # Column Non-Null Count Dtype --- ------ -------------- ----- 0 adverts 200 non-null float64 1 sales 200 non-null int64 2 airplay 200 non-null int64 3 attract 200 non-null int64 dtypes: float64(1), int64(3) memory usage: 6.4 KB  1  sales.describe()    .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; }  \n  adverts sales airplay attract     count 200.000000 200.000000 200.000000 200.00000   mean 614.412255 193.200000 27.500000 6.77000   std 485.655208 80.698957 12.269585 1.39529   min 9.104000 10.000000 0.000000 1.00000   25% 215.917750 137.500000 19.750000 6.00000   50% 531.916000 200.000000 28.000000 7.00000   75% 911.225500 250.000000 36.000000 8.00000   max 2271.860000 360.000000 63.000000 10.00000     1 2 3 4 5  plt.style.use('seaborn-pastel') plt.figure(figsize=(10,10)) for i,j in enumerate(sales.columns): plt.subplot(2,2,i+1) sns.histplot(sales[j])   1  sns.pairplot(sales)   \u003cseaborn.axisgrid.PairGrid at 0x1e5f655a940\u003e  1  sns.heatmap(sales.corr(),annot=True,cmap='Blues')   \u003cAxesSubplot:\u003e  `시각화를 통해 보았을 때 advert가 치우쳐서 변수 변환이 필요할 수 있다는 점 빼고 큰 특징은 보이지 않는다.\n상관성이 좀 있는 편인데 일단 회귀 분석을 진행하면서 결과를 살펴봐야겠다.\n 2. train, test로 분리 후 다중회귀분석 결과 해석 1  x_train, x_test, y_train, y_test = train_test_split(sales.iloc[:,[0,2,3]], sales['sales'],)   상수항 넣었을 때\n1  x_data = sm.add_constant(x_train, has_constant = \"add\")   1 2 3 4  # const넣음 model = sm.OLS(y_train,x_data) result = model.fit() result.summary()   OLS Regression Results  Dep. Variable: sales  R-squared:   0.651   Model: OLS  Adj. R-squared:   0.644   Method: Least Squares  F-statistic:   90.71   Date: Fri, 09 Oct 2020  Prob (F-statistic): 3.44e-33   Time: 14:24:41  Log-Likelihood:   -789.91   No. Observations:  150  AIC:   1588.   Df Residuals:  146  BIC:   1600.   Df Model:  3       Covariance Type: nonrobust         coef std err t P|t| [0.025 0.975]   const  -36.6149  21.619  -1.694  0.092  -79.341  6.111   adverts  0.0825  0.008  10.032  0.000  0.066  0.099   airplay  3.4240  0.314  10.897  0.000  2.803  4.045   attract  12.5468  2.997  4.187  0.000  6.624  18.470    Omnibus:  0.238  Durbin-Watson:   1.725   Prob(Omnibus):  0.888  Jarque-Bera (JB):   0.189   Skew:  0.086  Prob(JB):   0.910   Kurtosis:  2.972  Cond. No.  4.41e+03   1 2  y_pred = result.predict(ols.add_constant(x_test, has_constant = \"add\")) mean_squared_error(y_pred,y_test)   2128.1345418881824  1 2 3 4  # 안 넣음 model2 = sm.OLS(y_train,x_train) result2 = model2.fit() result2.summary()   OLS Regression Results  Dep. Variable: sales  R-squared (uncentered):  0.950   Model: OLS  Adj. R-squared (uncentered):  0.949   Method: Least Squares  F-statistic:   928.3   Date: Sun, 11 Oct 2020  Prob (F-statistic): 2.75e-95   Time: 23:09:26  Log-Likelihood:   -791.37   No. Observations:  150  AIC:   1589.   Df Residuals:  147  BIC:   1598.   Df Model:  3       Covariance Type: nonrobust         coef std err t P|t| [0.025 0.975]   adverts  0.0797  0.008  9.830  0.000  0.064  0.096   airplay  3.3006  0.308  10.731  0.000  2.693  3.908   attract  8.1136  1.468  5.525  0.000  5.212  11.016    Omnibus:  0.694  Durbin-Watson:   1.762   Prob(Omnibus):  0.707  Jarque-Bera (JB):   0.587   Skew:  0.153  Prob(JB):   0.745   Kurtosis:  2.990  Cond. No.   300.   aic는 비슷하나 R-squared 면에서 상수항이 없는게 나음\n1 2  y_pred = result2.predict(x_test) mean_squared_error(y_pred,y_test)   2093.0726936877363  1 2  plt.plot(y_test.values) plt.plot(y_pred.values)   VIF\n1 2  from statsmodels.stats.outliers_influence import variance_inflation_factor [variance_inflation_factor(x_train.values,i) for i in range(3)]   [2.6632477766856404, 5.761240629832455, 6.855611086457372]  대체로 크게 나오는 편은 아니다.\n변수가 적어 모든 변수 조합에서 Variance와 mse를 살펴 봄\n1 2 3 4 5 6  from itertools import combinations joint = [] for i in range(1,4): k = combinations(x_train.columns,i) for j in k: joint.append(j)   [('adverts',), ('airplay',), ('attract',), ('adverts', 'airplay'), ('adverts', 'attract'), ('airplay', 'attract'), ('adverts', 'airplay', 'attract')]  1 2 3 4 5 6  stepw = [] for i in joint: model = sm.OLS(y_train,x_train[list(i)]) result = model.fit() y_pred = result.predict(x_test[list(i)]) stepw.append([list(i),result.aic,mean_squared_error(y_pred,y_test)])   1 2 3  stepw_frame = pd.DataFrame(stepw, columns=['Variables','AIC','MSE']) stepw_frame.set_index('Variables',inplace=True) stepw_frame    .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; }  \n  AIC MSE   Variables       [adverts] 1832.620857 9775.286334   [airplay] 1716.242475 5246.164309   [attract] 1727.874967 6423.816111   [adverts, airplay] 1615.042139 2447.023190   [adverts, attract] 1673.510244 3376.763066   [airplay, attract] 1662.523096 4237.857648   [adverts, airplay, attract] 1588.737818 2093.072694     3개 다 선택했을 때 값이 가장 적게 나온다.\n다중회귀분석의 매개변수별 신뢰구간\n1  result2.conf_int()    .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; }  \n  0 1     adverts 0.063717 0.095782   airplay 2.692710 3.908404   attract 5.211536 11.015580     3. 독립성, 정규성 가정 평가 1 2  # 독립성 sns.regplot(result2.fittedvalues, result2.resid, lowess=True, line_kws={'color': 'red'})   1 2  #정규성 stats.probplot(result2.resid,plot=plt);   1  stats.shapiro(result2.resid)   (0.9950959086418152, 0.8982971906661987)   독립성과 정규성을 만족하는 편이다. summary에서 durbin-watson 값이 1.5~2.5 안에 있어야 정상이라고 함  4. 표준화잔차, cook’s distance, DFBeta, 공분산비 보기  표준화잔차(standard_resid) : 잔차를 표준오차로 나눈 값 cook’s distance : 관측치가 제거되었을 때 모수 추정값들의 (동시적) 변화량 척도 DFBeta : 관측값이 각각의 회귀계수에 미치는 영향력을 측정 DFFITS : 관측치가 예측값에서 보유하고 있는 영향력을 측정  1 2 3  infl = result2.get_influence() sm_fr = infl.summary_frame() sm_fr    .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; }  \n  dfb_adverts dfb_airplay dfb_attract cooks_d standard_resid hat_diag dffits_internal student_resid dffits     23 -0.000441 -0.009346 0.000516 0.000159 -0.238252 0.008315 -0.021816 -0.237486 -0.021746   33 -0.005728 0.022027 -0.020366 0.000221 -0.152693 0.027656 -0.025751 -0.152185 -0.025666   117 -0.004076 0.000292 -0.001237 0.000026 -0.133886 0.004372 -0.008872 -0.133438 -0.008842   93 -0.054948 -0.212492 0.243871 0.020558 1.247608 0.038112 0.248342 1.249992 0.248816   64 -0.029928 -0.040401 0.068245 0.001846 0.489364 0.022606 0.074423 0.488095 0.074230   ... ... ... ... ... ... ... ... ... ...   153 -0.050052 0.055071 -0.006892 0.002166 0.452345 0.030779 0.080610 0.451118 0.080391   130 0.002361 0.053852 -0.030313 0.001554 0.697670 0.009485 0.068270 0.696447 0.068151   104 -0.048983 0.167837 -0.092858 0.010958 0.829723 0.045577 0.181316 0.828839 0.181123   161 0.094157 0.025861 -0.098308 0.005490 -1.127330 0.012794 -0.128339 -1.128377 -0.128458   183 -0.028555 -0.003881 0.015144 0.000299 -0.089645 0.100417 -0.029951 -0.089342 -0.029850     1 2 3 4 5 6 7  album_sales_diagnostics = pd.concat([x_train,y_train],axis=1) album_sales_diagnostics['cook'] = infl.cooks_distance[0] album_sales_diagnostics['resid_std'] = infl.resid_studentized album_sales_diagnostics[['dfbeta_adverts','dfbeta_airplay','dfbeta_attract']] = infl.dfbeta album_sales_diagnostics['covariance'] = infl.cov_ratio album_sales_diagnostics.head()    .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; }  \n  adverts airplay attract sales cook resid_std dfbeta_adverts dfbeta_airplay dfbeta_attract covariance     23 656.137 34 7 210 0.000159 -0.238252 -0.000004 -0.002884 0.000760 1.028055   33 759.862 6 7 130 0.000221 -0.152693 -0.000047 0.006798 -0.030006 1.049221   117 624.538 20 5 150 0.000026 -0.133886 -0.000033 0.000090 -0.001823 1.024796   93 268.598 1 7 140 0.020558 1.247608 -0.000445 -0.065233 0.357433 1.027779   64 391.749 22 9 200 0.001846 0.489364 -0.000243 -0.012459 0.100476 1.039201     영향력이 큰 사례\ncook distance가 큰 순서대로 정렬\n 4/표본수 이상이면 영향력이 크다고 할 수 있음.  1 2  album.resid_std = np.abs(album.resid_std) album.sort_values(by = ['cook','resid_std'],ascending=[False, False])    .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; }  \n  adverts airplay attract sales cook resid_std dfbeta_adverts dfbeta_airplay dfbeta_attract covariance     168 145.585 42 8 360 0.075704 3.067079 -0.002579 0.071664 0.107867 0.857218   0 10.256 43 10 330 0.065682 2.262619 -0.002828 0.025215 0.302940 0.953043   118 912.349 57 6 230 0.053361 1.709781 -0.000618 -0.111819 0.430083 1.013622   99 1000.000 5 7 250 0.050402 2.064131 0.001338 -0.098943 0.371103 0.967650   54 1542.329 33 8 190 0.050391 2.267631 -0.002619 0.004308 0.094568 0.944246   ... ... ... ... ... ... ... ... ... ... ...   79 15.313 22 5 110 0.000026 0.092506 0.000056 -0.000595 -0.005664 1.029915   117 624.538 20 5 150 0.000026 0.133886 -0.000033 0.000090 -0.001823 1.024796   179 26.598 47 8 220 0.000025 0.045893 0.000048 -0.001569 -0.000459 1.056691   141 893.355 26 6 210 0.000023 0.089516 0.000044 0.000217 -0.001188 1.029495   109 102.568 22 7 140 0.000013 0.050878 -0.000035 -0.000455 0.007294 1.036476     데이터 출처 : SpringSchool\n","description":"","tags":null,"title":"회귀 분석을 이용한 앨범 판매량 분석 및 예측","uri":"/posts/data_science/machine_learning/regress/"},{"categories":["Data_Science","Association_Rule"],"content":"연관 분석 ` 거래 또는 사건들 간의 규칙을 발견하여 IF-THEN 구조로 결과의 연관성을 파악\n연관 규칙 측도  지지도(support) : 전체 거래 중 A와 B를 동시에 포함하는 비율  $P(A \\cap B) $   신뢰도(confidence) : A 거래중 A와 B를 동시에 포함하는 비율  $P(B | A)$   향상도(lift) : A가 구매되지 않았을 때 B의 구매확률에 비해 A가 구매되었을 때 B의 구매확률의 증가비  $P(B | A) / P(B)$    Apriori 최소 지지도 이상의 빈발항목집합을 찾은 후 연관규칙 계산\n apply 회차와 6개 숫자 정보가 있는 로또 데이터를 이용\n1 2 3 4 5  import numpy as np import pandas as pd lotto = pd.read_csv('data/lotto.csv') lotto.time_id = lotto['time_id'].astype('str') lotto.head()    .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; }  \n  time_id num1 num2 num3 num4 num5 num6     0 859 8 22 35 38 39 41   1 858 9 13 32 38 39 43   2 857 6 10 16 28 34 38   3 856 10 24 40 41 43 44   4 855 8 15 17 19 43 44     1 2  # pd.melt(lotto, id_vars='time_id') lotto_ary = lotto.set_index('time_id').T.to_dict('list')   Transaction data로 변환하기 각 아이템이 있는지 없는지 보여줌\n1 2 3 4 5  from mlxtend.preprocessing import TransactionEncoder te = TransactionEncoder() te_ary = te.fit(lotto_ary.values()).transform(lotto_ary.values()) df = pd.DataFrame(te_ary, columns=te.columns_) df.head()   1 2 3 4 5 6 7  from mlxtend.preprocessing import TransactionEncoder from mlxtend.frequent_patterns import apriori, association_rules fre_set = apriori(df, min_support=0.002, use_colnames=True) # 최소 지지도 0.002 # fre_set['length'] = fre_set['itemsets'].apply(lambda x: len(x)) fre_rule = association_rules(fre_set,metric=\"confidence\", min_threshold=0.8) # 최소 신뢰도 0.8   1  fre_rule.sort_values(by=\"lift\",ascending=False).iloc[:10,:]    .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; }  \n  antecedents consequents antecedent support consequent support support confidence lift leverage conviction     703 (16, 26, 31) (43, 36) 0.002328 0.012806 0.002328 1.0 78.090909 0.002298 inf   643 (24, 34, 22) (31, 7) 0.002328 0.012806 0.002328 1.0 78.090909 0.002298 inf   642 (34, 31, 7) (24, 22) 0.002328 0.012806 0.002328 1.0 78.090909 0.002298 inf   682 (26, 21, 14) (18, 15) 0.002328 0.013970 0.002328 1.0 71.583333 0.002296 inf   652 (34, 10, 36) (44, 22) 0.002328 0.013970 0.002328 1.0 71.583333 0.002296 inf   646 (24, 22, 31) (34, 7) 0.002328 0.013970 0.002328 1.0 71.583333 0.002296 inf   666 (24, 20, 15) (12, 30) 0.002328 0.013970 0.002328 1.0 71.583333 0.002296 inf   702 (16, 26, 43) (36, 31) 0.002328 0.013970 0.002328 1.0 71.583333 0.002296 inf   700 (16, 43, 36) (26, 31) 0.002328 0.015134 0.002328 1.0 66.076923 0.002293 inf   653 (34, 10, 22) (36, 44) 0.002328 0.016298 0.002328 1.0 61.357143 0.002290 inf      번호 개수를 시각화보면 다음과 같다\n1 2 3 4 5  k = [] data = np.array([k+_ for _ in lotto_ary.values()]).flatten() data = pd.Series(data) import seaborn as sns sns.barplot(x=data.value_counts(ascending=False).index[:10] ,y = data.value_counts(ascending=False)[:10], order=data.value_counts(ascending=False).index[:10])   34가 제일 많이 나와서 34가 나오는 규칙을 추출해 보았다.\n1  fre_rule[conse.astype('str').str.contains('34')]   여기서 향상도는 6.4정도로 나오는데 1번 규칙만 살펴보면 34만 추출된 것 보다 1,5,13이 뽑히고 34가 뽑힐 확률이 6.4배 정도 된다는 뜻이다. 하지만 순서를 고려하지 않고 단순히 조합에 대한 확률만 고려한 규칙이라 여기서는 향상도가 높은 조합이 추첨번호가 될 가능성이 높은 것은 아님.\n그 외에도 인사이트를 찾아보기 위해 describe() 등 해보는 게 좋음.\n데이터 출처 : 데이터 에듀 adp 모의고사\n","description":"","tags":null,"title":"연관 분석","uri":"/posts/data_science/association_rule/asso/"},{"categories":["Data_Science","Statistics"],"content":"1. 통계적 가설 검정 `모집단의 특성에 대한 가설에 대한 통계적 유의성 검정 - 통계적 유의성 -\u003e 확률적으로 봐서 단순한 우연이 아님\n과정\n 귀무 가설 대립 가설 설정 검정 통계량 설정 기각역 설정 검정통계량 계산 의사 결정  가설 검정 오류\n제 1종 오류 : 참인데 거짓이라 함\n제 2종 오류 : 거짓인데 참\np-value : 귀무 가설이 맞다고 가정할 때 얻은 결과와 다른 결과가 관측될 확률, 귀무 가설을 기각할 근거가 됨.\n 1  from scipy.stats import *   T 검정 1 2 3  # 단일 표본 검정 ttest_1samp(ser_1, popmean = 5) # pvalue가 대략적으로 0.05 미만이면기각   Ttest_1sampResult(statistic=-2.499999999999999, pvalue=0.04652823228416732)  1 2  # 대응 표본 검정 ttest_rel(ser_1, ser_2)   Ttest_relResult(statistic=-1.219715097075045, pvalue=0.2683379268893624)  1 2  # 독립 표본 검정(등분산 X) ttest_ind(ser_1, ser_2, equal_var = False)   Ttest_indResult(statistic=-1.684024198163435, pvalue=0.11958234592838302)  독립성 검정(카이제곱 검정) 1 2 3 4 5 6  df_chi2 = pd.DataFrame({\"ID\": [\"A\", \"A\", \"A\", \"A\", \"A\", \"B\", \"B\", \"B\", \"B\", \"B\"], \"YN\": [\"Y\", \"N\", \"N\", \"Y\", \"N\", \"Y\", \"Y\", \"N\", \"Y\", \"Y\"]}) df_crosstab = pd.crosstab(df_chi2[\"ID\"], df_chi2[\"YN\"]) chi2_contingency(df_crosstab) # 통계량, P-VALUE, DF, 기대도수   (0.41666666666666663, 0.5186050164287255, 1, array([[2., 3.], [2., 3.]]))  1  df_crosstab    .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; }  \n YN N Y   ID       A 3 2   B 1 4     정규성 정규성을 만족하는지 확인하는 방법은 shapiro, kstest, qqplot 등이 있다.\n1 2 3 4 5  ser_nor = pd.Series([4, 2, 5, 6, 7, 4, 5, 2, 6, 1, 3, 0, 15]) from scipy.stats import shapiro shapiro(ser_nor) # 통계량, p-value, 0.05이상이어야 정규성을 만족한다 할 수 있음.   (0.8451933264732361, 0.02470559999346733)  정규성 검정은 샘플 개수에 대해 민감한 편이므로 여러 방면으로 확인해 보는 것이 좋다.\n등분산성 정규성을 만족하는 경우와 아닌 경우\n1 2 3 4 5 6  # 표본이 정규성 ser_1 = pd.Series([2, 5, 3, 4, 6, 2, 3]) ser_2 = pd.Series([7, 3, 6, 5, 2, 6, 7]) bartlett(ser_1, ser_2)   BartlettResult(statistic=0.3574441170696212, pvalue=0.549929145265077)  1 2  # 표본이 정규 X levene(ser_1, ser_2)   LeveneResult(statistic=0.1666666666666668, pvalue=0.6902818588864357)   일원분산분석(Anova) 셋 이상의 그룹에서 차이가 존재하는지 확인\n1 2 3 4 5 6 7 8 9 10 11 12 13  ser_1 = pd.Series([2, 5, 3, 4, 6, 2, 3]) ser_2 = pd.Series([7, 3, 6, 5, 2, 6, 7]) ser_3 = pd.Series([9, 11, 4, 8, 2, 15, 3]) df_aov = pd.DataFrame([ser_1, ser_2, ser_3]).transpose().melt() from statsmodels.formula.api import ols from statsmodels.stats.anova import anova_lm formula = \"value ~ C(variable)\" # C() 범주형 변수임을 명시 lm = ols(formula, df_aov).fit() anova_lm(lm) # p-value 0.05이하여야 유의미한 차이가 있다고 할 수 있음.    .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; }  \n  df sum_sq mean_sq F PR(\u003eF)     C(variable) 2.0 52.666667 26.333333 2.783557 0.088449   Residual 18.0 170.285714 9.460317 NaN NaN     사후 검정 1 2 3  from statsmodels.stats.multicomp import pairwise_tukeyhsd print(pairwise_tukeyhsd(df_aov[\"value\"], df_aov[\"variable\"])) # reject가 true면 차이 있음   Multiple Comparison of Means - Tukey HSD, FWER=0.05 =================================================== group1 group2 meandiff p-adj lower upper reject --------------------------------------------------- 0 1 1.5714 0.6082 -2.6229 5.7658 False 0 2 3.8571 0.0746 -0.3372 8.0515 False 1 2 2.2857 0.3675 -1.9087 6.4801 False ---------------------------------------------------   상관분석 연속형 변수 간에 선형 관계 파악\n1 2  df = pd.DataFrame([ser_1, ser_2, ser_3]).T pd.plotting.scatter_matrix(df);   1 2 3 4  print(pearsonr(df.iloc[:,0], df.iloc[:,1])) print(pearsonr(df.iloc[:,1], df.iloc[:,2])) print(pearsonr(df.iloc[:,0], df.iloc[:,2])) # 상관계수, p-value, 0.05미만이면 유의한 상관성이 있다고 봄   (-0.9359709753334592, 0.0019245719846704063) (0.13695501944225102, 0.7696722723761817) (-0.4136643973298085, 0.3562507831530036)   스피어만 : 두 변수 순위의 단조 관련성을 측정. 변수의 분포가 심각하게 정규성을 벗어나거나 순위형 자료일 때 사용  1 2  # 스피어만 상관계수를 dataframe으로 보기 df.corr(method = 'spearman')   비선형 관계를 보려면 시각화 해보는 게 좋음\n","description":"","tags":null,"title":"가설 검정","uri":"/posts/data_science/statistics/stat1/"},{"categories":["Algorithm","study9"],"content":"`\n다익스트라 방식으로 풀었고 거리계산에서 다음과 같이 처리\ndist[next] = max(dist[next], min(dist[cur],cost(cur,next))\n우선순위 큐 활용해야 $O(VlogE)$ 에 가능\n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74  import java.io.BufferedReader; import java.io.IOException; import java.io.InputStreamReader; import java.util.ArrayList; import java.util.PriorityQueue; import java.util.StringTokenizer; public class B13905 { static int N,M,S,E; static class Edge implements Comparable\u003cEdge\u003e{ int end; int value; Edge(int end, int value) { this.end = end; this.value = value; } @Override public int compareTo(Edge o) { // 내림차순으로 해야 정확한 비교가 가능함 \treturn o.value - value; } } public static void main(String[] args) throws IOException { BufferedReader br = new BufferedReader(new InputStreamReader(System.in)); StringTokenizer st = new StringTokenizer(br.readLine()); N= Integer.parseInt(st.nextToken()); M= Integer.parseInt(st.nextToken()); ArrayList\u003cEdge\u003e edges[] = new ArrayList[N+1]; int[] dist = new int[N+1]; boolean visit[] = new boolean[N+1]; for(int i = 0;i\u003c=N;i++) { edges[i] = new ArrayList\u003cEdge\u003e(); } st = new StringTokenizer(br.readLine()); S= Integer.parseInt(st.nextToken()); E= Integer.parseInt(st.nextToken()); dist[S] = Integer.MAX_VALUE; for (int i = 0; i \u003c M; i++) { st = new StringTokenizer(br.readLine()); int start = Integer.parseInt(st.nextToken()); int end = Integer.parseInt(st.nextToken()); int w = Integer.parseInt(st.nextToken()); edges[start].add(new Edge(end,w)); edges[end].add(new Edge(start,w)); } PriorityQueue \u003cEdge\u003e pq = new PriorityQueue \u003cEdge\u003e(); pq.add(new Edge(S,0));\twhile(!pq.isEmpty()) { Edge cur = pq.poll(); if(visit[cur.end]) continue; visit[cur.end] = true; // 모든 길을 보고 각 루트의 최소값 구하고 최대값으로 update \tfor(int i =0 ;i \u003c edges[cur.end].size();i++) { int next = edges[cur.end].get(i).end; int cost = edges[cur.end].get(i).value; dist[next]= Math.max(dist[next], Math.min(dist[cur.end], cost)); pq.add(edges[cur.end].get(i)); } } System.out.println(dist[E]); } }   ","description":"","tags":null,"title":"[백준]13905 세부","uri":"/posts/algorithm/study9/%EB%B0%B1%EC%A4%80_13905/"},{"categories":["Algorithm","study9"],"content":"` 시뮬레이션 + dfs\n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109  import java.io.BufferedReader; import java.io.IOException; import java.io.InputStreamReader; import java.util.StringTokenizer; public class B20058 { static int N, Q, sum, count, max; static int arr[][], delta[][] = {{0,1},{1,0},{0,-1},{-1,0}}; static boolean[][] visit, check; public static void main(String[] args) throws IOException { BufferedReader br = new BufferedReader(new InputStreamReader(System.in)); StringTokenizer st = new StringTokenizer(br.readLine()); N = Integer.parseInt(st.nextToken()); Q = Integer.parseInt(st.nextToken()); arr = new int[1\u003c\u003cN][1\u003c\u003cN]; for (int i = 0; i \u003c 1\u003c\u003cN; i++) { st = new StringTokenizer(br.readLine()); for (int j = 0; j \u003c 1\u003c\u003cN; j++) { arr[i][j] = Integer.parseInt(st.nextToken()); } } st = new StringTokenizer(br.readLine()); for (int i = 0; i \u003c Q; i++) { int K = Integer.parseInt(st.nextToken()); rotate(K); melt(); } // 다른 것에 포함되었는지 확인 여부 \tvisit = new boolean[1\u003c\u003cN][1\u003c\u003cN]; for (int i = 0; i \u003c 1\u003c\u003cN; i++) { for (int j = 0; j \u003c 1\u003c\u003cN; j++) { visit[i][j] = true; sum+=arr[i][j]; // 시작이 0인지 여부 \tcount=arr[i][j]!=0?1:0; counting(i,j); max = Math.max(count, max); } } System.out.println(sum+\"\\n\"+max); } // 나눠진 구간에 대해 90도 회전 \tprivate static void rotate(int r) { int[][] copy = new int[1\u003c\u003cN][1\u003c\u003cN]; int k = 1\u003c\u003cr; for(int i=0;i\u003c1\u003c\u003cN;i+=k) { for(int j=0;j\u003c1\u003c\u003cN;j+=k) { for(int a = 0; a \u003c k; a++) { for(int b = 0; b \u003c k ; b++) { copy[i+b][j+k-a-1] = arr[i+a][j+b]; } } } } arr = copy; } public static void melt() { // 녹일 얼음 찾을 배열  check = new boolean[1\u003c\u003cN][1\u003c\u003cN]; for(int i = 0; i \u003c 1\u003c\u003cN; i++) { for(int j = 0; j \u003c 1\u003c\u003cN; j++) { // 0일 때 skip  if(arr[i][j]==0) continue; int count = 0; for(int k = 0; k \u003c 4; k++) { int nx = i + delta[k][0]; int ny = j + delta[k][1]; // 주변에 얼음이 있으면 counting  if(inside(nx, ny) \u0026\u0026 arr[nx][ny] \u003e= 1) count++; } // 3면보다 작은거 체크  if(count \u003c 3) { check[i][j] = true; } } } for(int i = 0; i \u003c 1\u003c\u003cN; i++) { for(int j = 0; j \u003c 1\u003c\u003cN; j++) { if(check[i][j]) arr[i][j]--; } } } // dfs : 붙어있는 얼음 개수 세기 \tprivate static void counting(int x, int y) { for(int d=0;d\u003c4;d++) { int nx = x + delta[d][0]; int ny = y + delta[d][1]; if(inside(nx,ny)\u0026\u0026!visit[nx][ny] \u0026\u0026 arr[nx][ny]\u003e=1) { visit[nx][ny] = true; count++; counting(nx,ny); } } } public static boolean inside(int x, int y) { return x \u003e= 0 \u0026\u0026 y \u003e= 0 \u0026\u0026 x \u003c 1\u003c\u003cN \u0026\u0026 y \u003c 1\u003c\u003cN; } }   ","description":"","tags":null,"title":"[백준]20058 마법사 상어와 파이어 스톰","uri":"/posts/algorithm/study9/%EB%B0%B1%EC%A4%80_20058/"},{"categories":["Data_Science","Data_Handling"],"content":"melt\n1 2 3 4 5 6  ser_1 = pd.Series([2, 5, 3, 4, 6, 2, 3]) ser_2 = pd.Series([7, 3, 6, 5, 2, 6, 7]) ser_3 = pd.Series([9, 11, 4, 8, 2, 15, 3]) df_aov = pd.DataFrame([ser_1, ser_2, ser_3]).transpose().melt() df_aov   ` id_vars로 id를 지정할 수 있는데 칼럼으로 들어감\ncut\n값을 기반으로 이산화\n1  pd.cut([5, 20, 29, 33, 41], bins = 5, right = False)   [[5.0, 12.2), [19.4, 26.6), [26.6, 33.8), [26.6, 33.8), [33.8, 41.036)] Categories (5, interval[float64]): [[5.0, 12.2) \u003c [12.2, 19.4) \u003c [19.4, 26.6) \u003c [26.6, 33.8) \u003c [33.8, 41.036)]  qcut\n특정 분위수를 계산해 이산화\n1  pd.qcut([5, 20, 29, 33, 41], [0,0.2,0.4,0.6,0.8,1])   [(4.999, 17.0], (17.0, 25.4], (25.4, 30.6], (30.6, 34.6], (34.6, 41.0]] Categories (5, interval[float64]): [(4.999, 17.0] \u003c (17.0, 25.4] \u003c (25.4, 30.6] \u003c (30.6, 34.6] \u003c (34.6, 41.0]]   재구조화 : pivot_table\npd.pivot_table(data, index, columns, values, aggfunc)\n1 2 3 4 5 6 7 8  import numpy as np import pandas as pd data = pd.DataFrame({'cust_id': ['c1', 'c1', 'c1', 'c2', 'c2', 'c2', 'c3', 'c3', 'c3'], 'prod_cd': ['p1', 'p2', 'p3', 'p1', 'p2', 'p3', 'p1', 'p2', 'p3'], 'grade' : ['A', 'A', 'A', 'A', 'A', 'A', 'B', 'B', 'B'], 'pch_amt': [30, 10, 0, 40, 15, 30, 0, 0, 10]}) data    .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; }  \n  cust_id prod_cd grade pch_amt     0 c1 p1 A 30   1 c1 p2 A 10   2 c1 p3 A 0   3 c2 p1 A 40   4 c2 p2 A 15   5 c2 p3 A 30   6 c3 p1 B 0   7 c3 p2 B 0   8 c3 p3 B 10     1  data.pivot(index='cust_id', columns='prod_cd', values='pch_amt')    .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; }  \n prod_cd p1 p2 p3   cust_id        c1 30 10 0   c2 40 15 30   c3 0 0 10      aggfuc : 중복되는 값이 여러 개 있을 경우 집계할 수 있는 함수 제공  1  pd.pivot_table(data, index='grade', columns='prod_cd', values='pch_amt', aggfunc=np.mean)    .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; }  \n prod_cd p1 p2 p3 All   grade         A 35.000000 12.500000 15.000000 20.833333   B 0.000000 0.000000 10.000000 3.333333   All 23.333333 8.333333 13.333333 15.000000      margins=True : 모든 행과 열 기준으로 집계  1  pd.pivot_table(data, index='grade', columns='prod_cd', values='pch_amt', aggfunc=np.sum, margins=True)    .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; }  \n prod_cd p1 p2 p3 All   grade         A 70 25 30 125   B 0 0 10 10   All 70 25 40 135      stack, unstack\n stack : 위에서 아래로 쌓는 것 unstack 쌓은 것을 왼쪽에서 오른쪽으로 늘어놓는 것  1 2 3 4  mul_index = pd.MultiIndex.from_tuples([('cust_1', '2015'), ('cust_1', '2016'),('cust_2', '2015'), ('cust_2', '2016')]) data = pd.DataFrame(data=np.arange(16).reshape(4, 4), index=mul_index,columns=['prd_1', 'prd_2', 'prd_3', 'prd_4'], dtype='int') data    .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; }  \n   prd_1 prd_2 prd_3 prd_4     cust_1 2015 0 1 2 3   2016 4 5 6 7   cust_2 2015 8 9 10 11   2016 12 13 14 15     1  data.stack(level = -1, dropna=False)   cust_1 2015 prd_1 0 prd_2 1 prd_3 2 prd_4 3 2016 prd_1 4 prd_2 5 prd_3 6 prd_4 7 cust_2 2015 prd_1 8 prd_2 9 prd_3 10 prd_4 11 2016 prd_1 12 prd_2 13 prd_3 14 prd_4 15 dtype: int32   level은 default로 -1로 상위에 있는 것을 올리고 내림.  1  data.unstack(level=-1)    .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead tr th { text-align: left; }  \n   prd_1 prd_2 prd_3 prd_4    2015 2016 2015 2016 2015 2016 2015 2016     cust_1 0 4 1 5 2 6 3 7   cust_2 8 12 9 13 10 14 11 15      level이 0 이상 숫자 : 왼쪽에서 숫자만큼의 index 칼럼을 올림  1  data.unstack(level=0)    .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead tr th { text-align: left; }  \n   prd_1 prd_2 prd_3 prd_4    cust_1 cust_2 cust_1 cust_2 cust_1 cust_2 cust_1 cust_2     2015 0 8 1 9 2 10 3 11   2016 4 12 5 13 6 14 7 15     1  data.unstack(level=1)    .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead tr th { text-align: left; }  \n   prd_1 prd_2 prd_3 prd_4    2015 2016 2015 2016 2015 2016 2015 2016     cust_1 0 4 1 5 2 6 3 7   cust_2 8 12 9 13 10 14 11 15     multi index 교차표\npd.crosstab([id1, id2], [col1, col2])\n","description":"","tags":null,"title":"pandas 사용","uri":"/posts/data_science/data_handling/pandas/"},{"categories":["Algorithm","study9"],"content":"` dfs + backtracking\n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57  import java.io.BufferedReader; import java.io.IOException; import java.io.InputStreamReader; import java.util.StringTokenizer; public class B16432 { static int N, K; static boolean flag; static int arr[][], dp[]; static boolean[][] visit; public static void main(String[] args) throws IOException { BufferedReader br = new BufferedReader(new InputStreamReader(System.in)); StringBuilder sb = new StringBuilder(); StringTokenizer st; N = Integer.parseInt(br.readLine()); arr = new int[N][10]; visit = new boolean[N+1][10]; dp = new int[N]; for(int i=0;i\u003cN;i++) { st = new StringTokenizer(br.readLine()); K = Integer.parseInt(st.nextToken()); for (int j = 0; j \u003c K; j++) { arr[i][Integer.parseInt(st.nextToken())] = 1; } } get(0,0); if(flag) { for(int i=0;i\u003cN;i++) { sb.append(dp[i]).append(\"\\n\"); } }else sb.append(-1); System.out.println(sb); } private static void get(int num, int next) { if(next==N) { flag = true; return; } for (int i = 1; i \u003c 10; i++) { /// 이전 값과 비교하고 다음 값 있는지 확인 \tif(num==i) continue; if(arr[next][i]==1 \u0026\u0026 !visit[next+1][i]) { // 재방문해도 아래쪽 결과는 같으므로 다시 방문하지 않아도 됨 \tvisit[next+1][i] = true; dp[next]=i; get(i,next+1); if(flag) return; } } } }   ","description":"","tags":null,"title":"[백준]16234 떡장수와 호랑이","uri":"/posts/algorithm/study9/%EB%B0%B1%EC%A4%80_16234_/"},{"categories":["Data_Science","Time_Series"],"content":"2-1-1 : 코로나 인구대비 확진자수가 많은 상위 5개국 누적확진자수, 일일확진자수, 누적사망자수, 일일사망자수 선그래프로 시각화\n2-1-2 : 코로나 검사자수, 확진자수, 완치자수, 사망자수, 인구수를 바탕으로 위험지수를 만들고 그 지수를 바탕으로 국가별 위험도를 판단, 상위 10개국에 대해 위험지수 막대그래프로 시각화\n2-1-3 : 한국 누적 확진자수를 바탕으로 시계열 예측. 선형 시계열과 비선형 시계열 2가지로 모델링하고 평가. 5월 16일 이후 데이터로 테스트.\n1 2 3 4 5 6 7 8  import numpy as np import pandas as pd import seaborn as sns import matplotlib.pyplot as plt %matplotlib inline import statsmodels.api as sm from statsmodels.graphics.tsaplots import plot_acf, plot_pacf from statsmodels.tsa.seasonal import seasonal_decompose   1 2  corona = pd.read_csv('../data/covid_19_data.csv',index_col = 'ObservationDate',parse_dates=True) corona.info()   \u003cclass 'pandas.core.frame.DataFrame'\u003e DatetimeIndex: 109382 entries, 2020-01-22 to 2020-09-13 Data columns (total 7 columns): # Column Non-Null Count Dtype --- ------ -------------- ----- 0 SNo 109382 non-null int64 1 Province/State 75709 non-null object 2 Country/Region 109382 non-null object 3 Last Update 109382 non-null object 4 Confirmed 109382 non-null float64 5 Deaths 109382 non-null float64 6 Recovered 109382 non-null float64 dtypes: float64(3), int64(1), object(3) memory usage: 6.7+ MB  1  corona.head()    .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; }  \n  SNo Province/State Country/Region Last Update Confirmed Deaths Recovered   ObservationDate            2020-01-22 1 Anhui Mainland China 1/22/2020 17:00 1.0 0.0 0.0   2020-01-22 2 Beijing Mainland China 1/22/2020 17:00 14.0 0.0 0.0   2020-01-22 3 Chongqing Mainland China 1/22/2020 17:00 6.0 0.0 0.0   2020-01-22 4 Fujian Mainland China 1/22/2020 17:00 1.0 0.0 0.0   2020-01-22 5 Gansu Mainland China 1/22/2020 17:00 0.0 0.0 0.0     2-1-1 1  corona.index.unique()   DatetimeIndex(['2020-01-22', '2020-01-23', '2020-01-24', '2020-01-25', '2020-01-26', '2020-01-27', '2020-01-28', '2020-01-29', '2020-01-30', '2020-01-31', ... '2020-09-04', '2020-09-05', '2020-09-06', '2020-09-07', '2020-09-08', '2020-09-09', '2020-09-10', '2020-09-11', '2020-09-12', '2020-09-13'], dtype='datetime64[ns]', name='ObservationDate', length=236, freq=None)  1 2 3  last_day = corona.loc[corona.index == '2020-09-13'] last_day_country = last_day.groupby('Country/Region')[['Confirmed','Deaths','Recovered']].sum() last_day_country    .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; }  \n  Confirmed Deaths Recovered   Country/Region        Afghanistan 38716.0 1420.0 31638.0   Albania 11353.0 334.0 6569.0   Algeria 48254.0 1612.0 34037.0   Andorra 1344.0 53.0 943.0   Angola 3388.0 134.0 1301.0   ... ... ... ...   West Bank and Gaza 30574.0 221.0 20082.0   Western Sahara 10.0 1.0 8.0   Yemen 2011.0 583.0 1212.0   Zambia 13539.0 312.0 12260.0   Zimbabwe 7526.0 224.0 5678.0     1 2 3  Confirmed_list = last_day_country.sort_values(by='Confirmed',ascending=False)[:5].index Deaths_list = last_day_country.sort_values(by='Deaths',ascending=False)[:5].index last_day_country.sort_values(by='Confirmed',ascending=False)    .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; }  \n  Confirmed Deaths Recovered   Country/Region        US 6519573.0 194071.0 2451406.0   India 4754356.0 78586.0 3702595.0   Brazil 4330455.0 131625.0 3723206.0   Russia 1059024.0 18517.0 873684.0   Peru 722832.0 30526.0 559321.0   ... ... ... ...   Laos 23.0 0.0 21.0   Saint Kitts and Nevis 17.0 0.0 17.0   Holy See 12.0 0.0 12.0   Western Sahara 10.0 1.0 8.0   MS Zaandam 9.0 2.0 0.0     1  Confirmed_list   Index(['US', 'India', 'Brazil', 'Russia', 'Peru'], dtype='object', name='Country/Region')  1 2  Top_Confrimed = corona.loc[corona['Country/Region'].isin(Confirmed_list)] Top_Deaths = corona.loc[corona['Country/Region'].isin(Deaths_list)]   1 2  five_top_Confirmed = Top_Confrimed.groupby(['Country/Region','ObservationDate'])['Confirmed'].sum() five_top_Deaths = Top_Deaths.groupby(['Country/Region','ObservationDate'])['Deaths'].sum()   1 2  five_top_Confirmed.unstack('Country/Region').plot() five_top_Deaths.unstack('Country/Region').plot()   1 2 3 4  f_u = five_top_Confirmed.unstack('Country/Region') f_d = five_top_Deaths.unstack('Country/Region') one_day_Confirmed = f_u - f_u.shift(1) one_day_Deaths = f_d - f_d.shift(1)   1  one_day_Confirmed    .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; }  \n Country/Region Brazil India Peru Russia US   ObservationDate          2020-01-22 NaN NaN NaN NaN NaN   2020-01-23 NaN NaN NaN NaN 0.0   2020-01-24 NaN NaN NaN NaN 1.0   2020-01-25 NaN NaN NaN NaN 0.0   2020-01-26 NaN NaN NaN NaN 3.0   ... ... ... ... ... ...   2020-09-09 35816.0 95735.0 4615.0 5172.0 34256.0   2020-09-10 40557.0 96551.0 6586.0 5310.0 35286.0   2020-09-11 43718.0 97570.0 7291.0 5421.0 47192.0   2020-09-12 33523.0 94372.0 6603.0 5406.0 41471.0   2020-09-13 14768.0 0.0 6162.0 5361.0 34359.0     1 2 3  one_day_Confirmed.fillna(0).plot() one_day_Deaths.fillna(0).plot() plt.ylim(-100,5000)   (-100.0, 5000.0)  2-1-2  risk = (확진자 수 - 사망자 수 - 완치자 수)/(state * 10000) 국가별 1달 risk 계산 평균 -\u003e top 10  1 2 3  one_month = corona['2020-08-14':] a = one_month.groupby(['ObservationDate','Country/Region'])[['Confirmed','Deaths','Recovered']].sum() a    .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; }  \n   Confirmed Deaths Recovered   ObservationDate Country/Region        2020-08-14 Afghanistan 37431.0 1363.0 26714.0   Albania 7117.0 219.0 3695.0   Algeria 37664.0 1351.0 26308.0   Andorra 989.0 53.0 863.0   Angola 1852.0 86.0 584.0   ... ... ... ... ...   2020-09-13 West Bank and Gaza 30574.0 221.0 20082.0   Western Sahara 10.0 1.0 8.0   Yemen 2011.0 583.0 1212.0   Zambia 13539.0 312.0 12260.0   Zimbabwe 7526.0 224.0 5678.0     1  a.reset_index(level=0)    .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; }  \n  ObservationDate Confirmed Deaths Recovered   Country/Region         Afghanistan 2020-08-14 37431.0 1363.0 26714.0   Albania 2020-08-14 7117.0 219.0 3695.0   Algeria 2020-08-14 37664.0 1351.0 26308.0   Andorra 2020-08-14 989.0 53.0 863.0   Angola 2020-08-14 1852.0 86.0 584.0   ... ... ... ... ...   West Bank and Gaza 2020-09-13 30574.0 221.0 20082.0   Western Sahara 2020-09-13 10.0 1.0 8.0   Yemen 2020-09-13 2011.0 583.0 1212.0   Zambia 2020-09-13 13539.0 312.0 12260.0   Zimbabwe 2020-09-13 7526.0 224.0 5678.0     1 2 3  b = last_day.groupby('Country/Region')['SNo'].count() b.name = 'State_Num' b.sort_values(ascending=False)[:10]   Country/Region Russia 83 US 58 Japan 49 India 37 Colombia 33 Mexico 32 Mainland China 31 Ukraine 27 Brazil 27 Peru 26 Name: State_Num, dtype: int64  1  df = a.reset_index(level=0).join(b, how='left')   1  df.set_index('ObservationDate',append=True,inplace=True)   1  df    .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; }  \n   Confirmed Deaths Recovered State_Num   Country/Region ObservationDate         Afghanistan 2020-08-14 37431.0 1363.0 26714.0 1   2020-08-15 37551.0 1370.0 27166.0 1   2020-08-16 37596.0 1375.0 27166.0 1   2020-08-17 37599.0 1375.0 27166.0 1   2020-08-18 37599.0 1375.0 27166.0 1   ... ... ... ... ... ...   Zimbabwe 2020-09-09 7429.0 222.0 5542.0 1   2020-09-10 7453.0 222.0 5635.0 1   2020-09-11 7479.0 224.0 5660.0 1   2020-09-12 7508.0 224.0 5675.0 1   2020-09-13 7526.0 224.0 5678.0 1     1 2  df['risk_pi'] = (df['Confirmed'] - df['Deaths'] - df['Recovered'])/(df['State_Num']*10000) df.head()    .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; }  \n   Confirmed Deaths Recovered State_Num risk_pi   Country/Region ObservationDate          Afghanistan 2020-08-14 37431.0 1363.0 26714.0 1 0.9354   2020-08-15 37551.0 1370.0 27166.0 1 0.9015   2020-08-16 37596.0 1375.0 27166.0 1 0.9055   2020-08-17 37599.0 1375.0 27166.0 1 0.9058   2020-08-18 37599.0 1375.0 27166.0 1 0.9058     1 2 3 4 5  # last_day_country['risk_pi'] = (last_day_country['Confirmed']/1000000 - last_day_country['Recovered']/1000000)/1000000 # top_risk_list = last_day_country.sort_values(by='risk_pi',ascending=False)[:10] df_risk = df.groupby('Country/Region')['risk_pi'].mean() top_risk_list = df_risk.sort_values(ascending=False)[:10] top_risk_list   Country/Region Bangladesh 10.533694 Argentina 10.164006 South Africa 7.527106 US 6.239020 Philippines 6.162177 Belgium 5.627332 Iraq 5.155116 Bolivia 5.124435 Honduras 4.621997 Romania 4.466106 Name: risk_pi, dtype: float64  1  top_risk_list.plot.bar()   \u003cAxesSubplot:xlabel='Country/Region'\u003e  2-1-3 1 2 3  k_c = corona[corona['Country/Region']=='South Korea'] print(len(k_c)) print(len(k_c.index.unique()))   236 236  1  from statsmodels.tsa.stattools import adfuller # 정상성 판별 여부   1 2 3  k = k_c['Confirmed'] korea_co = (k - k.shift(1)).dropna() korea_co.plot()   \u003cAxesSubplot:xlabel='ObservationDate'\u003e  1 2  train = korea_co[:'2020-05-15'] test = korea_co['2020-05-16':'2020-06-15']   1  adfuller(train)   (-2.692880412737049, 0.07527839224613403, 5, 108, {'1%': -3.4924012594942333, '5%': -2.8886968193364835, '10%': -2.5812552709190673}, 1147.051801657943)  `1차 차분\n1 2  diff1 = (train - train.shift(1)).dropna() adfuller(diff1)   (-5.228238034317768, 7.697004182819284e-06, 2, 110, {'1%': -3.4912451337340342, '5%': -2.8881954545454547, '10%': -2.5809876033057852}, 1139.877102390829)  1 2 3  decomposition = seasonal_decompose(diff1) decomposition.plot() plt.show()   1 2  diff2 = (diff1 - diff1.shift(1)).dropna() adfuller(diff2)   (-6.291128356594684, 3.5970963612700875e-08, 6, 105, {'1%': -3.4942202045135513, '5%': -2.889485291005291, '10%': -2.5816762131519275}, 1140.9946617995597)  2차 차분\n1 2 3  decomposition = seasonal_decompose(diff2) decomposition.plot() plt.show()   1 2  plot_acf(diff1); plot_pacf(diff1);   1 2  model = sm.tsa.statespace.SARIMAX(train, order=[1,1,1],trend='t')   C:\\Users\\Gyu\\Anaconda3\\envs\\py37\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:165: ValueWarning: No frequency information was provided, so inferred frequency D will be used. % freq, ValueWarning)  1 2  result = model.fit() result.summary()   Statespace Model Results  Dep. Variable: Confirmed  No. Observations:  114   Model: SARIMAX(1, 1, 1)  Log Likelihood  -641.888   Date: Sun, 27 Sep 2020  AIC  1291.777   Time: 10:40:43  BIC  1302.687   Sample: 01-23-2020  HQIC  1296.204    - 05-15-2020       Covariance Type: opg         coef std err z P|z| [0.025 0.975]   drift  -0.0210  0.162  -0.129  0.897  -0.339  0.297   ar.L1  -0.1768  0.215  -0.821  0.412  -0.599  0.245   ma.L1  -0.0869  0.199  -0.437  0.662  -0.476  0.302   sigma2  5025.8920  309.739  16.226  0.000  4418.815  5632.969    Ljung-Box (Q): 34.23  Jarque-Bera (JB):  350.68   Prob(Q): 0.73  Prob(JB):  0.00   Heteroskedasticity (H): 0.01  Skew:  -0.03   Prob(H) (two-sided): 0.00  Kurtosis:  11.63  Warnings:[1] Covariance matrix calculated using the outer product of gradients (complex-step). 1  pred = result.predict(start='2020-05-16',end='2020-06-15')   1 2 3  train.plot(label='Train') test.plot(label='Test') pred.plot(label='pred')   \u003cAxesSubplot:xlabel='ObservationDate'\u003e  1 2  from sklearn.metrics import mean_squared_error mean_squared_error(test,pred)   3631.3045190567364  1 2 3 4  model = sm.tsa.statespace.SARIMAX(train, order=[1,1,1], trend = [0,1,1]) result = model.fit() result.summary()   C:\\Users\\Gyu\\Anaconda3\\envs\\py37\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:165: ValueWarning: No frequency information was provided, so inferred frequency D will be used. % freq, ValueWarning)  Statespace Model Results  Dep. Variable: Confirmed  No. Observations:  114   Model: SARIMAX(1, 1, 1)  Log Likelihood  -641.925   Date: Sun, 27 Sep 2020  AIC  1293.851   Time: 10:42:26  BIC  1307.488   Sample: 01-23-2020  HQIC  1299.384    - 05-15-2020       Covariance Type: opg         coef std err z P|z| [0.025 0.975]   drift  -0.0008  0.735  -0.001  0.999  -1.441  1.439   trend.2  -0.0002  0.016  -0.015  0.988  -0.031  0.031   ar.L1  -0.1758  0.224  -0.785  0.433  -0.615  0.263   ma.L1  -0.0878  0.207  -0.425  0.671  -0.493  0.317   sigma2  5216.6180  347.385  15.017  0.000  4535.756  5897.480    Ljung-Box (Q): 34.24  Jarque-Bera (JB):  350.89   Prob(Q): 0.73  Prob(JB):  0.00   Heteroskedasticity (H): 0.01  Skew:  -0.04   Prob(H) (two-sided): 0.00  Kurtosis:  11.63  Warnings:[1] Covariance matrix calculated using the outer product of gradients (complex-step). 1 2 3 4  pred = result.predict(start='2020-05-16',end='2020-06-15') train.plot(label='Train') test.plot(label='Test') pred.plot(label='pred')   \u003cAxesSubplot:xlabel='ObservationDate'\u003e  1  mean_squared_error(test,pred)   6478.176590606611  1 2 3 4  from statsmodels.tsa.api import ExponentialSmoothing model = ExponentialSmoothing(np.asarray(train), trend='add') model_result = model.fit()   1  model_result.summary()   ExponentialSmoothing Model Results  Dep. Variable: endog  No. Observations:  114   Model: ExponentialSmoothing  SSE  571027.819   Optimized: True  AIC  979.165   Trend: Additive  BIC  990.110   Seasonal: None  AICC  979.950   Seasonal Periods: None  Date:  Sun, 27 Sep 2020   Box-Cox: False  Time:  10:46:34   Box-Cox Coeff.: None         coeff code optimized   smoothing_level  0.7647937  alpha  True   smoothing_slope  0.000000  beta  True   initial_level  0.000000  l.0  True   initial_slope  0.1845664  b.0  True   1 2 3  y_hat = pd.DataFrame(test.copy()) y_hat['ES'] = model_result.forecast(len(test)) mean_squared_error(y_hat['Confirmed'],y_hat['ES'])   360.9693621017652  1 2 3 4  train.plot(label='Train') test.plot(label='Test') y_hat['ES'].plot(label='ES') plt.legend()   1 2 3  model = ExponentialSmoothing(np.asarray(train+1),trend='mul') model_result = model.fit() model_result.summary()   ExponentialSmoothing Model Results  Dep. Variable: endog  No. Observations:  114   Model: ExponentialSmoothing  SSE  559193.862   Optimized: True  AIC  976.778   Trend: Multiplicative  BIC  987.723   Seasonal: None  AICC  977.563   Seasonal Periods: None  Date:  Sun, 27 Sep 2020   Box-Cox: False  Time:  10:47:32   Box-Cox Coeff.: None         coeff code optimized   smoothing_level  0.7749651  alpha  True   smoothing_slope  0.000000  beta  True   initial_level  0.4787151  l.0  True   initial_slope  0.9574234  b.0  True   1 2 3  y_hat = pd.DataFrame(test.copy()) y_hat['ES'] = model_result.forecast(len(test)) mean_squared_error(y_hat['Confirmed'],y_hat['ES'])   995.7063961726025  1 2 3 4  train.plot(label='Train') test.plot(label='Test') y_hat['ES'].plot(label='ES') plt.legend()   \u003cmatplotlib.legend.Legend at 0x2212c6de470\u003e  ","description":"","tags":null,"title":"Corona 확진자 분석 및 시계열 예측","uri":"/posts/data_science/time_series/corona/"},{"categories":["Algorithm","Graph"],"content":"그래프 `정점들의 집합과 이들을 연결하는 간선들의 집합\n그래프 표현 인접 행렬\nN*N의 행렬을 이용\n 인접된 부분에 연결되어 있으면 1을 주거나 가중치 부여 희소 행렬에서 비효율적  인접 리스트\n정점에 대한 인접 정점들을 노드로 하는 연결 리스트로 저장\n 노드 추가, 삭제가 빈번한 경우 사용하기 좋음  간선 리스트\n간선 자체를 객체로 표현하고 두 정점의 정보를 가짐\n그래프 탐색   BFS\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23  void bfs(int start){ Queue\u003cInteger\u003e queue = new LinkedList\u003c\u003e(); queue.add(start); // 생성, 삽입  visited[start] = true; //방문 표시  int depth = 0; while (!queue.isEmpty()) { int size = queue.size(); while (size-- \u003e 0) { int head = queue.poll(); sb.append(head).append(\" \"); // 결과 저장  // 연결된 모든 간선 탐색  List\u003cInteger\u003e childs = graph2[head]; for (int i = 0; i \u003c childs.size(); i++) { if (!visited[childs.get(i)]) { // 방문하지 않은 곳 탐색  visited[childs.get(i)] = true; queue.add(childs.get(i)); // 방문 표시, 큐에 넣기  } } } } }     DFS\n1 2 3 4 5 6 7 8 9 10 11 12 13  void dfs(int node){ visited[node] = true; // 방문 표시  // 사용  sb.append(node).append(\" \"); // 결과 저장  // 연결된 모든 간선 탐색  List\u003cInteger\u003e nodes = graph2[node]; for (Integer child : nodes) { if (!visited[child]) { dfs2(child); // 자식 재귀 탐색  } } }     서로소 집합 (Disjoint-set)   중복 포함된 원소가 없는 집합들\n  집합에 속한 한 특정 멤버를 통해 집합을 구분 ⇒ 대표자\n  연결리스트나 트리, 배열로 disjoint-sets를 표현 가능\n  연산\nMake-Set(x) : 유일한 멤버 x를 포함하는 새로운 집합을 생성\nFind-Set(x) : x를 포함하는 집합을 찾음\nUnion(x, y) : x와 y를 포함하는 두 집합을 통합 (x의 부모를 y의 부모로)\n  문제점 depth가 너무 깊어지는 경우 → Rank, Path compression\nRank\n 각 노드가 자신을 루트로 하는 subtree의 높이를 Rank라는 이름으로 저장 두 집합을 합칠 때 rank가 낮은 집합을 랭크가 높은 집합에 붙이기  rank가 같을 경우, key 기준을 통해 판단. 정해진 집합은 rank 1 증가    Path compression\n Find-Set 과정에서 만나는 모든 노드들이 직접 루트를 가리키도록 포인터 바꾸기  1 2 3 4 5 6 7 8 9 10  int findset(x){ if(x==p[x]) return x; else return findset(p[x]) } // path compression int findset(x){ if(x==p[x]) return x; else return p[x] = findset(p[x]) }    최소 신장 트리 (MST) 최소 비용 문제 : 두 정점 사이 최소 비용 경로, 간선들의 가중치의 합이 최소가 되는 트리 찾기\n신장 트리 : n개 정점으로 이루어진 무향 그래프에서 n개의 정점과 n-1개 간선으로 이루어진 트리\nMST : 무향 가중치 그래프에서 신장 트리를 구성하는 간선들의 가주치의 합이 최소인 신장 트리\n  사이클은 존재하면 안 됨\n⇒ visit배열로 방문 여부를 기록\n  Kruskal  간선을 가중치에 따라 오름차순 정렬 가중치가 가장 낮은 간선부터 선택하면서 트리 증가  사이클이 존재하면 다음으로 가중치가 낮은 간선 선택      Kruskal\n1 2 3 4 5 6 7 8 9 10  void kruskal(g, w){ for v in g.v make(v) //g.e에 포함된 간선들을 가중치 w에 의해 정렬  for u,v in g.e if findset(u) != findset(v) union(u,v) }     Prim 하나의 정점에서 연결된 간선 중 하나씩 선택\n 임의 정점을 하나 선택 인접 정점 중 최소 비용 간선의 정점 선택    트리 정점 : MST를 만들기 위해 선택된 정점\n  비트리 정점 : 선택X\n  위의 두 집합은 서로소 유지!\n사이클 여부 판단을 하지 않아도 됨 -\u003e 애초에 사이클을 생성하지 않는다\n  Prim\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  int prim(g, r){ // r은 시작 정점  for v in g.v minedge[v] = inf minedge[r] while true u = extract_min() // 방문하지 않은(mst 포함x) 최소 비용 인접 정점  visit[v] = true result+=minEdge[v] if(++cnt==N) break;\t// 모든 정점 연결  for u in g.e[v] // v 인접 정점들  if !visit[u] \u0026\u0026 w(v,u) \u003c minedge[u] // v에서 u로의 최소비용 갱신  minedge[u] = w(v,u) return result }      그래프 최단경로 알고리즘 bfs, dfs : 가중치가 없을 경우\n다익스트라 시작 정점이 주어지고 다른 모든 노드 사이의 최단거리 계산\n 선택되지 않은 노드들 중 최단 거리가 가장 짧은 노드 선택 선택된 노드와 연결된 다른 노드의 최단거리 갱신 1번으로  가장 짧은 노드를 선택할 때 Priority queue 또는 heap을 사용하면 O(ElogE)\ndists[curr] = min(dists[curr], dists[next] + cost(curr,next)\ncurr : 선택된 노드 , next : 갱신해야 하는 노드\n1 2 3 4 5 6 7 8 9 10 11 12  while (!pq.isempty()) { int curr = pq.top().second; pq.pop(); for (node it : nodes[curr]) { int next = it.target_node; int cost = it.weight; if (dist[next] \u003c 0 || dist[next] \u003e dist[curr] + cost) { dist[next] = dist[curr] + cost; pq.push(pair\u003cint, int\u003e(dist[next], next)); } } }   플로이드 와샬 2차원 배열, 복잡도 n^3\ndists[i][j] = min(dists[i][j], dists[i][k] + dists[k][j])\n 노드 0부터 k를 경유할 수 있을 때 노드 i부터 j까지의 최단거리 정의 최단경로가 노드 k를 경유하거나 경유하지 않는 경우를 계산해 최소값이 최단경로  1 2 3 4 5 6 7  for (int k = 0; k \u003c nodes.size(); ++k) { for (int i = 0; i \u003c nodes.size(); ++i) { for (int j = 0; j \u003c nodes.size(); ++j) { dists[i][j] = min(dists[i][j], dists[i][k] + dists[k][j]); } } }   벨만 포드 음수 간선이 있을 때(음의 사이클)\ndists[curr] = min(dists[curr], dists[next] + cost(curr,next)\n다익스트라와 동일한 식이나 모든 edge에 대해 적용\n음의 사이클이 있을 수 있어 다익스트라 1번을 한번더 실행\n1 2 3 4 5 6 7 8 9 10 11  for (int i = 0; i \u003c nodes.size() - 1; ++i) { for (int curr = 0; curr \u003c nodes.size(); ++curr) { if (dist[curr] \u003c inf) { for (auto it : nodes[curr]) { int next = it.target_node; int cost = it.weight; dist[next] = min(dist[next], dist[curr] + cost); } } } }   ","description":"","tags":null,"title":"Graph 정리","uri":"/posts/algorithm/graph/graph/"},{"categories":["Algorithm","study7"],"content":"` 플로이드 와샬 활용\n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63  import java.io.BufferedReader; import java.io.IOException; import java.io.InputStreamReader; import java.util.StringTokenizer; public class B14938 { static int N, M, R, S,E,D, max; static final int MAX = 987654321; static int[] item, visitDis; static int [][] graph; public static void main(String[] args) throws IOException { BufferedReader br = new BufferedReader(new InputStreamReader(System.in)); StringTokenizer st = new StringTokenizer(br.readLine()); N = Integer.parseInt(st.nextToken()); M = Integer.parseInt(st.nextToken()); R = Integer.parseInt(st.nextToken()); graph = new int[N+1][N+1]; item = new int[N+1]; st = new StringTokenizer(br.readLine()); for (int i = 1; i \u003c= N; i++) { item[i] = Integer.parseInt(st.nextToken()); } for (int i = 1; i \u003c= N; i++) { for (int j = 1; j \u003c= N; j++) { if(i!=j) graph[i][j] = MAX; } } for(int i=0;i\u003cR;i++) { st = new StringTokenizer(br.readLine()); S = Integer.parseInt(st.nextToken()); E = Integer.parseInt(st.nextToken()); D = Integer.parseInt(st.nextToken()); graph[S][E] =D ; graph[E][S] =D; } for (int k = 1; k \u003c= N; k++) for (int i = 1; i \u003c= N; i++) for (int j = 1; j \u003c= N; j++) { // 최단거리 갱신 \tif (graph[i][k] + graph[k][j] \u003c graph[i][j]) graph[i][j] = graph[i][k] + graph[k][j]; } for (int i = 1; i \u003c= N; i++) { int cnt = 0; for (int j = 1; j \u003c= N; j++) { if (graph[i][j] \u003c= M) cnt += item[j]; } max = Math.max(max, cnt); } System.out.println(max); } }   ","description":"","tags":null,"title":"[백준]_14938_서강그라운드","uri":"/posts/algorithm/study7/%EB%B0%B1%EC%A4%80_14938_%EC%84%9C%EA%B0%95%EA%B7%B8%EB%9D%BC%EC%9A%B4%EB%93%9C/"},{"categories":["Algorithm","study8"],"content":"`\n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58  import java.io.BufferedReader; import java.io.IOException; import java.io.InputStreamReader; import java.util.ArrayList; import java.util.Collections; import java.util.StringTokenizer; public class B2457 { static int N, ans, max; public static void main(String[] args) throws IOException { BufferedReader br = new BufferedReader(new InputStreamReader(System.in)); StringTokenizer st; ArrayList\u003cint[]\u003e arr = new ArrayList\u003c\u003e(); N = Integer.parseInt(br.readLine()); for (int i = 0; i \u003c N; i++) { st = new StringTokenizer(br.readLine()); int s_m = Integer.parseInt(st.nextToken()); int s_d = Integer.parseInt(st.nextToken()); int e_m = Integer.parseInt(st.nextToken()); int e_d = Integer.parseInt(st.nextToken()); arr.add(new int[] { s_m * 40 + s_d, e_m * 40 + e_d }); } Collections.sort(arr, (o1, o2) -\u003e { if (o1[0] == o2[0]) return o1[1] - o2[1]; return o1[0] - o2[0]; }); int id = 0; int start = 121; while (start \u003c 481) { max = 0; boolean flag = false; for (int i = id; i \u003c N; i++) { int[] cur = arr.get(i); if (cur[0] \u003e start) break; if (cur[0] \u003c= start \u0026\u0026 max \u003c cur[1]) { max = cur[1]; id = i + 1; flag = true; } } if (flag) { start = max; ans++; } else break; } System.out.println(max\u003c481?0:ans); } }   ","description":"","tags":null,"title":"[백준]_2457 공주님 정원","uri":"/posts/algorithm/study8/%EB%B0%B1%EC%A4%80_2457%EA%B3%B5%EC%A3%BC%EB%8B%98/"},{"categories":["Algorithm","study8"],"content":"` queue 활용\n  K범위 내에 n명이 있다면 $_{n} \\mathrm{C}_{2}$\n $_{n} \\mathrm{C}_{2} = n(n-1) / 2 = 1 + 2 + … n-1 $ 위에서 얻은 아이디어는 n번째 사람을 큐에 넣기 전에 n-1을 더하는 식을 생각    300000명의 이름의 길이가 모두 같을 경우를 생각해보면 int 범위를 넘어감.\n   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30  import java.io.*; import java.util.*; public class Main { static int n, k; static long cnt; public static void main(String[] args) throws IOException { BufferedReader br = new BufferedReader(new InputStreamReader(System.in)); StringTokenizer st = new StringTokenizer(br.readLine()); n = Integer.parseInt(st.nextToken()); k = Integer.parseInt(st.nextToken()); Queue\u003cInteger\u003e q[] = new LinkedList[21]; for(int i=0;i\u003c21;i++) { q[i] = new LinkedList\u003c\u003e(); } for (int i = 0; i \u003c n; i++) { int len = br.readLine().length(); while (!q[len].isEmpty() \u0026\u0026 i - q[len].peek() \u003e k) { q[len].poll(); } cnt += q[len].size(); q[len].offer(i); } System.out.println(cnt); } }   ","description":"","tags":null,"title":"[백준]_3057 좋은친구","uri":"/posts/algorithm/study8/%EB%B0%B1%EC%A4%80_3057_%EC%A2%8B%EC%9D%80%EC%B9%9C/"},{"categories":["Algorithm","study8"],"content":"` dfs 문제\n  움직임이 가능한 부분부터 탐색하고 찾지 못하면 return\n  지나쳐서 다시 오는거도 된다고 했지만 그냥 바로 출력함.\n   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100  import java.io.BufferedReader; import java.io.IOException; import java.io.InputStreamReader; import java.util.ArrayList; import java.util.List; import java.util.StringTokenizer; public class B18188 { static int H, W, N; static char[][] arr; static char[][] command; static int[][] delta = { { -1, 0 }, { 0, -1 }, { 1, 0 }, { 0, 1 } }; static int[] d; static boolean flag, ans; static StringBuilder sb = new StringBuilder(); public static void main(String[] args) throws IOException { BufferedReader br = new BufferedReader(new InputStreamReader(System.in)); StringTokenizer st = new StringTokenizer(br.readLine()); H = Integer.parseInt(st.nextToken()); W = Integer.parseInt(st.nextToken()); arr = new char[H][W]; for (int i = 0; i \u003c H; i++) { arr[i] = br.readLine().toCharArray(); for (int j = 0; j \u003c W; j++) { if (arr[i][j] == 'D') { d = new int[] {i,j}; } } } N = Integer.parseInt(br.readLine()); command = new char[N][2]; for (int i = 0; i \u003c N; i++) { st = new StringTokenizer(br.readLine()); command[i][0] = st.nextToken().charAt(0); command[i][1] = st.nextToken().charAt(0); } dfs(0,d[0],d[1], new ArrayList\u003c\u003e()); // key를 저장하기 위한 list \tSystem.out.println(ans?sb:\"NO\"); } private static void dfs(int start, int r, int c, List\u003cCharacter\u003e list) { for (int i = start; i \u003c N; i++) { flag = false; for (int j = 0; j \u003c 2; j++) { int dir = keydir(command[i][j]); int x = r + delta[dir][0]; int y = c + delta[dir][1]; if (inside(x, y) \u0026\u0026 arr[x][y] != '@') { list.add(command[i][j]); flag = true; // 찾을 경우 바로 결과 출력, ans를 이용해 모두 종료 \tif (arr[x][y] == 'Z') { sb.append(\"YES\").append(\"\\n\"); for (int k = 0; k \u003c list.size(); k++) { sb.append(list.get(k)); } ans = true; return; } else { // 다음꺼 탐색 \tdfs(i + 1, x, y, list); if(ans) return; list.remove(list.size() - 1); flag = false; } } if(ans) return; } // 끝까지 탐색했는데 찾지 못함 \tif(!flag) return; } } // 입력받은 키를 index로 변환 \tprivate static int keydir(char c) { int result = 0; if (c == 'W') { result = 0; } else if (c == 'A') { result = 1; } else if (c == 'S') { result = 2; } else if (c == 'D') { result = 3; } return result; } public static boolean inside(int x, int y) { return x \u003e= 0 \u0026\u0026 y \u003e= 0 \u0026\u0026 x \u003c H \u0026\u0026 y \u003c W; } }   ","description":"","tags":null,"title":"[백준]_18188 다오의 데이트","uri":"/posts/algorithm/study8/%EB%B0%B1%EC%A4%80_18188%EB%8B%A4%EC%98%A4%EC%9D%98%EB%8D%B0%EC%9D%B4%ED%8A%B8/"},{"categories":["Data_Science","Time_Series"],"content":"시계열 데이터  시계열 데이터 요소   추세(Trend): 장기적으로 나타나는 변동 패턴 계절성(Seasonal): 주,월,분기,반기 단위 등 이미 알려진 시간의 주기로 나타나는 패턴 주기(Cyclic): 고정된 기간이 아닌 장기적인 변동 랜덤요소 (random/residual/remainder)  `비정상 시계열이란 위의 4가지 패턴이 들어가 있는 경우를 말하고 이 요소들을 제거하고 정상화하는 것이 필수적이다.\ny_t = Level + Trend + Seasonality + Noise\nStationary(정상성) 평균,분산 공분산이 시간에 따라 변하지 않아야 함.\n일반적인 시계열 분석  시각화 시계열 안정 자기상관성 및 parameter 찾기 ARIMA 모델 등으로 예측  안정성을 위한 과정 Differencing  앞 데이터와 뒤 데이터의 차이 stationary하게 만드는 과정 -\u003e d parameter trend, seasonality가 없어지는 과정 -\u003e 보통 1,2차에서 끝나고 그래도 성능이 좋아지지 않으면 다른 요인의 문제  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  # stationary 확인 from statsmodels.tsa.stattools import adfuller def adf_check(ts): result = adfuller(ts) if result[1] \u003c= 0.05: print('Stationary {}'.format(result[1])) else: print('Non-Stationary {}'.format(result[1])) # 보통 0.05이하가 되어야  adf_check(timeseries) # 1차 차분 diff1 = timeseries - timeseries.shift(1) adf_check(diff1.dropna())   로그 변환  표준편차가 자료의 크기에 비례하여 증가할 경우  정상과정 확률 모형 가우시안 백색잡음의 현재값과 과거값들의 선형조합으로 이루어져 있다고 가정\nAutoregression(AR)  p parameter 관련 데이터와 이전 시점 사이의 관계에 대한 회귀 모델  Moving Average(MA)  q parameter 이전 시점의 moveing average의 residual에 대한 회귀 모델 -\u003e noise 예측  ARMA (Auto-Regressive Moving Average)  AR모형과 MA모형의 특징을 모두 가지는 모형  ARIMA(p,d,q)  Augmented Dickey-Fuller 검정 : d 자기상관계수 함수(ACF): q 편자기상관계수 함수(PACF) : p  acf : 특정 시간만큼 지연된 데이터와 연관성 pacf : t와 t-p의 연관성을 배제하고 보여줌 값이 파란 영역 내에 다 들어가야 p,q를 정할 수 있음 confidence level 보통 95%해서 lag=20으로 두고 2개 이상 올라오지 않으면 correlation이 없다고 생각한다.\n   모형 ACF PACF     AR(p) 지수함수적으로 감소하거나 점차 진폭이 축소되는 사인 곡선의 파동을 나타내거나 또는 양쪽모두 나타남 (시차가 증가함에 따라0 으로 급속히 접근) p 의 시차까지 유의성 있는 값을 나타내고 이후 소멸함   MA(q) q 의 시차까지 유의성 있는 값을 나타내고 이후 소멸함 지수함수적으로 감소하거나 점차진폭이 축소되는 사인 곡선의 파동을 나타내거나 또는 양쪽 모두 나타남 (시차가 증가함에 따라 0 으로급속히접근)   ARMA(p,q) 지수함수적으로 감소하거나 점차 진폭이 축소되는 사인 곡선의 파동을 나타내거나 또는 양쪽 모두 나타남 (시차가 증가함에 따라 0 으로 급속히 접근) 지수함수적으로 감소하거나 점차 진폭이 축소되는 사인 곡선의 파동을 나타내거나 또는 양쪽 모두 나타남 (시차가 증가함에 따라 0 으로 급속히 접근)    1 2 3 4  from statsmodels.graphics.tsaplots import plot_acf, plot_pacf plot_acf(diff2.dropna()); plot_pacf(diff2.dropna(),method='ywm');   위 그림에서 대략적으로 acf에서 q=1, p=7로 정해줄 수 있음\n SARIMAX Seasonal ARIMA 모형.\n단순 SARIMA 모형은 각 계절에 따른 독립적인 ARIMA 모형이 합쳐져 있는 모형이다. 기존 ARIMA(p,d,q) 모형에 계절성 주기를 나타내는 차수 s가 추가적으로 필요하기 때문에 SARIMA(P,D,Q,s) 로 표기한다. s의 값은 월별 계절성을 나타낼 때는 $s=12$ 가 되고 분기별 계절성을 나타낼 때는 $s=4$ 가 된다\nD는 차분 횟수고 P,Q는 위와 같이 ACF, PACF로 구해준다. 아래는 차분을 2번한 것을 s=7로 한 결과이다\n1 2 3 4 5 6  diff2_seasonal_diff1 = diff2 - diff2.shift(7) adf_check(diff2_seasonal_diff1.dropna()) # Stationary 4.042667176872469e-09 plot_acf(diff2_seasonal_diff1.dropna()); plot_pacf(diff2_seasonal_diff1.dropna(),method='ywm');   acf -\u003e Q=2 pacf -\u003e P=3\nModeling 앞의 결과와 합하면 최종적으로 SARIMA (7,2,1)X(3,2,2,7)\n1 2 3 4 5 6  import statsmodels.api as sm model = sm.tsa.statespace.SARIMAX(timeseries, order=[7,2,1],seasonal_order=[3,2,2,7]) result = model.fit() result.summary()   result.plot_diagnostics()를 통해 정규성, 정상성 여부 등 확인\nforecast 1 2 3 4  pred = result.predict(start='2020-08-14',end='2020-09-13', ) train['Confirmed'].plot(label='Train') test['Confirmed'].plot(label='Test') pred.plot(label='pred')    Rolling forecast 일정 구간을 train, 다음 것을 예측을 반복\n1 2 3 4 5 6 7 8 9 10 11 12 13  from statsmodels.tsa.arima_model import ARIMA import itertools # 파라미터 조합 만들기 p = list(range(0,6)) d= [1,2] q = list(range(0,2)) pdq = list(itertools.product(p,d,q)) for params in pdq: model = ARIMA(timeseries, order=params) result = model.fit(disp=-1) print('ARIMA{} AIC : {}'.format(params,result.aic))   ARIMA(0, 1, 0) AIC : 3935.7017097744483 ARIMA(0, 1, 1) AIC : 3937.582587394849 ARIMA(0, 2, 0) AIC : 4061.9453403812095 ARIMA(0, 2, 1) AIC : 3924.744203746418 ARIMA(1, 1, 0) AIC : 3937.590721228459 ....  1 2 3 4 5 6 7 8 9 10 11 12 13 14  predictions = [] history = [x for x in timeseries] for t in range(len(test)): model = ARIMA(history, order=(4,1,3)) result = model.fit(disp=0) output = result.forecast() yhat = output[0] predictions.append(yhat) obs = test['Confirmed'][t] history.append(obs) plt.plot(np.asarray(test['Confirmed'])) plt.plot(predictions)   참고 : 작년 코로나 데이터 분석한 것을 복습 + 추가 개념 정리 Corona data anaylsis 자주 쓰는 numpy/pandas (https://h3imdallr.github.io/2017-08-19/arima/)\n","description":"","tags":null,"title":"시계열 데이터 이해","uri":"/posts/data_science/time_series/hello/"},{"categories":["Programming","Python"],"content":"Python Basic lambda 함수를 간단하게 표현. 일회성을 지님\nlambda 인자 : 표현식\n1 2  (lambda x,y: x + y)(10, 20) # 30    map 리스트로부터 원소를 하나씩 꺼내서 함수를 적용하고 새로운 리스트에 담음\nmap(함수, 리스트)\n1 2  list(map(lambda x: x ** 2, range(5))) # [0, 1, 4, 9, 16]    reduce 순서형 자료(문자열, 리스트, 튜플 )의 원소를 순서대로 함수에 적용\nreduce(함수, sequence)\n1 2  reduce(lambda x, y: y + x, 'abcde') # 'edcba'   x를 기존 문자, y를 새로운 문자로 생각하면 새로운 원소가 기존 원소의 앞에 붙는다고 생각하면 위와 같이 역순으로 나온다.\n filter 리스트로부터 원소를 함수에 적용시키고 결과가 참인 값들로 새 리스트를 만듬\nfilter(함수, 리스트)\n1 2 3 4  list(filter(lambda x: x \u003c 5, range(10))) # [0, 1, 2, 3, 4] list(filter(lambda x: x % 2, range(10))) # [1, 3, 5, 7, 9]   ","description":"","tags":null,"title":"Python_Programming1","uri":"/posts/programming/python/python_programming1/"},{"categories":["Algorithm","study7"],"content":"` Dfs + memoization\n dfs로만 풀 경우 시간초과 남 -\u003e 정보를 저장해 다음 탐색 때 이전 값을 활용   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59  package com.baek.dfsbfs.gol345; import java.io.BufferedReader; import java.io.IOException; import java.io.InputStreamReader; import java.util.Arrays; import java.util.StringTokenizer; public class B1937 { static int N, max; static int[][] arr,depth,delta = { { 0, 1 }, { 1, 0 }, { 0, -1 }, { -1, 0 } }; static boolean[][] visit; public static void main(String[] args) throws NumberFormatException, IOException { BufferedReader br = new BufferedReader(new InputStreamReader(System.in)); StringTokenizer st; N = Integer.parseInt(br.readLine()); arr = new int[N][N]; depth = new int[N][N]; for(int i=0;i\u003cN;i++) { st = new StringTokenizer(br.readLine()); for(int j=0;j\u003cN;j++) { arr[i][j] = Integer.parseInt(st.nextToken()); Arrays.fill(depth[i],-1); } } for(int i=0;i\u003cN;i++) { for(int j=0;j\u003cN;j++) { max = Math.max(max,dfs(i,j)); } } System.out.println(max); } private static int dfs(int x, int y) { if(depth[x][y]!=-1) return depth[x][y]; //이전에 탐색된 곳이면 return \tdepth[x][y] = 1; int cnt = 0; for (int i = 0; i \u003c 4; i++) { int nx = x + delta[i][0];\tint ny = y + delta[i][1]; if(!inside(nx,ny)|| arr[nx][ny] \u003c=arr[x][y] ) continue; cnt = Math.max(cnt, dfs(nx, ny)); } depth[x][y] += cnt; return depth[x][y]; } private static boolean inside(int x, int y) { return x \u003e= 0 \u0026\u0026 x \u003c N \u0026\u0026 y \u003e= 0 \u0026\u0026 y \u003c N; } }   ","description":"","tags":null,"title":"[백준]_1937_욕심쟁이 판다","uri":"/posts/algorithm/study7/%EB%B0%B1%EC%A4%80_1937_%EC%9A%95%EC%8B%AC%EC%9F%81%EC%9D%B4%ED%8C%90%EB%8B%A4/"},{"categories":["Programming","Frontend"],"content":"DML Insert 1 2  insert into member (name1, name2, ....) values (val1, val2...);   ` Auto increment : primary key에서 자동으로 데이터 개수를 알 수 있도록\nUpdate 1 2  update table set name1 = val1, [name2 = val2...namen = valn] where name = 'a'    Where 생략하면 모든 데이터가 바뀜  Delete 1 2  delete from table where name = 'a'   Select 1  select a from table where condition    : 모든 열  distinct : 중복 행 제거\nexpression, alias 등\nifnull(expr1, expr2) : expr1이 null이면 expr2 출력\ncase..then : 조건에 대한 값을 바꿔서 보여줘야 할 때\n1 2 3 4  select salary case when salary \u003e 15000 then '고액' when salary \u003e 8000 then '평균' else '저액'   where id in ('a','b','c') : 안에 포함되는지 여부\nwhere salary between 60 and 100 : 사이값\nwhere salary is not null : null 아닌거 나오게\nLike\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  --A로 시작하는 문자를 찾기-- SELECT 컬럼명 FROM 테이블 WHERE 컬럼명 LIKE 'A%' --A로 끝나는 문자 찾기-- SELECT 컬럼명 FROM 테이블 WHERE 컬럼명 LIKE '%A' --끝에서 3번째 자리가 A인 문자 찾기-- SELECT 컬럼명 FROM 테이블 WHERE 컬럼명 LIKE '%A__' --A를 포함하는 문자 찾기-- SELECT 컬럼명 FROM 테이블 WHERE 컬럼명 LIKE '%A%' --A로 시작하는 두글자 문자 찾기-- SELECT 컬럼명 FROM 테이블 WHERE 컬럼명 LIKE 'A_' --첫번째 문자가 'A''가 아닌 모든 문자열 찾기-- SELECT 컬럼명 FROM 테이블 WHERE 컬럼명 LIKE'[^A]' --첫번째 문자가 'A'또는'B'또는'C'인 문자열 찾기-- SELECT 컬럼명 FROM 테이블 WHERE 컬럼명 LIKE '[ABC]' SELECT 컬럼명 FROM 테이블 WHERE 컬럼명 LIKE '[A-C]'   논리 연산시 주의\n NOT NULL → NULL NULL AND TRUE → NULL, NULL AND FALSE → FALSE NULL OR FALSE → NULL, NULL OR TRUE → TRUE  order by : 정렬(default : ASC), DESC : 내림차순\n JDBC API JDBC 연결 순서   Connection 생성 : com.mysql.cj.jdbc.Driver 로딩\n Connection은 인터페이스임  1  Connection con = null;     연결\n1 2 3 4 5  con = DriverManager.getConnection( \"jdbc:mysql://127.0.0.1:포트번호/db이름?serverTimezone=UTC\u0026useUniCode=yes\u0026characterEncoding=UTF-8\", id, pwd );     statement 생성\n1  Statement st = con.createStatement();     execute() or exectueQuery() 실행\n1 2 3 4 5  rs = st.executeQuery(\"select * from emp\"); while(rs.next()) { System.out.println(rs.getString(\"ename\")+\" , \"+rs.getInt(\"sal\")); }     preparedStatement\n  resultSet\n   담아서 커서를 통해 접근  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80  import java.sql.Connection; import java.sql.DriverManager; import java.sql.ResultSet; import java.sql.SQLException; import java.sql.Statement; // 기능만 제공한다 -\u003e 멤버 변수, 즉 state가 없다 -\u003e stateless public class DBUtil { private static DBUtil util = new DBUtil(); public static DBUtil getUtil() { return util; } private DBUtil() { try { // 1. Driver Loading \tClass.forName(\"com.mysql.cj.jdbc.Driver\"); } catch (ClassNotFoundException e) { e.printStackTrace(); } } // 2. Connection \tpublic Connection getConnection() { String url = \"jdbc:mysql://127.0.0.1:포트번호/db이름?erverTimezone=UTC\u0026useUniCode=yes\u0026characterEncoding=UTF-8\"; Connection con = null; try { con = DriverManager.getConnection(url, id, pwd); } catch (SQLException e) { e.printStackTrace(); } return con; } public void close(ResultSet rset, Statement pstmt, Connection con) { try { if(rset!=null) { rset.close(); } if(pstmt!=null) { pstmt.close(); } if(con!=null) { con.close(); } }catch(SQLException e) { e.printStackTrace(); } } } private void selectTest(int idx) { Connection con = util.getConnection(); // 3. Statement Create \tPreparedStatement pstmt = null; ResultSet rset = null; try { String sql = \"select * from member where idx=?\"; // idx는 pk이므로 반복문 쓸 필요x.. \t// 4. SQL Prapare and Execute \tpstmt = con.prepareStatement(sql); pstmt.setInt(1, idx); rset = pstmt.executeQuery(); if(rset.next()) { String userid = rset.getString(\"userid\"); String username = rset.getString(\"username\"); String userpwd = rset.getString(\"userpwd\"); String emailid = rset.getString(\"emailid\"); System.out.println(userid +\" : \" + username +\" : \" + userpwd+\" : \" + emailid); } }catch(SQLException e) { e.printStackTrace(); }finally { //5. close \tutil.close(rset, pstmt, con); } }   Statement는 사용하지 않음 → sql injection 삽입공격 때문\n statement 는 sql을 그대로 전달 preparedstatement는 값들을 인자처럼 처리  ","description":"","tags":null,"title":"CRUD and JDBC","uri":"/posts/programming/frontend/crud_jdbc/"},{"categories":["Algorithm","study7"],"content":"` dp문제\n 위치, 현재 높이(now), 이전 높이(before) 로 3차원 배열 2개 모든 경우를 구한 것과 2높이가 없는 경우를 구해 차이를 구함  현재 높이와 과거 높이를 보고 다음에 올 수 있는 높이의 경우를 구하는 식임\n처음에 java로 풀었는데 시간초과 떠서 python으로 하니 통과됐다. 거의 비슷한거 같은데 아직 이유는 못 찾음…\n python 풀이\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76  def sol(n, now, before): global MOD_NUM if n == 0: // 처음에 시작 높이 1 if now == 0: dp[n][now][before] = 1 else: dp[n][now][before] = 0 return dp[n][now][before] if dp[n][now][before] == -1: a1, a2, a3 = 0, 0, 0 // 높이가 0일 경우 다음꺼 상관x if now == 0: a1 = sol(n - 1, 0, now)% MOD_NUM a2 = sol(n - 1, 1, now)% MOD_NUM a3 = sol(n - 1, 2, now)% MOD_NUM elif now == 1: //현재 1 if before == 0: // 이전 높이가 0이면 아무거나 올 수 있다. a1 = sol(n - 1, 0, now)% MOD_NUM a2 = sol(n - 1, 1, now)% MOD_NUM a3 = sol(n - 1, 2, now)% MOD_NUM else: // 아니면 다음 높이는 무조건 0 a1 = sol(n - 1, 0, now)% MOD_NUM else: // 2일 때 if before == 0: // 2가 연속으로 올 수 없음 a1 = sol(n - 1, 0, now)% MOD_NUM a2 = sol(n - 1, 1, now)% MOD_NUM else: a1 = sol(n - 1, 0, now)% MOD_NUM dp[n][now][before] = (a1 + a2 + a3) % MOD_NUM return dp[n][now][before] def exp(n, now, before): global MOD_NUM if n == 0: if now == 0: ex[n][now][before] = 1 else: ex[n][now][before] = 0 return ex[n][now][before] if ex[n][now][before] == -1: a1, a2 = 0, 0 if now == 0: a1 = exp(n - 1, 0, now)% MOD_NUM a2 = exp(n - 1, 1, now)% MOD_NUM else: if before == 0: a1 = exp(n - 1, 0, now)% MOD_NUM a2 = exp(n - 1, 1, now)% MOD_NUM else: a1 = exp(n - 1, 0, now)% MOD_NUM ex[n][now][before] = (a1 + a2) % MOD_NUM return ex[n][now][before] import sys sys.setrecursionlimit(2000) MOD_NUM = 1000000007 N = int(input()) dp = [[[-1 for i in range(3)] for i in range(3)] for i in range(N)] ex = [[[-1 for i in range(2)] for i in range(2)] for i in range(N)] alls = sol(N - 1, 0, 0) + sol(N - 1, 1, 0) + sol(N - 1, 2, 0) exception = exp(N - 1, 0, 0) + exp(N - 1, 1, 0) print((alls - exception) % MOD_NUM)    java 풀이\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89  import java.io.BufferedReader; import java.io.IOException; import java.io.InputStreamReader; import java.util.Arrays; public class B20544 { static int T, MOD = 1000000007; static long[][][] arr, exps; public static void main(String[] args) throws IOException { BufferedReader br = new BufferedReader(new InputStreamReader(System.in)); T = Integer.parseInt(br.readLine()); //i는 위치, j는 전꺼 k는 현재 높이 \tarr= new long[T+1][3][3]; for(long first[][]:arr) { for(long second[]:first) { Arrays.fill(second, -1L); } } exps= new long[T+1][2][2]; for(long first[][]:exps) { for(long second[]:first) { Arrays.fill(second, -1L); } } long all = (solve(T - 1, 0, 0) + solve(T - 1, 1, 0) + solve(T - 1, 2, 0)) % MOD; long excep = (exception(T - 1, 0, 0) + exception(T - 1, 1, 0)) % MOD; System.out.println((excep)%MOD); } private static long solve(int n, int now, int before) { if (arr[n][now][before] != -1) return arr[n][now][before]; if (n == 0){ if (now == 0) arr[n][now][before] = 1; else arr[n][now][before] = 0; return arr[n][now][before]; } if (now == 0){ return (solve(n - 1, 2, now) + solve(n - 1, 1, now) + solve(n - 1, 0, now))%MOD; } else if (now == 1){ if (before == 0) return (solve(n - 1, 2, now) + solve(n - 1, 1, now) + solve(n - 1, 0, now))%MOD; else return solve(n - 1, 0, now)%MOD; } else if (now == 2){ if (before == 0) return (solve(n - 1, 1, now) + solve(n - 1, 0, now))%MOD; else if (before == 1) return solve(n - 1, 0, now)%MOD; } return arr[n][now][before]%MOD; } private static long exception(int n, int now, int before) { if (exps[n][now][before] != -1) return exps[n][now][before]; if (n == 0) { if (now == 0) exps[n][now][before] = 1; else exps[n][now][before] = 0; return exps[n][now][before]; } if (now == 0){ return (exception(n - 1, 1, now) + exception(n - 1, 0, now)) % MOD; } else if (now == 1){ if (before == 0) return (exception(n - 1, 1, now) + exception(n - 1, 0, now)) % MOD; else if (before == 1) return exception(n - 1, 0, now) % MOD; } return exps[n][now][before]%MOD; } }   ","description":"","tags":null,"title":"[백준]_20544_공룡게임","uri":"/posts/algorithm/study7/%EB%B0%B1%EC%A4%80_20544_%EA%B3%B5%EB%A3%A1/"},{"categories":["Algorithm","study7"],"content":"`\n예시에서 8 12 -\u003e 16\n8과 12의 최대공약수는 4이고 최대공약수로 나눈 타일에서 대각선 포함 타일 * 최대공약수를 해주면 됨.\nn과 m이 서로소일 경우 n이 크든 m이 크든 상관 없이 n+m-1개의 타일 개수가 포함되는 것을 알 수 있었음.\n python 풀이\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76  def sol(n, now, before): global MOD_NUM if n == 0: // 처음에 시작 높이 1 if now == 0: dp[n][now][before] = 1 else: dp[n][now][before] = 0 return dp[n][now][before] if dp[n][now][before] == -1: a1, a2, a3 = 0, 0, 0 // 높이가 0일 경우 다음꺼 상관x if now == 0: a1 = sol(n - 1, 0, now)% MOD_NUM a2 = sol(n - 1, 1, now)% MOD_NUM a3 = sol(n - 1, 2, now)% MOD_NUM elif now == 1: //현재 1 if before == 0: // 이전 높이가 0이면 아무거나 올 수 있다. a1 = sol(n - 1, 0, now)% MOD_NUM a2 = sol(n - 1, 1, now)% MOD_NUM a3 = sol(n - 1, 2, now)% MOD_NUM else: // 아니면 다음 높이는 무조건 0 a1 = sol(n - 1, 0, now)% MOD_NUM else: // 2일 때 if before == 0: // 2가 연속으로 올 수 없음 a1 = sol(n - 1, 0, now)% MOD_NUM a2 = sol(n - 1, 1, now)% MOD_NUM else: a1 = sol(n - 1, 0, now)% MOD_NUM dp[n][now][before] = (a1 + a2 + a3) % MOD_NUM return dp[n][now][before] def exp(n, now, before): global MOD_NUM if n == 0: if now == 0: ex[n][now][before] = 1 else: ex[n][now][before] = 0 return ex[n][now][before] if ex[n][now][before] == -1: a1, a2 = 0, 0 if now == 0: a1 = exp(n - 1, 0, now)% MOD_NUM a2 = exp(n - 1, 1, now)% MOD_NUM else: if before == 0: a1 = exp(n - 1, 0, now)% MOD_NUM a2 = exp(n - 1, 1, now)% MOD_NUM else: a1 = exp(n - 1, 0, now)% MOD_NUM ex[n][now][before] = (a1 + a2) % MOD_NUM return ex[n][now][before] import sys sys.setrecursionlimit(2000) MOD_NUM = 1000000007 N = int(input()) dp = [[[-1 for i in range(3)] for i in range(3)] for i in range(N)] ex = [[[-1 for i in range(2)] for i in range(2)] for i in range(N)] alls = sol(N - 1, 0, 0) + sol(N - 1, 1, 0) + sol(N - 1, 2, 0) exception = exp(N - 1, 0, 0) + exp(N - 1, 1, 0) print((alls - exception) % MOD_NUM)    java 풀이\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89  import java.io.BufferedReader; import java.io.IOException; import java.io.InputStreamReader; import java.util.Arrays; public class B20544 { static int T, MOD = 1000000007; static long[][][] arr, exps; public static void main(String[] args) throws IOException { BufferedReader br = new BufferedReader(new InputStreamReader(System.in)); T = Integer.parseInt(br.readLine()); //i는 위치, j는 전꺼 k는 현재 높이 \tarr= new long[T+1][3][3]; for(long first[][]:arr) { for(long second[]:first) { Arrays.fill(second, -1L); } } exps= new long[T+1][2][2]; for(long first[][]:exps) { for(long second[]:first) { Arrays.fill(second, -1L); } } long all = (solve(T - 1, 0, 0) + solve(T - 1, 1, 0) + solve(T - 1, 2, 0)) % MOD; long excep = (exception(T - 1, 0, 0) + exception(T - 1, 1, 0)) % MOD; System.out.println((excep)%MOD); } private static long solve(int n, int now, int before) { if (arr[n][now][before] != -1) return arr[n][now][before]; if (n == 0){ if (now == 0) arr[n][now][before] = 1; else arr[n][now][before] = 0; return arr[n][now][before]; } if (now == 0){ return (solve(n - 1, 2, now) + solve(n - 1, 1, now) + solve(n - 1, 0, now))%MOD; } else if (now == 1){ if (before == 0) return (solve(n - 1, 2, now) + solve(n - 1, 1, now) + solve(n - 1, 0, now))%MOD; else return solve(n - 1, 0, now)%MOD; } else if (now == 2){ if (before == 0) return (solve(n - 1, 1, now) + solve(n - 1, 0, now))%MOD; else if (before == 1) return solve(n - 1, 0, now)%MOD; } return arr[n][now][before]%MOD; } private static long exception(int n, int now, int before) { if (exps[n][now][before] != -1) return exps[n][now][before]; if (n == 0) { if (now == 0) exps[n][now][before] = 1; else exps[n][now][before] = 0; return exps[n][now][before]; } if (now == 0){ return (exception(n - 1, 1, now) + exception(n - 1, 0, now)) % MOD; } else if (now == 1){ if (before == 0) return (exception(n - 1, 1, now) + exception(n - 1, 0, now)) % MOD; else if (before == 1) return exception(n - 1, 0, now) % MOD; } return exps[n][now][before]%MOD; } }   ","description":"","tags":null,"title":"[백준]_2168_타일 위의 대각선","uri":"/posts/algorithm/study7/%EB%B0%B1%EC%A4%80_2168_%ED%83%80%EC%9D%BC/"},{"categories":["Algorithm","study7"],"content":"` graph 문제\n  처음에 그래프를 만드는 식으로 하려 했으나 a-\u003eb, a-\u003ec는 불가능하고 a-\u003ec, b-\u003ec는 가능하다.\n  따라서 각 알파벳에 대해 부모를 지정해주면 배열로 처리할 수 있음.\n   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45  import java.io.BufferedReader; import java.io.IOException; import java.io.InputStreamReader; import java.util.StringTokenizer; public class B15723 { static int N,M, cnt=0; static char a,b; static int[] parent; public static void main(String[] args) throws IOException { BufferedReader br = new BufferedReader(new InputStreamReader(System.in)); StringBuilder sb = new StringBuilder(); StringTokenizer st; N = Integer.parseInt(br.readLine()); parent = new int[27];\tfor (int i = 0; i \u003c N; i++) { st = new StringTokenizer(br.readLine(),\" \"); a = st.nextToken().charAt(0); st.nextToken(); b = st.nextToken().charAt(0); parent[a-'a'+1] = b-'a'+1; } M = Integer.parseInt(br.readLine()); for (int i = 0; i \u003c M; i++) { st = new StringTokenizer(br.readLine(),\" \"); a = st.nextToken().charAt(0); st.nextToken(); b = st.nextToken().charAt(0); a-=('a'-1); b-=('a'-1); // 부모를 찾는 과정 \twhile(a!=b \u0026\u0026 parent[a]!=0) { a = (char)parent[a]; } sb.append(a==b?'T':'F').append(\"\\n\"); } System.out.println(sb); } }   ","description":"","tags":null,"title":"[백준]_15723_n단논법","uri":"/posts/algorithm/study7/%EB%B0%B1%EC%A4%80_15723_n%EB%8B%A8%EB%85%BC%EB%B2%95/"},{"categories":["Algorithm","study7"],"content":"` brute force + Backtracking\n 처음에 에라토스테네스의 체로 문제를 풀었고 역시나 메모리 초과가 떠서 소수 판별 방식 재구성   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43  import java.io.BufferedReader; import java.io.IOException; import java.io.InputStreamReader; public class Main { static StringBuilder sb = new StringBuilder(); static int T; public static void main(String[] args) throws IOException { BufferedReader br = new BufferedReader(new InputStreamReader(System.in)); T = Integer.parseInt(br.readLine()); int[] arr = {2,3,5,7}; for(int i=0;i\u003c4;i++) { dfs(1,arr[i]); } System.out.println(sb); } private static void dfs(int cnt, int sosu) { if(cnt==T) { sb.append(sosu).append(\"\\n\"); return; } // 홀수인 경우만 추가 \tfor(int i=1;i\u003c10;i+=2) { int nnum = sosu*10+i; if(!isCut(nnum)) continue; dfs(cnt+1,nnum); } } // 소수 여부 판단 \tprivate static boolean isCut(int a) { int n = (int) Math.sqrt(a); for (int i = 2; i \u003c= n; i++) { if (a % i == 0) { return false; } } return true; } }   ","description":"","tags":null,"title":"[백준]_2023_신기한소수","uri":"/posts/algorithm/study7/%EB%B0%B1%EC%A4%80_2023_%EC%8B%A0%EA%B8%B0%ED%95%9C%EC%86%8C%EC%88%98/"},{"categories":["Algorithm","study6"],"content":"`     1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35  import java.io.BufferedReader; import java.io.IOException; import java.io.InputStreamReader; import java.util.HashSet; import java.util.Set; public class B13915 { static int N; static String l; static int let = (1 \u003c\u003c 10) - 1; public static void main(String[] args) throws IOException { BufferedReader br = new BufferedReader(new InputStreamReader(System.in)); StringBuilder sb =new StringBuilder(); while((l=br.readLine())!=null \u0026\u0026 !l.equals(\"\")) { N = Integer.parseInt(l); Set\u003cInteger\u003e s = new HashSet\u003c\u003e(); int[] arr = new int[N]; for(int i=0;i\u003cN;i++) { String b = br.readLine(); for (char c : b.toCharArray()) { arr[i] |= 1 \u003c\u003c (c - 'a'); } } for(int i=0;i\u003cN;i++) { s.add(arr[i]); } sb.append(s.size()).append(\"\\n\"); } System.out.println(sb); } }   ","description":"","tags":null,"title":"[백준]_13915_현수의 열기구 교실","uri":"/posts/algorithm/study6/%EB%B0%B1%EC%A4%80_13915_%ED%98%84%EC%88%98%EC%97%B4%EA%B8%B0%EA%B5%AC/"},{"categories":["Algorithm","study6"],"content":"`\n 홀수는 n +(n+1)로 표현가능 짝수의 경우 다음과 같이 생각할 수 있다.  $6 = 2+2+2$ 에서 앞 뒤로 1을 빼고 더하면 $1+2+3$ $14 = 2*7 = (-1+0+1)+2+3+4+5 = 2+3+4+5$    그렇다면 12인 경우 답은 3+4+5인데 2+2+2+2+2+2에서 위와 같이 하긴 힘들다. 그래서 좀 더 생각해보니 $12 = 2^2*3$ 이고 4로 나누었을 때 풀이가 나오는 것이 가능하다.\n $12 = 4+4+4 = 3+4+5$  이렇게 규칙을 찾았을 때, 짝수여도 2를 제외한 소수가 있을 경우 연속된 수로 표현이 가능하다. 결국 가능하지 않은 경우는 2의 제곱수에 해당하는 것들이라 할 수 있다.\n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26  import java.io.BufferedReader; import java.io.IOException; import java.io.InputStreamReader; public class B16464 { static int T,N; public static void main(String[] args) throws IOException { BufferedReader br = new BufferedReader(new InputStreamReader(System.in)); StringBuilder sb = new StringBuilder(); T = Integer.parseInt(br.readLine()); for(int t=0;t\u003cT;t++) { N = Integer.parseInt(br.readLine()); while(N!=1) { if(N%2==1) { sb.append(\"Gazua\").append(\"\\n\"); break; } N/=2; } if(N==1) sb.append(\"GoHanGang\").append(\"\\n\"); } System.out.println(sb); } }   ","description":"","tags":null,"title":"[백준]_16464_가주아","uri":"/posts/algorithm/study6/%EB%B0%B1%EC%A4%80_16464_%EA%B0%80%EC%A3%BC%EC%95%84/"},{"categories":["Algorithm","study6"],"content":"` dfs 문제\n min과 max를 구해 E가 범위 안에 있기만 하면 답을 바로 구할 수 있음   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82  import java.io.BufferedReader; import java.io.IOException; import java.io.InputStreamReader; import java.util.StringTokenizer; public class B18233 { static int N, P, E; static int[][] arr; static int[] num, doll; static boolean[] visit; static boolean flag; public static void main(String[] args) throws IOException { BufferedReader br = new BufferedReader(new InputStreamReader(System.in)); StringTokenizer st = new StringTokenizer(br.readLine()); StringBuilder sb= new StringBuilder(); N = Integer.parseInt(st.nextToken()); P = Integer.parseInt(st.nextToken()); E = Integer.parseInt(st.nextToken()); arr = new int[N][2]; num = new int[P]; doll = new int[N]; visit = new boolean[N]; for (int i = 0; i \u003c N; i++) { st = new StringTokenizer(br.readLine()); arr[i][0] = Integer.parseInt(st.nextToken()); arr[i][1] = Integer.parseInt(st.nextToken()); } dfs(0,0); for(int k : doll) { sb.append(k).append(\" \"); } System.out.println(flag?sb:-1); } private static void dfs(int cnt, int start) { if (cnt == P) { int min = 0, max = 0; for (int i = 0; i \u003c P; i++) { min += arr[num[i]][0]; max += arr[num[i]][1]; } // E가 min과 max 범위 안에 있는지 \tif (!(min \u003c= E \u0026\u0026 E \u003c=max)) return; // 남은 인형의 개수 \tint div = E - min; // 조건을 만족할 경우 -1을 출력하지 않음 \tflag = true; for (int i = 0; i \u003c P; i++) { // 해당하는 사람에게 인형을 주고 남은 인형을 분배하는 로직 \tdoll[num[i]] = arr[num[i]][0]; if(div==0) continue; int get = arr[num[i]][1] - arr[num[i]][0]; if (div \u003e get) { div -= get; doll[num[i]]+=get; }else { doll[num[i]]+=div; div=0; }\t} return; } for (int i = start; i \u003c N; i++) { if (arr[i][0] \u003c= E) { num[cnt] = i; dfs(cnt + 1, i+1); // 하나라도 만족할 경우 모두 종료시킴. \tif (flag) return; } } } }   ","description":"","tags":null,"title":"[백준]_18233_러버덕을 사랑하는 모임","uri":"/posts/algorithm/study6/%EB%B0%B1%EC%A4%80_18233_%EB%9F%AC%EB%B2%84%EB%8D%95/"},{"categories":["Algorithm","study6"],"content":"` dp문제\n규칙을 구해보면 피보나치 수열이 나오는 것을 알 수 있음.\n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  import java.io.BufferedReader; import java.io.IOException; import java.io.InputStreamReader; import java.util.ArrayList; import java.util.List; public class B1904 { public static void main(String[] args) throws IOException { BufferedReader br = new BufferedReader(new InputStreamReader(System.in)); int N = Integer.parseInt(br.readLine()); List\u003cInteger\u003e list = new ArrayList\u003c\u003e(); list.add(1); list.add(2); for(int i=2;i\u003cN;i++) { list.add((list.get(i-1)+list.get(i-2))%15746); } System.out.println(list.get(N-1)); } }   ","description":"","tags":null,"title":"[백준]_1904_01타일","uri":"/posts/algorithm/study6/%EB%B0%B1%EC%A4%80_1904_01%ED%83%80%EC%9D%BC/"},{"categories":["Programming","Frontend"],"content":"JavaScript 선언 \u003cbody\u003e 안에 위치하면 브라우저가 html부터 해석하여 화면에 그리기 때문에 빠르다고 느낄 수 있어서 보통 body안 맨 밑에 삽입하는 경향임.\n`html과 연결하기\n1 2 3 4  외부 \u003cscript language=\"text/javascript\" src=\"외부 스크립트 파일의 URL\"\u003e\u003c/script\u003e 내부 \u003cscript type=\"text/javascript\"\u003e\u003c/script\u003e   데이터 타입 primitive\n숫자, 문자열, boolean, undefined(초기화되지 않음), null(없거나 빔)\nreference\nwindow(브라우저 및 창 프레임 표시), document(html 파일 기술된 문서 제공 및 작업 수행), Date, Array, RegExp(정규 표현식)\n변수 var로 선언, 값 대입 시점에 타입 자동 설정, 중복 선언 가능\n 전역 변수 : 외부에서 선언 후 함수 내에서 var 없이 사용 지역 변수 : 내부에서만 사용  let : 중복을 허용하지 않음\n프로그래밍의 안전성을 위해 let을 쓰는 게 더 나음.\nconst : 상수, 바꿀 수 없음.\n앞에 선언 없이 변수 선언 : 전역 레벨 변수 선언 → 절대 하지 마요…\n→ 전역 객체인 window의 속성으로 등록해버림.\nPrimitive Type\n  숫자 자료형 : 모든 숫자를 실수로 처리\n js에서는 연산에서 예외를 발생시키지 않음 Infinity : 무한대 NaN : 결과가 숫자가 아님    string : 따옴표 상관x, 16비트\n  boolean, null. undefined\n   빈 문자열, null, undefined, 숫자 0은 false로 간주됨.  js에서는 자료형에 대해 느슨한 구조 → 어떤 자료형이든 전달하고 변환 가능\n사용자 정의 함수\n1 2 3 4  function 함수명([arg1, arg2, ...]) { statement [return expression;] }   Hoisting js에서 일어나는 현상, js는 parsing과 실행 2단계로 처리됨\n parsing : 전역 레벨의 var 변수 인지 및 undefined 초기화, 함수에 대해 함수명과 동일한 변수 생성 및 인지 실행 : 할당 등 실행문 실행  선언과 초기화를 먼저 하기 때문에 선언되기 전에 참조 가능\n예시\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29  console.log(\"1\", num1, square, square2); var num1 = 10; console.log(\"2\", num1, square, square2); // 전역 레벨의 변수 선언 - 절대 하지 않기.. // num2 = 20;  var square = 0; console.log(\"3\", num1, square, square2); function square(x){ return x*x } // square(num1); //square가 함수가 아니라 안됨. var square2 = function(){ return x*x } console.log(\"5\",num1, square, square2); 결과 1 undefined ƒ square(x){ return x*x } undefined 2 10 ƒ square(x){ return x*x } undefined 3 10 0 undefined 5 10 0 ƒ (){ return x*x }   let으로 선언할 경우 1,2,3처럼 할당되지 않은 것이 실행되버리는 결과를 막을 수 있음.\n연산자 ===, !== : 일반적인 ==과 !=가 “1” 과 1도 같다고 판별하기 때문에 타입까지 비교하기 위함.\n + : 문자열 결합연산, 0(false)/1(true) , 참조형일 경우 toString()결과와 결합 -, *, /,% : 문자열을 최대한 숫자로 바꾸고 못하면 NaN, 참조형일 경우 valueOf()의 결과와 연산  논리 연산 : 마지막으로 평가한 값을 리턴\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35  console.log(1 + \"123\") console.log(true + true + false) console.log(new Date() + 123) //1123 //2 // 현재 시간123  console.log(1 - \"123\") console.log(0 - \"A\") console.log(new Date().valueOf()) console.log(new Date()-60*60*24*1000); //-122 //NaN //1614832363259 //1614745963259  console.log(true==1,true===1, null==undefined, null===undefined) //true false true false  let result1 = 1 || undefined; // true || false -\u003e true console.log(result1); let result2 = 0 || undefined; // false || false -\u003e false console.log(result2); let result3 = null || \"False\"; // false || \"False\" --\u003e \"False\" console.log(result3); if(result3){ // true임 \tconsole.log(\"Hello js\") } // 1 // undefined // False // Hello js    반복문 of : 값이 바로 나오게\nin : 배열 순회 보다는 객체의 속성 탐색\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  let arr = [1,2,3,4,5]; for (var i = 0; i \u003c arr.length; i++) { console.log(arr[i])\t} //12345  for(let i in arr){ // i는 index라 할 수 있음. \tconsole.log(i) } //01234  for(let i of arr){ // data 자체가 나옴 \tconsole.log(i) } //12345  let person = { name : \"홍길동\", age : 30 } for(let key in person){ console.log(key,person[key]); }   객체 생성 객체 리터럴\n1  var a = { width: 20, height: 30, position: {x:200, y:400} };   Object 생성자 함수\n1 2 3 4 5 6  var a = new Object(); a.name = \"가나다\" a.age = 30; a.info = function(){ console.log(\"hi\") };   생성자 함수\n1 2 3 4 5 6 7  function a(name,age){ this.name = name; this.age = age; this.info = function(){ console.log(\"hi\") }; }    Window 객체 웹 브라우저에서 작동하는 js 최상위 객체(BOM)\n함수를 호출하면 브라우저에서 제공하는 창 open\n alert : 알림창 confirm : 확인/취소 선택창 prompt : 입력창 + 확인/취소  navigator\n브라우저 정보가 내장된 객체, 서로 다른 브라우저 구분, 다르게 처리 가능\nuser-agent로 mobile환경, chrome 등 정보 확인 가능\nlocation\nurl정보 관련\n  location.href : 현재 url 조회. 값을 할당하면 해당 url로\n  reload : 새로고침\n  history\n페이지 이력을 담는 객체\n  back, forward : 뒤로 가기, 앞으로 가기\n  window.open(url,창이름,특성,히스토리 대체여부)\n  특성 : 창의 너비 높이, 위치, 크기 조정, menubar 등.\n  대체여부 : 현재 페이지 히스토리에 덮어쓸지 여부\n    1 2 3  function windowOpen() { window.open('./index.html', 'abc', 'width=300, height=200'); }    DOM 문서의 구조를 정의하는 API제공\n문서 조작   createElement(name) : 엘리먼트생성\n1  var ele = document.createElement(\"img\"); // 메모리에 생성     append(string | node) : 엘리먼트 추가\n1  parent.append(element);     setAttribute(name, value) : 속성 변경. ,getAttribute(name) : 값 가져옴\n1 2  ele.setAttribute(\"width\", 200); ele.width = 200;   사용자 속성 변경시에는 setAttribute를 써야 함\n1 2 3  ele.setAttribute(\"name\", \"차\"); =\u003e 성공 ele.name = \"차\"; =\u003e 실패     innerHTML : 요소 내용 변경\n1  list.innerHTML = \"\u003cimg src='./images/cake.jpg' width='200'/\u003e\"     문서 접근   getElementById(String)\n1  var ele = document.getElementById(\"a\"); =\u003e \u003cdiv id=\"a\"\u003e지역\u003c/div\u003e     querySelector(css selector)\n1 2 3 4  var ele = document.querySelector(\"#a\") =\u003e \u003cdiv id=\"a\"\u003e지역\u003c/div\u003e var ele = document.querySelector(\"div\") =\u003e \u003cdiv id=\"a\"\u003e지역\u003c/div\u003e var ele = document.querySelector(\".b\") =\u003e \u003cdiv class=\"b\"\u003e지역\u003c/div\u003e var ele = document.querySelector(\"[name='c']\") =\u003e \u003cdiv name=\"c\"\u003e구미\u003c/div\u003e     querySelectorAll(css selector) : 결과를 배열처럼 사용\n1 2 3 4  var list = document.querySelectorAll(\"div\"); for (var i=0; i\u003clist.length; i++) { console.log(list[i]) }   1 2 3 4 5 6 7 8 9  var ele = document.querySelectorAll(\"div\"); =\u003e \u003cdiv id=\"a\"\u003e지역\u003c/div\u003e \u003cdiv id=\"b\"\u003e광주\u003c/div\u003e \u003cdiv id=\"c\"\u003e구미\u003c/div\u003e var ele = document.querySelectorAll(\".b\"); =\u003e \u003cdiv id=\"a\" class=\"b\"\u003e지역\u003c/div\u003e \u003cdiv class=\"b\"\u003e광주\u003c/div\u003e   1 2  ele.width = 200; // 사용자 속성에는 접근 불가 ele[\"width\"] = 200; // 사용자 속성에 접근 가능!!!!      이벤트 처리 요소.addEventLister( 이벤트 타입, 이벤트리스너(함수명), 이벤트전파방식);\n1  tn.addEventListener(\"click\", doAction, true);   localstage에는 문자열 밖에 저장되지 않음.\n 기타 문자열 표현 1 2  console.log(\"이름은\"+person.name+\"나이는\" + person.age); console.log(`이름은 ${person.name}, 나이는 ${person.age}`);   JSON client ←→ server 간 데이터 전달 -\u003e JSON 활용\nJSON(JavaScript Object Notation) : js의 객체 표현법\nJSON.stringify(object) : json → string으로\nJSON.parse(str) : string → json\n\rfunction의 다양한 용도\n 일반적인 method 역할  1 2 3 4  function sayHi(){ console.log(\"Hi\"); } sayHi();   객체로써의 역할  1 2 3 4  let sayHello = function(){ console.log(\"Hello\"); } sayHello();   생성자로써의 역할  1 2 3 4 5  function Student(name, age){ this.name = name; this.age = age; } let student = new Student(\"홍길동\",30);   \ncallback\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  // 기준을 가지고 정렬해보기 strs.sort(function(first, second){ return first.length - second.length; }) // 3초에 한 번씩 함수 실행하게 하기 window.setInterval(function() { console.log(new Date()); }, 3000) // 10초 후 window.setTimeout(function() { location.href = \"https://www.google.com\"; }, 10*1000)   일정 간격으로 함수를 일정 조건만큼 실행하고 싶은 경우, 재귀 활용\nfor문 안에 그냥 쓸 경우 setTime으로 딜레이 되어도 for문은 계속 돌아가서 결국 동시에 실행되는 것처럼 보임\n→ setTimeout안에서 계속 실행되어 일정 시간 후 함수가 실행된 후 그 안의 setTimeout이 실행된다고 할 수 있음!\n1 2 3 4 5 6 7 8 9 10  function looper(i) { if (i \u003c 6) { setTimeout(function () { one_choice(lotto[i]) i++; looper(i); }, 2000) } } looper(0);   ","description":"","tags":null,"title":"JavaScript1","uri":"/posts/programming/frontend/javascript1/"},{"categories":["Algorithm","study6"],"content":"` 다이나믹 프로그래밍\nN=3 일때\n$fibo(3) = fibo(2) + fibo(1) = (fibo(1) + fibo(0)) + fibo(1)$ 이라 할 수 있다.\n또한 계속 구해보면\n fibo(0)은 1,0,1,1,2,3,5…. fibo(1)은 0,1,1,2,3,5…. 으로 피보나치 함수 형태를 띄는 것을 알 수 있다.   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36  import java.io.BufferedReader; import java.io.IOException; import java.io.InputStreamReader; import java.util.ArrayList; import java.util.List; public class B1003 { public static void main(String[] args) throws IOException { BufferedReader br = new BufferedReader(new InputStreamReader(System.in)); StringBuilder sb = new StringBuilder(); List\u003cInteger\u003e zero = new ArrayList\u003c\u003e(); List\u003cInteger\u003e one = new ArrayList\u003c\u003e(); for(int i=0;i\u003c2;i++) { zero.add(1-i); one.add(i); } int T = Integer.parseInt(br.readLine()); int max =1; for(int i=0;i\u003cT;i++) { int N = Integer.parseInt(br.readLine()); if(max \u003c N) { for(int k=max+1;k\u003c=N;k++) { zero.add(zero.get(k-1) + zero.get(k-2)); one.add(one.get(k-1) + one.get(k-2)); } max = N; } sb.append(zero.get(N)).append(\" \").append(one.get(N)).append(\"\\n\"); } System.out.println(sb); } }   ","description":"","tags":null,"title":"[백준]_1003_피보나치 함수","uri":"/posts/algorithm/study6/%EB%B0%B1%EC%A4%80_1003_%ED%94%BC%EB%B3%B4%EB%82%98%EC%B9%98%ED%95%A8%EC%88%98/"},{"categories":["Algorithm","study6"],"content":"` 이진법을 활용한 방법\n01로 이진수를 만들듯이 16과 27을 각각 이진수처럼 생각하여 풀이\n 1267이 나오는 자리 수 및 개수 저장, 67은 12로 바꿈 $2^{1267개수} \u003c K - 1$ 이면 -1 출력 K/2를 계속 하면서 나머지가 1이면 12를 67로 바꾼다.   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53  import java.io.BufferedReader; import java.io.IOException; import java.io.InputStreamReader; public class B12025 { static long K; public static void main(String[] args) throws IOException { BufferedReader br = new BufferedReader(new InputStreamReader(System.in)); StringBuilder sb = new StringBuilder(); char[] arr = br.readLine().toCharArray(); int[] num = new int[arr.length]; int cnt = 0; for (int i = arr.length - 1; i \u003e= 0; i--) { if (arr[i] == '1' || arr[i] == '2' || arr[i] == '6' || arr[i] == '7') { // 위치 및 개수 저장 \tnum[cnt++] = i; // 67이면 12로 바꾸기 \tif (arr[i] == '6') arr[i] = '1'; else if (arr[i] == '7') arr[i] = '2'; } } K = Long.parseLong(br.readLine()); K--; long maximum = (long) Math.pow(2, cnt); // 범위 넘어갈 경우 out \tif (maximum \u003c K) { System.out.println(-1); return; } cnt = 0; while (K \u003e 0) { // K를 2로 나누면서 나머지가 1이면 해당자리의 숫자를 바꿈 \tif(K%2==1) { if (arr[num[cnt]] == '1') arr[num[cnt]] = '6'; else if (arr[num[cnt]] == '2') arr[num[cnt]] = '7'; } K/=2; cnt++; } for(char c : arr) sb.append(c); System.out.println(sb); } }   ","description":"","tags":null,"title":"[백준]_12025_장난꾸러기 영훈이","uri":"/posts/algorithm/study6/%EB%B0%B1%EC%A4%80_12025_%EC%9E%A5%EB%82%9C%EA%BE%B8%EB%9F%AC%EA%B8%B0%EC%98%81%ED%9B%88%EC%9D%B4/"},{"categories":["Algorithm","study6"],"content":"`String을 bfs\n 문자열이 나왔는지를 체크하기 위해 Set 활용 substiring함수를 이용해 문자열 조작   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75  import java.io.BufferedReader; import java.io.IOException; import java.io.InputStreamReader; import java.util.*; public class B1327 { static int N,K; static char[] arr, copy; static String arr_str, copy_str; public static void main(String[] args) throws IOException { BufferedReader br = new BufferedReader(new InputStreamReader(System.in)); StringTokenizer st = new StringTokenizer(br.readLine()); N = Integer.parseInt(st.nextToken()); K = Integer.parseInt(st.nextToken()); arr = new char[N]; arr = br.readLine().replace(\" \", \"\").toCharArray(); copy = Arrays.copyOf(arr, N); Arrays.sort(arr); arr_str = new String(arr); copy_str = new String(copy); System.out.println(bfs()); } private static int bfs() { Queue\u003cStrint\u003e q = new LinkedList\u003c\u003e(); Set\u003cString\u003e search = new HashSet\u003c\u003e(); // SET으로 방문 여부 관리 \tq.offer(new Strint(copy_str, 0)); while(!q.isEmpty()) { Strint ci = q.poll(); String str = ci.str; int cnt = ci.cnt; // 결과와 같을 경우 CNT 반환 \tif(arr_str.equals(str)) return cnt; // set에 포함되어 있지 않을 경우 k개 뒤집은 배열 넣기 \tif(!search.contains(str)) { search.add(str); for(int i=0; i\u003c=N-K;i++) { q.offer(new Strint(reverseStr(str,i,i+K), cnt+1)); } } } return -1; } private static String reverseStr(String str, int i, int j) { StringBuilder sb = new StringBuilder(); sb.append(str.substring(0, i)); // 특정 부분만 뒤집기 \tString reverse = str.substring(i,j); for(int t = K-1;t\u003e=0;t--) { sb.append(reverse.charAt(t)); } sb.append(str.substring(j, N)); return sb.toString(); } private static class Strint{ String str; int cnt; public Strint(String str, int cnt) { this.str = str; this.cnt = cnt; } } }   ","description":"","tags":null,"title":"[백준]_1327_소트게임","uri":"/posts/algorithm/study6/%EB%B0%B1%EC%A4%80_1327_%EC%86%8C%ED%8A%B8%EA%B2%8C%EC%9E%84/"},{"categories":["Algorithm","study6"],"content":"`\n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56  import java.io.BufferedReader; import java.io.IOException; import java.io.InputStreamReader; import java.util.ArrayList; import java.util.Collections; import java.util.List; import java.util.StringTokenizer; public class B2529 { static int N; static char[] arr; static List\u003cString\u003e num = new ArrayList\u003c\u003e(); static boolean[] visit = new boolean[10]; public static void main(String[] args) throws IOException { BufferedReader br = new BufferedReader(new InputStreamReader(System.in)); StringTokenizer st; N = Integer.parseInt(br.readLine()); arr = new char[N]; st = new StringTokenizer(br.readLine()); for (int i = 0; i \u003c N; i++) { arr[i] = st.nextToken().charAt(0); } search(0, new String()); // 조건 만족한 문자열 정렬 \tCollections.sort(num); System.out.println(num.get(num.size() - 1) +\"\\n\" + num.get(0)); } private static void search(int cnt, String sb) { if (cnt == N + 1) { num.add(sb); return; } for (int i = 0; i \u003c 10; i++) { // 방문 여부 및 부등호 연산이 맞는지 체크 \tif (!visit[i] \u0026\u0026 (cnt == 0 || check(sb.charAt(cnt - 1) - '0', i, arr[cnt - 1]))) { visit[i] = true; search(cnt + 1, sb + i); visit[i] = false; } } } private static boolean check(int prior, int idx, char op) { if (op == '\u003c' \u0026\u0026 prior \u003e idx) return false; if (op == '\u003e' \u0026\u0026 prior \u003c idx) return false; return true; } }   ","description":"","tags":null,"title":"[백준]_2529_부등호","uri":"/posts/algorithm/study6/%EB%B0%B1%EC%A4%80_2529_%EB%B6%80%EB%93%B1%ED%98%B8/"},{"categories":["Algorithm","study6"],"content":"` 구현 문제…? 더 깔끔한 방법이 있을 것 같지만 잘 생각나지 않아 일일이 계산하는 방식을 택함…\n for문 3개를 써서 win + lose + draw 가 20일 때 조건 만족 확률과 경우의 수 계산  확률 : $ W^{win} * L^{lose} * D^{draw} $ 경우의 수 : $ 20! \\over (win! * lose! * draw!) $     1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54  import java.io.BufferedReader; import java.io.IOException; import java.io.InputStreamReader; import java.util.StringTokenizer; public class B14613 { static double W,L,D; static double[] arr = new double[5]; public static void main(String[] args) throws IOException { BufferedReader br = new BufferedReader(new InputStreamReader(System.in)); StringBuilder sb = new StringBuilder(); StringTokenizer st = new StringTokenizer(br.readLine()); W = Double.parseDouble(st.nextToken()); L = Double.parseDouble(st.nextToken()); D = Double.parseDouble(st.nextToken()); for (int win = 0; win \u003c= 20; win++){ for (int lose = 0; lose \u003c= 20; lose++){ for (int draw = 0; draw \u003c= 20; draw++){ if (win + lose + draw == 20){ int score = 2000 + win * 50 - lose * 50; double pro = Math.pow(W, win * 1.0) * Math.pow(L, lose * 1.0) * Math.pow(D, draw * 1.0) * factorial(20) / factorial(win) / factorial(draw) / factorial(lose); if (score \u003e= 1000 \u0026\u0026 score \u003c= 1499){ arr[0] += pro; }else if (score \u003e= 1500 \u0026\u0026 score \u003c= 1999){ arr[1] += pro; }else if (score \u003e= 2000 \u0026\u0026 score \u003c= 2499){ arr[2]+= pro; }else if (score \u003e= 2500 \u0026\u0026 score \u003c= 2999){ arr[3] += pro; }else if (score \u003e= 3000 \u0026\u0026 score \u003c= 3499){ arr[4] += pro; } } } } } for(double x : arr) { sb.append(String.format(\"%.8f\", x)).append(\"\\n\"); } System.out.println(sb); } private static double factorial(int x) { if (x\u003c=1) return 1.0; return x*factorial(x-1); } }   ","description":"","tags":null,"title":"[백준]_14613_너의 티어는","uri":"/posts/algorithm/study6/%EB%B0%B1%EC%A4%80_14613_%EB%84%88%EC%9D%98%ED%8B%B0%EC%96%B4%EB%8A%94/"},{"categories":["Algorithm","study5"],"content":"`brute force + 비트마스킹\n그냥 풀면 시간 초과날거 같아서 비트마스킹을 사용해보려 했는데 어떻게 할지 잘 몰라서 찾아봤다….\n 단어에서 알파벳의 자리수를 and/or 연산을 통해 비트를 켜고 끄고 26개의 1비트를 만들어 비교하는 방식을 찾아 적용해 봄   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55  import java.io.BufferedReader; import java.io.IOException; import java.io.InputStreamReader; import java.util.StringTokenizer; public class B18119 { static int N, M, cnt; static char[] idx = new char[2]; static int[] bit; static int alpha = (1 \u003c\u003c 27) - 1; /// 26개 1비트 \tstatic String s; public static void main(String[] args) throws IOException { BufferedReader br = new BufferedReader(new InputStreamReader(System.in)); StringTokenizer st = new StringTokenizer(br.readLine()); StringBuilder sb = new StringBuilder(); N = Integer.parseInt(st.nextToken()); M = Integer.parseInt(st.nextToken()); bit = new int[N]; while (N-- \u003e 0) { s = br.readLine(); for (char c : s.toCharArray()) { bit[N] |= 1 \u003c\u003c (c - 'a'); } // 각 문자열 비트 생성 \t} while(M--\u003e0) { st = new StringTokenizer(br.readLine()); char o = st.nextToken().charAt(0); char c = st.nextToken().charAt(0); // and/or 연산을 통해 비트를 켜고 끔 \tif(o=='1') { alpha \u0026= ~(1 \u003c\u003c (c -'a')); }else { alpha |= (1\u003c\u003c(c -'a')); } //\tSystem.out.println(Integer.toBinaryString(alpha)); \tcnt = 0; // 단어가 전부 있을 경우 연산 그대로 되는 듯 \tfor(int i : bit) { if((alpha \u0026 i) \u003e= i) cnt++; } sb.append(cnt).append(\"\\n\"); } System.out.println(sb); } }   bit masking int 는 32bit이기 때문에 알파벳 문제에 적용해볼 수 있다.\n OR : 삽입 AND : 삭제 XOR : 삭제  ","description":"","tags":null,"title":"[백준]_18119_단어암기","uri":"/posts/algorithm/study5/%EB%B0%B1%EC%A4%80_18119_%EB%8B%A8%EC%96%B4%EC%95%94%EA%B8%B0/"},{"categories":["Algorithm","study5"],"content":"`bfs\n 처음에 너무 어렵게 생각해서 Map이랑 Set을 막 써보다 결국 Map 안에 Set을 넣는 경지까지 이르러버림. 방문 여부를 bfs 안에서 방문 여부랑 전체 방문 여부를 생각했는데 하나만 해줘도 되었다.   처음 짠 코드(1500ms정도)\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129  import java.io.BufferedReader; import java.io.IOException; import java.io.InputStreamReader; import java.util.*; public class Main { private static class Point{ int x,y; public Point(int x, int y) { this.x = x; this.y = y; } @Override public int hashCode() { final int prime = 31; int result = 1; result = prime * result + x; result = prime * result + y; return result; } @Override public boolean equals(Object obj) { Point other = (Point) obj; if (x != other.x) return false; if (y != other.y) return false; return true; } } static int N, L, R, nx,ny, cnt=0; static boolean flag; static int[][] arr, delta = { { 0, 1 }, { 1, 0 }, { 0, -1 }, { -1, 0 } }; static Set\u003cPoint\u003e visited; // bfs 하는 동안 방문 여부 \tstatic Set\u003cPoint\u003e global_visited; // 전체 탐색 중 방문 여부 \tstatic Queue\u003cPoint\u003e q; static Map\u003cSet\u003cPoint\u003e, Integer\u003e union; // 방문한 곳과 평균 값 담을 것 \tpublic static void main(String[] args) throws IOException { BufferedReader br = new BufferedReader(new InputStreamReader(System.in)); StringTokenizer st = new StringTokenizer(br.readLine()); N = Integer.parseInt(st.nextToken()); L = Integer.parseInt(st.nextToken()); R = Integer.parseInt(st.nextToken()); arr = new int[N][N]; for(int i=0;i\u003cN;i++) { st = new StringTokenizer(br.readLine()); for(int j=0;j\u003cN;j++) { arr[i][j] = Integer.parseInt(st.nextToken()); } } while(true) { flag = false; global_visited = new HashSet\u003c\u003e(); union = new HashMap\u003c\u003e(); for(int i=0;i\u003cN;i++) { for(int j=0;j\u003cN;j++) { if(!global_visited.contains(new Point(i,j))) { int get = bfs(i,j); if(visited.size()\u003e1) union.put(visited,get); //bfs 내 방문한 곳과 평균값 넣기 \tglobal_visited.addAll(visited); // 방문한 곳 전체 표시 \t} } } if(!flag) break; // bfs 내 거리 조건에 한 번도 들어가지 않았다면 종료 \tSet\u003cSet\u003cPoint\u003e\u003e s = union.keySet(); Iterator\u003cSet\u003cPoint\u003e\u003e iter = s.iterator(); // 키 값 순회를 위해 iterator 선언 \twhile(iter.hasNext()) { Set\u003cPoint\u003e sp = iter.next(); int m = union.get(sp); for(Point pi : sp) { // 방문한 곳 값 적용 \tarr[pi.x][pi.y] = m; } } cnt++; } System.out.println(cnt); } private static int bfs(int x, int y) { int sum = 0, num=0; visited = new HashSet\u003c\u003e(); // bfs 내 방문여부 \tvisited.add(new Point(x,y)); q = new LinkedList\u003c\u003e(); q.offer(new Point(x,y)); while(!q.isEmpty()) { Point p = q.poll(); sum+=arr[p.x][p.y]; num++; for(int i=0;i\u003c4;i++) { nx = p.x+delta[i][0]; ny = p.y+delta[i][1]; if(inside(nx,ny)\u0026\u0026!global_visited.contains(new Point(nx,ny)) \u0026\u0026!visited.contains(new Point(nx,ny))) { int dist = Math.abs(arr[p.x][p.y] - arr[nx][ny]); if(dist \u003e=L \u0026\u0026 dist \u003c=R) { flag = true; Point ps = new Point(nx,ny); q.offer(ps); visited.add(ps); // 거리 조건 만족하면 큐와 방문 set에 넣기 \t} } } } return sum/num; } private static boolean inside(int x, int y) { return x \u003e= 0 \u0026\u0026 x \u003c N \u0026\u0026 y \u003e= 0 \u0026\u0026 y \u003c N; } }    새롭게 짠 코드 (664ms 정도)\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96  import java.io.BufferedReader; import java.io.IOException; import java.io.InputStreamReader; import java.util.*; public class B16234 { private static class Point{ int x,y; public Point(int x, int y) { this.x = x; this.y = y; } } static int N, L, R, nx,ny, cnt=0; static boolean flag; static int[][] arr, delta = { { 0, 1 }, { 1, 0 }, { 0, -1 }, { -1, 0 } }; static boolean[][] visited; static Queue\u003cPoint\u003e q; public static void main(String[] args) throws IOException { BufferedReader br = new BufferedReader(new InputStreamReader(System.in)); StringTokenizer st = new StringTokenizer(br.readLine()); N = Integer.parseInt(st.nextToken()); L = Integer.parseInt(st.nextToken()); R = Integer.parseInt(st.nextToken()); arr = new int[N][N]; for(int i=0;i\u003cN;i++) { st = new StringTokenizer(br.readLine()); for(int j=0;j\u003cN;j++) { arr[i][j] = Integer.parseInt(st.nextToken()); } } while(true) { flag = false; visited = new boolean[N][N]; union = new HashMap\u003c\u003e(); for(int i=0;i\u003cN;i++) { for(int j=0;j\u003cN;j++) { if(!visited[i][j]) { bfs(i,j); } } } if(!flag) break; cnt++; } System.out.println(cnt); } private static void bfs(int x, int y) { int sum = 0, num=0; List\u003cPoint\u003e list = new ArrayList\u003c\u003e(); visited[x][y] = true; q = new LinkedList\u003c\u003e(); q.offer(new Point(x,y)); while(!q.isEmpty()) { Point p = q.poll(); sum+=arr[p.x][p.y]; num++; list.add(new Point(p.x,p.y)); for(int i=0;i\u003c4;i++) { nx = p.x+delta[i][0]; ny = p.y+delta[i][1]; if(inside(nx,ny)\u0026\u0026!visited[nx][ny]) { int dist = Math.abs(arr[p.x][p.y] - arr[nx][ny]); if(dist \u003e=L \u0026\u0026 dist \u003c=R) { flag = true; Point ps = new Point(nx,ny); q.offer(ps); visited[nx][ny] = true; } } } } // 여기서 바로 처리해 버리기 \tint average = sum/num; for(Point p: list) { arr[p.x][p.y] = average; } } private static boolean inside(int x, int y) { return x \u003e= 0 \u0026\u0026 x \u003c N \u0026\u0026 y \u003e= 0 \u0026\u0026 y \u003c N; } }   ","description":"","tags":null,"title":"[백준]_16234_인구이동","uri":"/posts/algorithm/study5/%EB%B0%B1%EC%A4%80_16234_%EC%9D%B8%EA%B5%AC%EC%9D%B4%EB%8F%99/"},{"categories":["Algorithm","Study5"],"content":"`stack 이용 문제\n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51  import java.io.BufferedReader; import java.io.IOException; import java.io.InputStreamReader; import java.util.Stack; import java.util.StringTokenizer; public class B2841 { static int N,P,num,line, count = 0; static Stack\u003cInteger\u003e[] arr = new Stack[6]; // 6개의 stack 배열 \tpublic static void main(String[] args) throws IOException { BufferedReader br = new BufferedReader(new InputStreamReader(System.in)); StringTokenizer st = new StringTokenizer(br.readLine()); N = Integer.parseInt(st.nextToken()); P = Integer.parseInt(st.nextToken()); for(int i=0;i\u003c6;i++) { arr[i] = new Stack\u003c\u003e(); } while(N--\u003e0) { st = new StringTokenizer(br.readLine()); line = Integer.parseInt(st.nextToken()); num = Integer.parseInt(st.nextToken()); while(true) { if(arr[line].isEmpty()) { arr[line].push(num); count++; break; } // 비어 있지 않은 경우 \tint peek = arr[line].peek(); // 값이 더 클 경우 pop \tif(peek \u003e num) { arr[line].pop(); count++; } // 값이 작을 경우 새로운 값 넣고 종료 \telse if(peek\u003cnum){ arr[line].push(num); count++; break; // 같을 경우 종료 \t}else break; } } System.out.println(count); } }   ","description":"","tags":null,"title":"[백준]_11501_주식","uri":"/posts/algorithm/study5/%EB%B0%B1%EC%A4%80_11501_%EC%A3%BC%EC%8B%9D/"},{"categories":["Algorithm","study5"],"content":"`divide and conquer\n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56  import java.io.BufferedReader; import java.io.IOException; import java.io.InputStreamReader; import java.util.StringTokenizer; public class B1780 { static int N; static int[] count = new int[3]; static int[][] arr; public static void main(String[] args) throws IOException { BufferedReader br = new BufferedReader(new InputStreamReader(System.in)); StringBuilder sb = new StringBuilder(); StringTokenizer st; N = Integer.parseInt(br.readLine()); arr = new int[N][N]; for(int i=0; i\u003cN;i++) { st = new StringTokenizer(br.readLine()); for(int j=0; j\u003cN;j++) { arr[i][j] = Integer.parseInt(st.nextToken()); } } divide(0,0,N); for(int i=0; i\u003c3;i++) { sb.append(count[i]).append(\"\\n\"); } System.out.println(sb); } private static void divide(int r, int c, int range) { // 조건 만족 시 종이 개수 카운트 \tif(isSame(r,c,range)) { count[arr[r][c]+1]++; return; } // 조건을 만족하지 못했을 때 3 * 3으로 나누기 \tint three = range/3; for(int i=0; i\u003c3;i++) { for(int j=0; j\u003c3;j++) { divide(r + three*i,c + three*j,three); } } } // 범위 내 종이가 같은지 체크 \tprivate static boolean isSame(int r, int c, int range) { int one = arr[r][c]; for(int i=r; i\u003cr+range;i++) { for(int j=c; j\u003cc+range;j++) { if(arr[i][j]!=one) return false; } } return true; } }   ","description":"","tags":null,"title":"[백준]_1780_종이의 개수","uri":"/posts/algorithm/study5/%EB%B0%B1%EC%A4%80_1780_%EC%A2%85%EC%9D%B4%EC%9D%98%EA%B0%9C%EC%88%98/"},{"categories":["Algorithm","study5"],"content":"`divide and conquer\n1과 4 사이의 숫자 조합 개수를 출력하는 문제(2의 거듭제곱)\n 처음에 divide(x/2) * divide(x/2) * (x%2+1) 로 제출하다가 시간초과됨   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24  import java.io.BufferedReader; import java.io.IOException; import java.io.InputStreamReader; public class B18291 { static int T,N; static final long m = 1000000007; public static void main(String[] args) throws IOException { BufferedReader br = new BufferedReader(new InputStreamReader(System.in)); StringBuilder sb = new StringBuilder(); T = Integer.parseInt(br.readLine()); for(int tc=0;tc\u003cT;tc++) { N = Integer.parseInt(br.readLine()); sb.append(N==1?1:divide(N-2)).append(\"\\n\"); } System.out.println(sb); } private static long divide(int x) { if(x==0) return 1; long temp = divide(x/2); return temp*temp*(x%2+1)% m; } }   ","description":"","tags":null,"title":"[백준]_18291_비요뜨의 징검다리 건너기","uri":"/posts/algorithm/study5/%EB%B0%B1%EC%A4%80_18291_%EB%B9%84%EC%9A%94%EB%9C%A8%EC%9D%98-%EC%A7%95%EA%B2%80%EB%8B%A4%EB%A6%AC-%EA%B1%B4%EB%84%88%EA%B8%B0/"},{"categories":["Algorithm","study5"],"content":"`stack 이용 문제\n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51  import java.io.BufferedReader; import java.io.IOException; import java.io.InputStreamReader; import java.util.Stack; import java.util.StringTokenizer; public class B2841 { static int N,P,num,line, count = 0; static Stack\u003cInteger\u003e[] arr = new Stack[6]; // 6개의 stack 배열 \tpublic static void main(String[] args) throws IOException { BufferedReader br = new BufferedReader(new InputStreamReader(System.in)); StringTokenizer st = new StringTokenizer(br.readLine()); N = Integer.parseInt(st.nextToken()); P = Integer.parseInt(st.nextToken()); for(int i=0;i\u003c6;i++) { arr[i] = new Stack\u003c\u003e(); } while(N--\u003e0) { st = new StringTokenizer(br.readLine()); line = Integer.parseInt(st.nextToken()); num = Integer.parseInt(st.nextToken()); while(true) { if(arr[line].isEmpty()) { arr[line].push(num); count++; break; } // 비어 있지 않은 경우 \tint peek = arr[line].peek(); // 값이 더 클 경우 pop \tif(peek \u003e num) { arr[line].pop(); count++; } // 값이 작을 경우 새로운 값 넣고 종료 \telse if(peek\u003cnum){ arr[line].push(num); count++; break; // 같을 경우 종료 \t}else break; } } System.out.println(count); } }   ","description":"","tags":null,"title":"[백준]_2841_외계인의 기타 연주","uri":"/posts/algorithm/study5/%EB%B0%B1%EC%A4%80_2841_%EC%99%B8%EA%B3%84%EC%9D%B8/"},{"categories":["Algorithm","study4"],"content":"`Binary search\n저번 스터디를 통해 이분 탐색을 알게 되었고 조건식 및 부등호 여부만 잘 생각하면 되는 문제였다.\n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44  import java.io.BufferedReader; import java.io.IOException; import java.io.InputStreamReader; import java.util.StringTokenizer; public class B1654 { static int N, M, cnt = 0; static long[] arr; public static void main(String[] args) throws IOException { BufferedReader br = new BufferedReader(new InputStreamReader(System.in)); StringTokenizer st = new StringTokenizer(br.readLine()); N = Integer.parseInt(st.nextToken()); M = Integer.parseInt(st.nextToken()); long max = 0; arr = new long[N]; for (int i = 0; i \u003c N; i++) { arr[i] = Integer.parseInt(br.readLine()); max = Math.max(arr[i], max); } binarySearch(1,max); } private static void binarySearch(long start, long end) { long mid = 0; while (start \u003c= end) { int cnt = 0; mid = (start + end) / 2; // 개수를 찾는 과정  for(int i =0;i\u003cN;i++) { cnt+=arr[i]/mid; } if (cnt \u003c M) { end = mid - 1; } else { start = mid + 1; } // 최대 길이를 구하므로 여기서 부등호  } System.out.println(start-1); } }   ","description":"","tags":null,"title":"[백준]_1654_랜선자르기","uri":"/posts/algorithm/study4/%EB%B0%B1%EC%A4%80_1654_%EB%9E%9C%EC%84%A0%EC%9E%90%EB%A5%B4%EA%B8%B0/"},{"categories":["Algorithm","study4"],"content":"`Tree 탐색\n저번 스터디를 통해 트리를 만들어 본 걸 이용해서 해결\n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55  import java.io.BufferedReader; import java.io.IOException; import java.io.InputStreamReader; import java.util.ArrayList; import java.util.StringTokenizer; public class B1068 { static int N,P,D, cnt=0; static int[] parent; static boolean [] visited; static ArrayList\u003cInteger\u003e[] tree; public static void main(String[] args) throws IOException { BufferedReader br = new BufferedReader(new InputStreamReader(System.in)); N = Integer.parseInt(br.readLine()); tree = new ArrayList[N]; visited = new boolean[N]; StringTokenizer st = new StringTokenizer(br.readLine());\tfor (int i = 0; i \u003c N; i++) { tree[i] = new ArrayList\u003cInteger\u003e(); } int root = 0; for (int i = 0; i \u003c N; i++) { P = Integer.parseInt(st.nextToken()); if (P == -1) { root = i; continue; } tree[P].add(i); tree[i].add(P); } D = Integer.parseInt(br.readLine()); if(root==D) { System.out.println(0); return; } search(root); System.out.println(cnt); } static void search(int num) { visited[num] = true; int child = 0; // D가 root인 subtree는 탐색하지 않고 모든 자식을 찾는 과정 \tfor( int i = 0 ; i \u003c tree[num].size() ; i++ ) { int son = tree[num].get(i); if(!visited[son] \u0026\u0026 son != D) { child++; search(son); } } if(child==0) { cnt++; } }   ","description":"","tags":null,"title":"[백준]_18119_단어암기","uri":"/posts/algorithm/study4/%EB%B0%B1%EC%A4%80_1068_%ED%8A%B8%EB%A6%AC/"},{"categories":["Algorithm","study4"],"content":"`map을 이용해 구현\n처음부터 시뮬레이션 하듯이 스트리밍 전, 후~종료 에 대한 처리를 순차적으로 함.\n아예 안 들어오는 경우를 생각 안 했다가 br.readline == null 을 넣고 해결\n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84  import java.io.BufferedReader; import java.io.IOException; import java.io.InputStreamReader; import java.util.HashMap; import java.util.Map; import java.util.StringTokenizer; public class B19583 { static int cnt = 0; static int[] time = new int[3]; static StringTokenizer st, st1; public static void main(String[] args) throws IOException { int h=0, m=0; String rename=new String(), line=new String(); BufferedReader br = new BufferedReader(new InputStreamReader(System.in)); st = new StringTokenizer(br.readLine(), \" \"); Map\u003cString, Boolean\u003e map = new HashMap\u003c\u003e(); // map에 아이디와 중복 여부 판별을 위해 boolean을 넣음 \tfor (int i = 0; i \u003c 3; i++) { st1 = new StringTokenizer(st.nextToken(), \":\"); h = Integer.parseInt(st1.nextToken()); m = Integer.parseInt(st1.nextToken()); time[i] = calTime(h,m); } // 스트리밍 시작 전 들어온 사람 map에 넣기 \twhile ((line = br.readLine()) != null) { st = new StringTokenizer(line, \" \"); st1 = new StringTokenizer(st.nextToken(), \":\"); h = Integer.parseInt(st1.nextToken()); m = Integer.parseInt(st1.nextToken()); if (calTime(h, m)\u003c=time[0]) { map.put(st.nextToken(), false); }else { rename = st.nextToken(); break; } } // 스트리밍 중 들어온 사람 처리 후 끝나고 들어온 사람이 있을 경우 넘어감 \tif (calTime(h, m)\u003c time[1]) { while ((line = br.readLine()) != null \u0026\u0026 calTime(h, m)\u003c time[1]) { st = new StringTokenizer(line, \" \"); st1 = new StringTokenizer(st.nextToken(), \":\"); h = Integer.parseInt(st1.nextToken()); m = Integer.parseInt(st1.nextToken()); rename = st.nextToken(); } } if (calTime(h, m)\u003e= time[1] \u0026\u0026 calTime(h, m)\u003c= time[2] \u0026\u0026 map.containsKey(rename)) { cnt++; map.put(rename, true); } // 스트리밍 끝 ~종료 때 있는 사람 체크 \twhile ((line = br.readLine()) != null) { st = new StringTokenizer(line, \" \"); st1 = new StringTokenizer(st.nextToken(), \":\"); h = Integer.parseInt(st1.nextToken()); m = Integer.parseInt(st1.nextToken()); if (calTime(h, m)\u003e= time[1] \u0026\u0026 calTime(h, m)\u003c= time[2]) { rename = st.nextToken(); if (map.containsKey(rename) \u0026\u0026 !map.get(rename)) { cnt++; map.put(rename, true); } }else { break; } } System.out.println(cnt); } // 시간비교를 위함 \tstatic int calTime(int hour, int min) { return hour*60 + min; } }   ","description":"","tags":null,"title":"[백준]_19583_싸이버개강총회","uri":"/posts/algorithm/study4/%EB%B0%B1%EC%A4%80_19583_%EC%8B%B8%EC%9D%B4%EB%B2%84%EA%B0%9C%EA%B0%95%EC%B4%9D%ED%9A%8C/"},{"categories":["Algorithm","study4"],"content":"`.\n물병을 2의 배수만큼 만들 수 있어서 이진법으로 쪽으로 생각하다가 2를 나누면서 나오는 1의 개수가 물병 개수라고 생각할 수 있었음.\n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29  import java.io.BufferedReader; import java.io.IOException; import java.io.InputStreamReader; import java.util.StringTokenizer; public class B1052 { static int N, M,cnt=0; public static void main(String[] args) throws IOException { BufferedReader br = new BufferedReader(new InputStreamReader(System.in)); StringTokenizer st = new StringTokenizer(br.readLine()); N = Integer.parseInt(st.nextToken()); M = Integer.parseInt(st.nextToken()); while(true) { int k = N + cnt, one = 0; // 나머지가 1일 경우 물병 하나 생성 \twhile(k!=0) { one+=k%2; k/=2; } // 만들어지는 물병 수가 M이하 \tif(one \u003c= M) { break; }else cnt++; } System.out.println(cnt); } }   ","description":"","tags":null,"title":"[백준]_1052_물병","uri":"/posts/algorithm/study4/%EB%B0%B1%EC%A4%80_1052_%EB%AC%BC%EB%B3%91/"},{"categories":["Algorithm","study4"],"content":"`greedy\ngreedy한 문제를 풀고 싶어서 내가 선택한 문제. 단순히 처음부터 검사해서 다르면 전환해서 풀면 되는 문제였다.\n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68  import java.io.BufferedReader; import java.io.IOException; import java.io.InputStreamReader; import java.util.StringTokenizer; public class B1080 { static int N, M,cnt=0; static boolean [][] A, B; static BufferedReader br = new BufferedReader(new InputStreamReader(System.in)); public static void main(String[] args) throws IOException { StringTokenizer st = new StringTokenizer(br.readLine()); N = Integer.parseInt(st.nextToken()); M = Integer.parseInt(st.nextToken()); // matrix를 받는 함수 \tA = getMatrix(A); B = getMatrix(B); if (N \u003c 3 || M \u003c 3) { System.out.println(isSame() ? cnt : -1); return ; } for(int i=0;i\u003cN-2;i++) { for(int j=0;j\u003cM-2;j++) { if(A[i][j] ^ B[i][j]) { // 다를 경우 바꾸는 함수 \tcnt += change(i,j); } } } // 전체적으로 확인 \tSystem.out.println(isSame() ? cnt : -1); } private static boolean[][] getMatrix(boolean[][] getM) throws IOException{ getM = new boolean[N][M]; for(int i=0;i\u003cN;i++) { String b = br.readLine(); for(int j=0;j\u003cM;j++) { getM[i][j] = b.charAt(j) == '1' ? true : false; } } return getM; } private static boolean isSame() { for (int i = 0; i \u003c N; i++) { for (int j = 0; j \u003c M; j++) { if (A[i][j] != B[i][j]) return false; } } return true; } // 3 * 3 영역을 바꾸는 함수 \tprivate static int change(int row, int col) { for (int i = row; i \u003c row + 3; i++) { for (int j = col; j \u003c col + 3; j++) { A[i][j] = !A[i][j]; } } return 1; } }   ","description":"","tags":null,"title":"[백준]_1080_행렬","uri":"/posts/algorithm/study4/%EB%B0%B1%EC%A4%80_1080_%ED%96%89%EB%A0%AC/"},{"categories":["Algorithm","Study3"],"content":"`브루트 포스 + 백트래킹\n예시가 너무해서 찾다가 유사한 다른 문제를 찾았다\nhttps://www.acmicpc.net/problem/1038\n  조합을 구했을 때 모든 수가 중복되지 않아 그것을 큰 순서로 나열했을 때 모두 줄어드는 숫자라 할 수 있다.\n  $_{n} \\mathrm{C}_{0} + _{n} \\mathrm{C}_{1} + … + _{n} \\mathrm{C}_{n} = 2^n$ 이기 때문에 하나도 뽑지 않을 경우를 제외한 1023가지의 경우의 수 밖에 나올 수 없음.\n   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55  import java.io.BufferedReader; import java.io.IOException; import java.io.InputStreamReader; import java.util.StringTokenizer; public class B18119 { static int N, M, cnt; static char[] idx = new char[2]; static int[] bit; static int alpha = (1 \u003c\u003c 27) - 1; /// 26개 1비트 \tstatic String s; public static void main(String[] args) throws IOException { BufferedReader br = new BufferedReader(new InputStreamReader(System.in)); StringTokenizer st = new StringTokenizer(br.readLine()); StringBuilder sb = new StringBuilder(); N = Integer.parseInt(st.nextToken()); M = Integer.parseInt(st.nextToken()); bit = new int[N]; while (N-- \u003e 0) { s = br.readLine(); for (char c : s.toCharArray()) { bit[N] |= 1 \u003c\u003c (c - 'a'); } // 각 문자열 비트 생성 \t} while(M--\u003e0) { st = new StringTokenizer(br.readLine()); char o = st.nextToken().charAt(0); char c = st.nextToken().charAt(0); // and/or 연산을 통해 비트를 켜고 끔 \tif(o=='1') { alpha \u0026= ~(1 \u003c\u003c (c -'a')); }else { alpha |= (1\u003c\u003c(c -'a')); } //\tSystem.out.println(Integer.toBinaryString(alpha)); \tcnt = 0; // 단어가 전부 있을 경우 연산 그대로 되는 듯 \tfor(int i : bit) { if((alpha \u0026 i) \u003e= i) cnt++; } sb.append(cnt).append(\"\\n\"); } System.out.println(sb); } }   bit masking int 는 32bit이기 때문에 알파벳 문제에 적용해볼 수 있다.\n OR : 삽입 AND : 삭제 XOR : 삭제  ","description":"","tags":null,"title":"[백준]_1174_줄어드는 숫자","uri":"/posts/algorithm/study3/%EB%B0%B1%EC%A4%80_1174_%EC%A4%84%EC%96%B4%EB%93%9C%EB%8A%94%EC%88%AB%EC%9E%90/"},{"categories":["Algorithm","Study3"],"content":"`Dynamic Programming\n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42  import java.io.BufferedReader; import java.io.IOException; import java.io.InputStreamReader; import java.util.StringTokenizer; public class B1106 { static int C,N; static int [] price,custom, arr; public static void main(String[] args) throws IOException { BufferedReader br = new BufferedReader(new InputStreamReader(System.in)); StringTokenizer st; st = new StringTokenizer(br.readLine()); C = Integer.parseInt(st.nextToken()); N = Integer.parseInt(st.nextToken()); arr = new int[1001]; price = new int[N]; custom = new int[N]; for(int i= 0;i\u003cN;i++) { st = new StringTokenizer(br.readLine()); price[i] = Integer.parseInt(st.nextToken()); custom[i] = Integer.parseInt(st.nextToken()); } System.out.println(cal(C,N)); } static int cal(int c, int n) { int min=100000, temp=0; // c가 범위를 넘어설 경우(최소이기 때문에 값 이상을 넘어 갈 수도 있음) \tif(c\u003c=0) return 0; // 값이 이미 존재 \telse if(arr[c]\u003e0) return arr[c]; // 이전 값과 새로운 price를 더함. \tfor(int i=0;i\u003cn;i++) { temp = cal(c - custom[i],n) + price[i]; min = temp \u003c min ? temp : min; } // 최소 값 할당 \tarr[c] = min; return min; } }   ","description":"","tags":null,"title":"[백준]_1106_호텔","uri":"/posts/algorithm/study3/%EB%B0%B1%EC%A4%80_1106_%ED%98%B8%ED%85%94/"},{"categories":["Algorithm","Study3"],"content":"`map을 사용하여 구현하는 방식의 문제.\n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44  import java.io.BufferedReader; import java.io.IOException; import java.io.InputStreamReader; import java.util.HashMap; import java.util.Map; public class B11652 { public static void main(String[] args) throws IOException { BufferedReader br = new BufferedReader(new InputStreamReader(System.in)); int N = Integer.parseInt(br.readLine()); // 범위가 2^63이므로 \tMap\u003cLong, Integer\u003e map = new HashMap\u003cLong, Integer\u003e(); int max = 1; long k=0, maxidx=0; for(int i=0;i\u003cN;i++) { k = Long.parseLong(br.readLine()); // key가 이미 존재 \tif(map.containsKey(k)){ map.put(k,map.get(k)+1); // 같거나 클 경우  if(max == map.get(k)){ maxidx = Math.min(maxidx, k); }else if(max \u003c map.get(k)){ max=map.get(k); maxidx = k; } // 없을 때 새로운 key 넣기  }else { map.put(k,1); // 처음에 넣은 것으로 지정  if(map.size()==1){ maxidx = k; } if(max ==1){ maxidx = Math.min(maxidx, k); } } } System.out.println(maxidx); } }   ","description":"","tags":null,"title":"[백준]_11652_카드","uri":"/posts/algorithm/study3/%EB%B0%B1%EC%A4%80_11652_%EC%B9%B4%EB%93%9C/"},{"categories":["Algorithm","Study3"],"content":"`BFS\nBFS를 알게 되고 나서 거의 처음 풀어본 문제들. 두 문제의 탐색 방향과 미로 탐색에서 배열을 받아서 푼 것 이외에는 풀이가 거의 비슷하다.\n 나이트의 이동\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82  import java.io.BufferedReader; import java.io.IOException; import java.io.InputStreamReader; import java.util.LinkedList; import java.util.Queue; import java.util.StringTokenizer; public class B7562 { static int T, I, x, y; static int[][] delta = {{-2,-1},{2,-1},{-2,1},{2,1},{1,2},{-1,2},{1,-2},{-1,-2}}; static boolean[][] visited; static Point start,end; public static void main(String[] args) throws IOException { BufferedReader br = new BufferedReader(new InputStreamReader(System.in)); StringBuilder sb = new StringBuilder(); StringTokenizer st; T = parse(br.readLine()); for (int i = 0; i \u003c T; i++) { I = parse(br.readLine()); visited = new boolean[I][I]; st = new StringTokenizer(br.readLine()); start = new Point(parse(st.nextToken()),parse(st.nextToken()),0); st = new StringTokenizer(br.readLine()); end = new Point(parse(st.nextToken()),parse(st.nextToken()),0); System.out.println(end.y); sb.append(gozero(start)).append(\"\\n\"); } System.out.println(sb); } static int gozero(Point at) { Queue\u003cPoint\u003e q = new LinkedList\u003c\u003e(); q.offer(at); visited[at.x][at.y] = true; while (!q.isEmpty()) { // queue에서 point 뽑기 \tPoint p = q.poll(); // end일 경우 끝내기 \tif (p.x == end.x \u0026\u0026 p.y == end.y) { return p.cnt; } for (int d = 0; d \u003c 8; d++) { int dx = p.x + delta[d][0]; int dy = p.y + delta[d][1]; // 방문 안 했을 때 queue에 넣기 \tif (inside(dx,dy) \u0026\u0026 !visited[dx][dy]){ visited[dx][dy] = true; q.offer(new Point(dx, dy, p.cnt + 1)); } } } // 모든 경우를 탐색하고 나오지 않을 때 \treturn -1; } static int parse(String s) { return Integer.parseInt(s); } static boolean inside(int nx, int ny) { return nx \u003e= 0 \u0026\u0026 nx \u003c I \u0026\u0026 ny \u003e= 0 \u0026\u0026 ny \u003c I; } } class Point{ int x; int y; int cnt; public Point(int x, int y,int cnt) { this.x = x; this.y = y; this.cnt = cnt; } }    미로 탐색\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77  import java.io.BufferedReader; import java.io.IOException; import java.io.InputStreamReader; import java.util.LinkedList; import java.util.Queue; import java.util.StringTokenizer; public class B2178 { static int N, M; static char[][] field; static int[][] delta = { { 1, 0 }, { 0, 1 }, { -1, 0 }, { 0, -1 } }; static Point start, end; static boolean[][] visited; public static void main(String[] args) throws IOException { BufferedReader br = new BufferedReader(new InputStreamReader(System.in)); StringTokenizer st; st = new StringTokenizer(br.readLine()); N = Integer.parseInt(st.nextToken()); M = Integer.parseInt(st.nextToken()); field = new char[N][M]; visited = new boolean[N][M]; for (int i = 0; i \u003c N; i++) { field[i] = br.readLine().toCharArray(); } start = new Point(0, 0, 0); end = new Point(N - 1, M - 1, 0); System.out.println(goend(start)+1); } static int goend(Point at) { Queue\u003cPoint\u003e q = new LinkedList\u003c\u003e(); q.offer(at); visited[at.x][at.y] = true; while (!q.isEmpty()) { // q에서 새로운 point 뽑기 \tPoint p = q.poll(); // end면 종료 \tif (p.x == end.x \u0026\u0026 p.y == end.y) { return p.cnt; } for (int d = 0; d \u003c 4; d++) { int dx = p.x + delta[d][0]; int dy = p.y + delta[d][1]; // 방문 안 한 곳이 1이면 queue에 넣기 \tif (inside(dx, dy) \u0026\u0026 !visited[dx][dy] \u0026\u0026 field[dx][dy] == '1') { visited[dx][dy] = true; q.offer(new Point(dx, dy, p.cnt + 1)); } } } // 끝까지 가기 실패 \treturn -1; } static boolean inside(int nx, int ny) { return nx \u003e= 0 \u0026\u0026 nx \u003c N \u0026\u0026 ny \u003e= 0 \u0026\u0026 ny \u003c M; } } class Point { int x; int y; int cnt; public Point(int x, int y, int cnt) { this.x = x; this.y = y; this.cnt = cnt; } }   ","description":"","tags":null,"title":"[백준]_7562_나이트의이동, 2178_미로 탐색","uri":"/posts/algorithm/study3/%EB%B0%B1%EC%A4%80_7562_%EB%82%98%EC%9D%B4%ED%8A%B8%EC%9D%98%EC%9D%B4%EB%8F%99_2178_%EB%AF%B8%EB%A1%9C-%ED%83%90%EC%83%89/"},{"categories":["Algorithm","Study2"],"content":"`비선형 자료구조인 graph를 구현하여 DFS를 해보는 문제\n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47  public class B2606_바이러스 { static ArrayList\u003cInteger\u003e[] a; static boolean[] visit; static int count; public static void main(String[] args) throws NumberFormatException, IOException { BufferedReader br = new BufferedReader(new InputStreamReader(System.in)); StringBuilder sb = new StringBuilder(); StringTokenizer st; int n = Integer.parseInt(br.readLine()); int m = Integer.parseInt(br.readLine()); a = new ArrayList[n+1]; visit = new boolean[n+1]; for (int i=1; i\u003c=n; i++) { a[i] = new ArrayList\u003cInteger\u003e(); } // 연결 된 부분 정보 저장 \tfor(int i=0;i\u003cm;i++) { st = new StringTokenizer(br.readLine()); int start = Integer.parseInt(st.nextToken()); int end = Integer.parseInt(st.nextToken()); a[start].add(end); a[end].add(start); } count=0; // 1번부터 탐색 \tsearch(1); System.out.println(count); } // 연결된 부분 탐색 \tpublic static void search(int x) { visit[x] = true; for (int y : a[x]) { if (visit[y] == false) { count++; search(y); } } } }   ","description":"","tags":null,"title":"[백준]_2606_바이러스","uri":"/posts/algorithm/study2/%EB%B0%B1%EC%A4%80_2606_%EB%B0%94%EC%9D%B4%EB%9F%AC%EC%8A%A4/"},{"categories":["Algorithm","Study2"],"content":"`조건에 맞도록 구현하는 문제\n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93  import java.io.BufferedReader; import java.io.IOException; import java.io.InputStreamReader; import java.util.HashMap; import java.util.Map; import java.util.StringTokenizer; public class B2621 { public static int[] color, digit; static int max_num, pair; // 각 상태와 max값, pair 값 등을 저장할 Map 선언 \tstatic Map\u003cString, Integer\u003e state; public static void main(String[] args) throws IOException { BufferedReader br = new BufferedReader(new InputStreamReader(System.in)); StringBuilder sb = new StringBuilder(); StringTokenizer st; color = new int[4]; digit = new int[10]; state = new HashMap\u003c\u003e(); for (int i = 0; i \u003c 5; i++) { st = new StringTokenizer(br.readLine()); char C = st.nextToken().charAt(0); int d = Integer.parseInt(st.nextToken()); // 색깔 저장 \tif (C == 'R') color[0]++; else if (C == 'B') color[1]++; else if (C == 'Y') color[2]++; else color[3]++; // 숫자 저장 \tdigit[d]++; max_num = Math.max(max_num, d); } // flush와 straight 상태 저장 \tfor (int i = 0; i \u003c 4; i++) { if (color[i] == 5) { state.put(\"flush\",i); break; } } for (int i = 0; i \u003c 6; i++) { if (digit[i] == 1 \u0026\u0026 digit[i + 1] == 1 \u0026\u0026 digit[i + 2] == 1 \u0026\u0026 digit[i + 3] == 1 \u0026\u0026 digit[i + 4] == 1) { state.put(\"straight\",i); break; } } // flush와 straight일 경우 점수 return \tif(state.containsKey(\"flush\")||state.containsKey(\"straight\")) { if(state.containsKey(\"flush\") \u0026\u0026 state.containsKey(\"straight\")) System.out.println(900 + max_num); else if(state.containsKey(\"flush\")) System.out.println(600 + max_num); else if(state.containsKey(\"straight\")) System.out.println(500 + max_num); return ; } // 같은 숫자 카드가 2,3,4장인지 확인 \tfor (int i = 0; i \u003c 10; i++) { if (digit[i] == 2) { if(state.containsKey(\"pair\")) state.put(\"two_pair\",i); else state.put(\"pair\",i); }else if(digit[i] == 3) { state.put(\"triple\",i); }else if(digit[i] == 4) { state.put(\"four\",i); } } if(state.containsKey(\"four\")) System.out.println(800 + state.get(\"four\")); else if(state.containsKey(\"triple\")) { int n = state.containsKey(\"pair\") ? 700+10*state.get(\"triple\") + state.get(\"pair\"): 400 + state.get(\"triple\"); System.out.println(n); } else if(state.containsKey(\"pair\")) { if(state.containsKey(\"two_pair\")) { int min_pair = Math.min(state.get(\"pair\"), state.get(\"two_pair\")); int max_pair = Math.max(state.get(\"pair\"), state.get(\"two_pair\")); System.out.println(300+10*max_pair + min_pair); }else System.out.println(200 + state.get(\"pair\")); } else System.out.println(100 + max_num); } }   ","description":"","tags":null,"title":"[백준]_2621_카드게임","uri":"/posts/algorithm/study2/%EB%B0%B1%EC%A4%80_2621_%EC%B9%B4%EB%93%9C%EA%B2%8C%EC%9E%84/"},{"categories":["Algorithm","Study2"],"content":"`Binary search 문제\n이분 탐색을 처음 접한 문제\n left와 right 지정. right는 Y가 X보다 클 수 없기 때문에 X로 지정 left와 right의 가운데 값을 구한 뒤 승률을 구함 승률이 크면 right를 낮추고 아니면 left를 높인다. 최소값을 구하기 때문에 left가 lower bound가 될 것이므로 left 반환   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35  import java.io.BufferedReader; import java.io.IOException; import java.io.InputStreamReader; import java.util.StringTokenizer; public class B1072 { static long X,Y,Z; public static void main(String[] args) throws IOException { BufferedReader br = new BufferedReader(new InputStreamReader(System.in)); StringTokenizer st = new StringTokenizer(br.readLine()); X = Integer.parseInt(st.nextToken()); Y = Integer.parseInt(st.nextToken()); Z = Y * 100 / X; if(Z\u003e=99) System.out.println(-1); else { binarySearch(1, X); } } private static void binarySearch(long start, long end) { long mid = 0, ratio = 0; while (start \u003c= end) { mid = (start + end) / 2; ratio = (Y + mid) * 100 / (X + mid); if (ratio \u003e Z) { end = mid - 1; } else { start = mid + 1; } } System.out.println(start); } }   ","description":"","tags":null,"title":"[백준]_1072_게임","uri":"/posts/algorithm/study2/%EB%B0%B1%EC%A4%80_1072_%EA%B2%8C%EC%9E%84/"},{"categories":["Programming","Java"],"content":"` 상속과 다형성에 대해 알아보자\nInheritance B가 A의 member variables과 method를 그대로 받으면 상속받는다고 하고 부모-자식, 상위-하위 관계이다.\n 기존의 클래스에서 자산(변수,메서드)을 자식 클래스에서 재사용 → 코드의 절감 접근 제한자에 상관없이 상속되지만 자식에게 보이지 않을 뿐.. 어떤 Class가 아무런 상속을 받지 않을 경우, 자동으로 java.lang.Object.Class가 Class의 부모가 된다.  1 2 3  public class B extends A{ ... }   자바는 다중 상속 불가능\nis a\n extends 관계  has a\n 상속하지 못한다고 버릴 필요는 없고 멤버 변수로 가지고 있기  구분..?\n is a 적합한지 보기 (ex superman is a person? superman is a super?) 나머지는 has a  super : 조상 class의 생성자 호출\n super(name) 처럼 생성자로 넘기는 식으로 활용 가능 this를 통해서 가지고 있는 것과 상속받은 것을 확인할 수 있다.  this는 나의 다른 생성자를 부를 때도 사용\n주의사항\n  둘 다 첫 줄에 사용해야 함\n→ this와 super를 같이 쓸 순 없음\n  다음은 가능\n1 2 3 4  public Corona(String name, int level, int spreadSpeed){ super(name,level); this.spreadSpeed = spreadSpeed; }     명시적으로 this 또는 super를 호출하지 않으면 생성자의 첫 줄에는 super() 가 생략되어 있음.\n  하위 class에서 private, default로 접근할 수 없기 때문에 접근해야 할 것은 protected사용하거나 public method활용\n      상속      Object toString   Virus -   Corona toString   ChildCorona -    ","description":"","tags":null,"title":"OOP3","uri":"/posts/programming/java/oop3/"},{"categories":["Algorithm","Study2"],"content":"`BFS\nBFS를 알게 되고 나서 거의 처음 풀어본 문제들. 두 문제의 탐색 방향과 미로 탐색에서 배열을 받아서 푼 것 이외에는 풀이가 거의 비슷하다.\n N과 M(3)\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44  import java.io.BufferedReader; import java.io.IOException; import java.io.InputStreamReader; import java.util.StringTokenizer; public class B15651 { public static StringBuilder sb = new StringBuilder(); public static int N, M; public static int[] arr; public static boolean[] visit; public static void main(String[] args) throws IOException { BufferedReader br = new BufferedReader(new InputStreamReader(System.in)); StringTokenizer st = new StringTokenizer(br.readLine()); N = Integer.parseInt(st.nextToken()); M = Integer.parseInt(st.nextToken()); arr = new int[M]; visit = new boolean[N+1]; search(0); System.out.println(sb); } public static void search(int end) { if (end == M) { for (int i = 0; i \u003c M; i++) { sb.append(arr[i]).append(' '); } sb.append('\\n'); return; } for (int i = 1; i \u003c= N; i++) { if (!visit[i]) { visit[i] = true; arr[end] = i; search(end + 1); visit[i] = false; } } } }    N과 M(7)\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42  import java.io.BufferedReader; import java.io.IOException; import java.io.InputStreamReader; import java.util.Arrays; import java.util.StringTokenizer; public class B15656 { public static StringBuilder sb = new StringBuilder(); public static int N, M; public static int[] arr, output; public static void main(String[] args) throws IOException { BufferedReader br = new BufferedReader(new InputStreamReader(System.in)); StringTokenizer st = new StringTokenizer(br.readLine()); N = Integer.parseInt(st.nextToken()); M = Integer.parseInt(st.nextToken()); output = new int[N+1]; st = new StringTokenizer(br.readLine()); for (int i = 1; i \u003c= N; i++) { output[i] = Integer.parseInt(st.nextToken()); } Arrays.sort(output); arr = new int[M]; search(0); System.out.println(sb); } public static void search(int depth) { if(depth == M) { for(int i=0;i\u003cM;i++) { sb.append(arr[i]).append(' '); } sb.append('\\n'); return; } for(int i=1;i\u003c=N;i++) { arr[depth] = output[i]; search(depth+1); } } }   ","description":"","tags":null,"title":"[백준]_15651_15656_N과M3,7","uri":"/posts/algorithm/study2/%EB%B0%B1%EC%A4%80_15651_15656_nm/"},{"categories":["Programming","Java"],"content":"` 상속과 다형성에 대해 알아보자\nInheritance B가 A의 member variables과 method를 그대로 받으면 상속받는다고 하고 부모-자식, 상위-하위 관계이다.\n 기존의 클래스에서 자산(변수,메서드)을 자식 클래스에서 재사용 → 코드의 절감 접근 제한자에 상관없이 상속되지만 자식에게 보이지 않을 뿐.. 어떤 Class가 아무런 상속을 받지 않을 경우, 자동으로 java.lang.Object.Class가 Class의 부모가 된다.  1 2 3  public class B extends A{ ... }   자바는 다중 상속 불가능\nis a\n extends 관계  has a\n 상속하지 못한다고 버릴 필요는 없고 멤버 변수로 가지고 있기  구분..?\n is a 적합한지 보기 (ex superman is a person? superman is a super?) 나머지는 has a  super : 조상 class의 생성자 호출\n super(name) 처럼 생성자로 넘기는 식으로 활용 가능 this를 통해서 가지고 있는 것과 상속받은 것을 확인할 수 있다.  this는 나의 다른 생성자를 부를 때도 사용\n주의사항\n  둘 다 첫 줄에 사용해야 함\n→ this와 super를 같이 쓸 순 없음\n  다음은 가능\n1 2 3 4  public Corona(String name, int level, int spreadSpeed){ super(name,level); this.spreadSpeed = spreadSpeed; }     명시적으로 this 또는 super를 호출하지 않으면 생성자의 첫 줄에는 super() 가 생략되어 있음.\n  하위 class에서 private, default로 접근할 수 없기 때문에 접근해야 할 것은 protected사용하거나 public method활용\n      상속      Object toString   Virus -   Corona toString   ChildCorona -    ","description":"","tags":null,"title":"OOP2","uri":"/posts/programming/java/oop2/"},{"categories":["Algorithm","Sort"],"content":"정렬 ` 정렬해 보았다.\n 람다식 Arrays.sort는 2차원 배열은 정렬할 수 없다. 이를 람다식을 이용해 해결할 수 있다.\n예시로 좌표 정렬하기를 풀어보았고 아래는 정렬 부분 코드이다.\n1 2 3 4 5 6  Arrays.sort(arr1, (e1, e2) -\u003e{ if(e1[0]==e2[0]) return e1[1] - e2[1]; else return e1[0] - e2[0]; });   다음은 단어 정렬에 사용한 코드이다.\n1 2 3 4 5 6 7 8 9  Arrays.sort(arr1, new Comparator\u003cString\u003e() { public int compare(String s1, String s2) { if (s1.length() == s2.length()) { return s1.compareTo(s2); } else { return s1.length() - s2.length(); } } });   Comparator 에서 에 있는 것은 상속관계에 있는 타입까지 허용한다는 뜻인데 여기서는 T자체만 봐도 상관없다. 또한 method를 정의하여 사용할 수 있다.\n이렇게 람다식을 사용해 간결한 표현을 할 수 있다. python의 lambda와 함수와 비슷하여 어떻게 돌아가는 이해는 했으나 사용방식이 익숙치 않아 좀 더 연습해봐야 할 것 같다.\n","description":"","tags":null,"title":"정렬, 람다식","uri":"/posts/algorithm/sort/%EC%A0%95%EB%A0%AC-%EB%9E%8C%EB%8B%A4%EC%8B%9D/"},{"categories":["Algorithm","Other"],"content":"` 자바에서 입출력에 관련해서 다뤄보겠다. 기본적으로 사용한 코드의 문제점은 다음과 같다.\n 입력이 많을 경우, Scanner의 문제 출력이 많을 경우 ,System.out의 문제  몇몇 문제의 경우 위의 문제가 해결되지 않을 경우 시간초과가 난다고 하여 BufferedReader, StringBuilder 등을 알게 되어 사용법을 공부하였다.\nBufferedReader 버퍼를 사용하여 입력을 받고 한 번에 전송하는 방식을 사용하여 하나씩 전송하는 Scanner보다 효과적임.\n 출력으로 BufferedWriter가 있고 추후에 사용해볼 예정.  StringBuilder System.out 의 잦은 사용 및 String과 String을 더하고 빼는 과정에서 성능이 좋지 않음\n append를 이용해 이어붙여서 출력  아래 코드를 기본으로 사용한다.\n1 2  BufferedReader br = new BufferedReader(new InputStreamReader(System.in)); StringBuilder sb = new StringBuilder();   이를 이용해 다음 문제를 풀어보았다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23  import java.io.BufferedReader; import java.io.InputStreamReader; public class a { public static void main(String[] args) throws Exception { BufferedReader br = new BufferedReader(new InputStreamReader(System.in)); int N = Integer.parseInt(br.readLine()); StringBuilder sb = new StringBuilder(); for (int i = 0; i \u003c N; i++) {\tString str = br.readLine(); int target = str.indexOf(\" \"); int result = Integer.parseInt(str.substring(0,target)) + Integer.parseInt(str.substring(target + 1));\tsb.append(result+\"\\n\"); } br.close(); System.out.print(sb); } }   추가로 StringTokenizer가 있고 추후 공부할 예정이다.\n","description":"","tags":null,"title":"[백준]_15552_빠른A+B(입출력 문제)","uri":"/posts/algorithm/other/%EB%B0%B1%EC%A4%80_15552_%EB%B9%A0%EB%A5%B8a+b/"},{"categories":["Programming","Java"],"content":"OOP ` 우리는 객체 지향적 삶을 살고 있고 그러한 현실을 프로그래밍에 반영하려고 함.\n장점\n 객체 교체(유지 보수)에 좋음 재사용성  OOP의 특징 OOP is A P.I.E\n  Abstraction : 특징 추출\n→ 현실의 객체(프로그램의 대상으로 삼는 것)를 추상화해서 class를 만들고 이를 구체화해서 object를 만든다.\n  Encpsulation : 필요한 기능 공개\n→ 데이터의 은닉과 보호\n  inheritance : 상속\n→ member variables, method를 자식이 물려받음 → 재사용\n  Polymorphism : 다형성\n→ 하나의 객체를 여러 타입으로 참조하는 것\n  Class class : 현실 세계를 추상화 해놓은 것 ex) 설계도, 청사진 등\n→ object를 만들기 위해 필요하지만 직접 class를 사용하진 않음.\n객체(object,instance) : 클래스를 구체화해서 메모리에 생성된 것\nclass = type\nfactor\n attribute : member variables → 각각 객체마다 다를 수 있음 behavior : methods → 동작, 객체들마다 같음 Constructor(생성자) → member variable 초기화  new\nConstructor를 보고 memory allocation 수행\n 생성자는 기본부터 여러 parameter를 가지는 등 다양하게 생성 가능  member variables\n 다양한 상태 표현 설정하지 않으면 default value 부여 OOP적 관점에서 외부에서 값을 바꾸는 것은 좋지 않음   Encapsulation   member variables과 method를 필요한 경우를 제외하고 노출하지 않도록 가정\n  노출할 경우 set\u0026get 으로 소통\n  여전히 외부에서 접근가능하므로 private 설정\n  new는 heap 영역에 객체를 생성한다는 의미!\n  1 2 3 4 5 6 7 8 9 10 11 12 13  int i1 = 10; int i2 = 10; String s1 = \"Hello\"; String s2 = \"Hello\"; // s1과 s2는 같은 곳을 가리킴 String s3 = new String(\"Hello\"); String s4 = new String(\"Hello\"); //new를 통해 생성하면 따로 생성됨  // == 는 메모리값 비교함 if( i1 == i2 ) { System.out.println(\"i1 i2 Same\"); } if( s1 == s2 ) { System.out.println(\"s1 s2 Same\"); } if( s3 == s4 ) { System.out.println(\"s3 s4 Same\"); } //equals 쓰면 나옴    String class StringBuilder\n+를 사용하면 불필요한 객체가 많아져 사용\nloop 등에서는 stringBuilder가 효과적\nappend를 이용\n1 2  StringBuilder sb = new StringBuilder(\"\"); sb.append(s1).append(\", \").append(s2);   toString 사용\n toString이 자동으로 생성되고 재정의해서 사용  1 2 3  public String toString() { return this.name + \" \" + this.color + \" \" + this.price; }   1 2  // main System.out.println(phone); // Galaxy Note B 10000   값 전달\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  public class PassByValueTest { public static void main(String[] args) { int i = 10; setVal(i); // 값 전달,최종적으로 안 바뀜. \tSystem.out.println(i); Pass p = new Pass(); p.val = 10; setVal(p); // reference 전달, 주소값을 찾아 값이 5로 바뀜. \tSystem.out.println(p.val); } public static void setVal(int x) { x = 5; } public static void setVal(Pass p) { p.val = 5; } } class Pass{ public int val = 3; }   Package  같은 패키지일 경우 package 선언하면 사용가능 다른 패키지일 경우 import로 불러와야 함. (com.web.*)  Access Modifier    구분 Same Class Same Package Sub Class Universe     private O X X X   default O O X X   protected O O O X   public O O O O    ","description":"","tags":null,"title":"OOP1","uri":"/posts/programming/java/oop1/"},{"categories":["Programming","Java"],"content":"배열 for each Array 1 2 3 4 5  int arr [] = {1,2,3,4,5}; for(int x : arr){ System.out.println(x); }   Array is immutable  크기 변경 불가 변경이 필요할 경우 새로 작성  arraycopy\n1 2 3 4  String [] students = { \"홍길동\", \"박사\", \"윤식당\", \"나오기\" }; String [] students3 = new String[5]; System.arraycopy(students, 0, students3, 0, 4); //[홍길동, 박사, 윤식당, 나오기, null] // index와 length를 정해 copy   1 2 3 4  int[] srcArray = {0, 1, 2, 3, 4, 5, 6, 7, 8, 9}; int[] tgtArray = {0, 0, 0, 0, 0, 0, 0, 0, 0, 0}; System.arraycopy(srcArray, 2, tgtArray, 1, 3); // [0, 2, 3, 4, 0, 0, 0, 0, 0, 0]   1 2 3 4 5 6 7 8 9  int[] intArray = { 3, 27, 13, 8, 235, 7, 22, 9, 435, 31, 54 }; int min = Integer.MAX_VALUE; int max = Integer.MIN_VALUE; for (int i = 0; i \u003c intArray.length; i++) { min = Math.min(min, intArray[i]); max = Math.max(max, intArray[i]); }   valuecount\n1 2 3 4 5 6 7 8  int[] intArray = { 3, 7, 2, 5, 7, 7, 9, 2, 8, 1, 1, 5, 3 }; int[] used = new int[10]; for (int i = 0; i \u003c intArray.length; i++) { used[intArray[i]]++; }   2차원 배열 array 만들기\n int [][]Array = new int[4][3]; int [][] intArray5 = new int[][] {{1,2,3},{1,2,3},{1,2,3},{1,2,3}};  1 2 3  int intArray[][] = new int [4][]; intArray[0] = new int[2]; intArray[2] = {1,2,3}; // 안됨    InputStreamReader와 BufferedReader를 이용해 입력처리를 빠르게 할 수 있음.   Array memory 1 2 3 4 5 6 7 8 9 10  static void makeAndPrint() { // 로컬 영역 \tint [] arr1 = new int[3]; int [] arr2 = {1,2,3} // array constant  // arr2 = {4,5,6} 불가능 \tarr2 = new int[] {4,5,6}; // 기존의 공간이 사라지고 새로운 공간이 할당됨. // 기존의 공간은 누구도 참조하지 않고 GC가 자동으로 회수 }   ` stack → local　heap → 객체\n int [] arr1 : arr1 (참조형) 생성 new int[3] : 3개의 int를 저장할 공간 생성(heap에 만들기!)  new로 생성할 경우 얼마나 공간을 차지할지 알려줘야 함.   32bit*3의 공간의 주소가 stack에 저장된다.  자바는 GC가 자동으로 사용하지 않는 메모리를 회수함\nn차원 배열  2차원  1차원 배열을 관리하는 1차원 배열이라 할 수 있음\n  int [][] arr3 = new int[3][]\n arr3의 3개의 공간에 각각 int[]가 들어가야 함.(기본값 null)  1 2 3  arr3[0] = new int[]{1,2,3,4,5}; arr3[1] = new int[]{6,7}; arr3[2] = new int[]{8,9};   Reference 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  static void reference() { char [] chars = \"Hello\".toCharArray(); change1(chars[0]); // 값이 복사되어 change로 넘어감. \tSystem.out.println(Arrays.toString(chars)); // 실제 H는 바뀌지 않았음 \tchange2(chars); // chars의 주소값을 넘겼기 때문에 바뀌게 된다. } static void change1(char data) { System.out.println(data+32); // 104 \tdata+=32; // 단항 연산자에서는 형변환이 일어나지 않음. \tSystem.out.println(data); // h } static void change2(char[] c2) { c2[0]+=32; }   엄밀히 말하면 위에서 chars는 배열이기 보다는 배열을 가리키는 주소값이라 할 수 있음\nswap\n1 2 3 4 5 6 7 8 9 10  static void swapTest() { int[] arr = {1,2,3}; swap(arr,1,2); // arr의 주소가 넘겨짐 } static void swap(int[] arr ,int a, int b) { int t = arr[a]; arr[a] = arr[b]; arr[b] = t; // 실제로 값이 바뀜. }   Arrays class  배열을 사용할 때 유용한 기능 제공  배열의 제약사항\n 타입, 크기  1 2 3 4 5 6 7 8 9 10 11 12  char [] chars = \"Hello Ssafy 5th class 12!!\".toCharArray(); char [] largeOne = Arrays.copyOf(chars, 40); // 한꺼번에 복사  char [] copy2 = Arrays.copyOfRange(chars, 0, 5); // 일부분 복사  Arrays.fill(largeOne, '#'); // 특정 값으로 채우기, 초기화에 유용 \tArrays.sort(chars); // 정렬    Array Delta Traversal 여태까지는 indexing을 이용한 방법\n방향을 나타내는 delta 행렬 선언\n1 2 3 4  static int[][] deltas = { { -1, 0 }, { 0, 1 }, { 1, 0 }, { 0, -1 } }; // 상하좌우를 나타내는 Delta 배열 static int[][] deltaPlus = { { -1, -1 }, { -1, 1 }, { 1, 1 }, { 1, -1 } }; // 대각선   1 2 3 4 5 6 7 8 9 10 11 12  for(int r=0;r\u003c3;r++) { for(int c=0;c\u003c3;c++) { int sum = 0; for(int d=0;d\u003c4;d++) { int nr = r + deltaPlus[d][0]; int nc = c + deltaPlus[d][1]; if(isIn(nr,nc)) sum +=map[nr][nc]; } result[r][c] = sum; } }   ","description":"","tags":null,"title":"Java_Programming2","uri":"/posts/programming/java/java_programming2/"},{"categories":["Algorithm","Dynamic_Programming"],"content":"`위 문제 유형은 Dynamic Programming이다. 규칙을 찾아서 적용하면 되겠다.\n과정   선언\n 2*n 의 최대값이 246912이므로 246913의 소수 여부 배열(boolean) 위와 같은 크기의 int배열 선언하여 1부터 소수가 몇 개 있는지 저장    값 할당\n 에라토스테네스 체 원리 이용하여 소수 여부를 true로 바꿈 2부터 반복문을 이용해 false가 나올 때마다 count를 올려주는 식으로 코드를 구성    최종 풀이\n 수를 입력받아 2*n까지의 소수 개수에서 n개까지 소수 개수를 빼고 정답 출력     이 문제는 python으로 풀었음.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  import sys input = sys.stdin.readline N = int(input()) dp = [0 for _ in range(N+3)] arr = [0 for _ in range(N+3)] for k in range(1,N+1): arr[k] = int(input()) dp [1] = arr[1] dp [2] = arr[1] + arr[2] dp [3] = max(arr[1] + arr[3] ,arr[2] + arr[3]) for i in range(4, N+1): dp[i] = max( dp[i-3] + arr[i-1] + arr[i] , dp[i-2] + arr[i] ) print(dp[N])   ","description":"","tags":null,"title":"[백준]_2579_계단오르기","uri":"/posts/algorithm/dynamic_programming/%EB%B0%B1%EC%A4%80_2579_%EA%B3%84%EB%8B%A8%EC%98%A4%EB%A5%B4%EA%B8%B0/"},{"categories":["Algorithm","Math"],"content":"위의 문제를 풀기 위해 에라토스테네스의 체의 원리를 이용했다. 에라토스테네스의 체는 소수를 구하기 위한 알고리즘 중 가장 성능이 좋은 방법으로, 소수의 배수를 거름으로써 건너뛰는 작업이 많아진다.\n과정   선언\n 2*n 의 최대값이 246912이므로 246913의 소수 여부 배열(boolean) 위와 같은 크기의 int배열 선언하여 1부터 소수가 몇 개 있는지 저장    값 할당\n 에라토스테네스 체 원리 이용하여 소수 여부를 true로 바꿈 2부터 반복문을 이용해 false가 나올 때마다 count를 올려주는 식으로 코드를 구성    최종 풀이\n 수를 입력받아 2*n까지의 소수 개수에서 n개까지 소수 개수를 빼고 정답 출력     전체 코드는 다음과 같다.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31  import java.util.Scanner; public class Test { public static void main(String[] args) { Scanner sc = new Scanner(System.in); boolean[] check = new boolean[246913]; int[] arr = new int[246913]; check[0] = check[1] = true; for(int i=2; i\u003c=Math.sqrt(246913);i++) { if(check[i]==true) continue; for(int j=i*i; j\u003c=246913; j=j+i) check[j]=true; } int count =0; for(int i=2;i\u003c246913;i++) { if(!check[i]) count++; arr[i] = count; } int n = 1; while(true) { n = sc.nextInt(); if (n==0) break; System.out.println(arr[2*n] - arr[n]);\t} } }   ","description":"","tags":null,"title":"[백준]_4948_베르트랑공준","uri":"/posts/algorithm/math/%EB%B0%B1%EC%A4%80_4948_%EB%B2%A0%EB%A5%B4%ED%8A%B8%EB%9E%91%EA%B3%B5%EC%A4%80/"},{"categories":["Programming","Java"],"content":"Java Basic 환경\n jdk : 소프트웨어 개발 jre : 실행 환경  다음 파일(HelloWorld.java)를 커멘드 상 실행하기 1 2 3 4 5 6 7  package com.ss.java_basic1 public class HelloWorld { public static void main(String[] args){ System.out.println(\"Hello World\"); } }    javac -d . HelloWorld.java 로 class 생성 java 클래스 이름으로 실행  Type\n primitive : 정해진 크기의 memory size reference : 정해질 수 없음, 공간의 주소를 저장  Type casting\n 묵시적 : 큰 type → 작은 type  정수형은 실수형으로 자동형변환   명시적 : 작은 type → 큰 type  /** 코드 */ : Javadoc 사용\nbit operator\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32  public class Test { public static void main(String[] args) { // bit and \tSystem.out.println(\"3 \u0026 4 = \" + (3 \u0026 4)); // 0011 \t// \u0026 0100 \t// ------ \t// 0000 \t// bit or \tSystem.out.println(\"3 | 4 = \" + (3 | 4)); // 0011 \t// | 0100 \t// ------ \t// 0111 \t// bit exclusive(xor) \tSystem.out.println(\"3 ^ 4 = \" + (3 ^ 4)); // 0011 \t// ^ 0100 \t// ------ \t// 0111 \t// bit not \tSystem.out.println(\" ~ 4 = \" + (~ 4)); // 0100 \t// ~ \t// ------ \t// 1011 \t} }   Bit 연산  *,/ 연산자에 비해 처리 속도가 훨씬 빠름.  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  public static void main(String[] args) { // \u003c\u003c \tSystem.out.println(\"1 \u003c\u003c 2 = \" + (1 \u003c\u003c 2)); // .... 0000 0001 \t// \u003c\u003c .... 0000 0100 1 \u003c\u003c 2 = 4 \tSystem.out.println(\"-16 \u003e\u003e 2 = \" + (-16 \u003e\u003e 2)); //\t.... 1111 0000 \t// \u003e\u003e .... 1111 1100 -16 \u003e\u003e 2 = -4 \t// \u003e\u003e\u003e \tSystem.out.println(\"7 \u003e\u003e\u003e 2 = \" + (7 \u003e\u003e\u003e 2)); //\t0000 .... 0000 0111 \t// \u003e\u003e\u003e 0000 .... 0000 0001 7 \u003e\u003e\u003e 2 = 1 \tSystem.out.println(\"-5 \u003e\u003e\u003e 24 = \" + (-5 \u003e\u003e\u003e 24)); //\t1111 1111 1111 1111 1111 1111 1111 1001 \t// \u003e\u003e\u003e 0000 0000 0000 0000 0000 0000 1111 1111  // -5 \u003e\u003e\u003e 24 = -1 \t}   조건문\n switch에서는 double 사용x ( String은 Java 버전 바뀜에 따라 됨) break 없으면 계속 내려가면서 검사 ‘A’와 65 둘 다 case에 있으면 겹치기 때문에 오류남.  삼항 연산\n1 2 3 4 5 6 7 8 9 10  public static void main(String[] args) { int N = 6; boolean isEven = ( N % 2 == 0 ) ? true : false; N = ( ! isEven ) ? 10 : 20; System.out.println(N); // 20 \t}   데이터 타입 문제 정수의 문제점 : 범위 문제(Overflow)\n1 2 3 4 5 6 7 8 9 10  int i = Integer.MAX_VALUE; // 가장 큰 수 알아보기 int i2 = i + 1; System.out.println(i); // 2147483647 System.out.println(i2); // -2147483648 , Integer.MIN_VALUE 가 되버림.  long l1 = i+1; long l2 = (long)(i+1); // 이미 깨진걸 사용해서 -2147483648가 나옴 \tlong l3 = (long)i + 1; // 2147483648, 형 변환 후 연산   ` 그렇지만 long도 무한대는 아니라 한계 존재…\n→ 별도의 class(BigInteger 등)로 표현!  실수의 문제점 : 부동소수점\n  컴퓨터는 정확한 실수를 표현하지 못함(근사값 사용)\n→ 실수의 계산은 믿을만한 게 아님(오차 허용)\n→ 정수로 올려서 계산하면 된다.\n  BigDecimal등을 이용할 수 있으나 무거움.\n값의 동등 비교  기본형 : == 객체형 : equals method  ","description":"","tags":null,"title":"Java_Programming1","uri":"/posts/programming/java/java_programming1/"},{"categories":null,"content":"`관심 분야 : 데이터 분석, 빅데이터, AI\nEducation  인하대학교 컴퓨터공학과 전공 (2015.03 ~ 2021.02) 통계학과 복수전공 (2016.03 ~ 2021.02)  Career  2019 Samsung SDS Brightics Contest 참가(2019.07 ~ 2020.08) L point Competetion(2019.12 ~ 2020.01) Dacon 참여 (반도체 박막 두께 분석(16등), 온도 추정 대회, 컴퓨터 비전 대회 등 다수) 빅데이터 청년 인재 고려대학교 과정(지능 정보 시스템) 수료 (2020.07 ~ 2020.09) AI Innovation 고급 과정 시각반(2020.09 ~ 2020.10) 삼성 청년 SW 아카데미(SSAFY) 5기(2021.01~)  Study  기계학습 스터디(2019.03~2019.06)  공유 자료로 공부 후 미세먼지량 예측   머신러닝, 딥러닝 스터디(2019.08~2020.03)  밑바닥부터 시작하는 딥러닝, 모두를 위한 딥러닝(tensorflow), Hands on Machine Learning   online kaggle study(2020.03~2020.05) ADP 실기 study (2020.09~) Algorithm(2020.01~)  Course 들었던 인터넷 강의 모음\n edwith  python, R , 선형대수학 Statistics 110 Machine Learning   Fast Campus 데이터 분석 K-mooc 텍스트 마이닝 Coursera  TensorFlow for Artificial Intelligence Data Science: Statistics and Machine Learning 특화 과정   T-academy  Git, Github page audio 데이터 처리    certificate  정보처리산업기사(2018.11) ADsP(2019.12) ADP(필기만, 2020.07)  Stack(언어/기술)  Python R C, C++ JAVA SQL HTML/CSS/JS Flask Git Data analysis Machine Learning Deep learning Computer Vision  Site Github  https://github.com/GyuYoungCho https://gyuyoungcho.github.io  Kaggle  https://www.kaggle.com/rbud613  Assignment  Bayesian 분류기 구현 Mnist 손글씨 인식 Cartpole 딥러닝 강화 학습  Project  잠재 고객 상품 추천 오디오 분류 식생활을 위한 음식 추천 CCTV를 이용한 날씨 분류  ","description":"","tags":null,"title":"About","uri":"/about/"},{"categories":null,"content":"HI! 이사했어 ","description":"","tags":null,"title":"Test","uri":"/posts/test/"},{"categories":["Certificate"],"content":"데이터 분석 R기초와 데이터 마트 R언어와 문법 데이터 구조  벡터 : 하나의 스칼라값, 하나 이상의 스칼라 원소(동일한 자료형) 행렬 -\u003e matrix 데이터 프레임 -\u003e data.frame(incom=a1,car=b1) 배열 -\u003e array(1:12, dim=c(3,4)) 리스트 : list(name=“a”,height=123)  기초 함수  solve : 역행렬 cov, cor : 공분산, 상관계수 substr(char,num1,num2) : num1번째에서 num2번째 계산 format(sys.Date(),'%a') : 현재 요일 출력   pairs : 산점도 행렬 melt(data,id) : id기준으로 variable, value 저장 cast(data,day~month~variable) : day, month기준으로 변수 배열 acast(data,month~variable,mean) : month 당 평균 subset 등으로 특정 변수만 선택가능 sqldf(“쿼리문”)  결측치 처리와 이상값 검색 결측값 대치법  평균 대치법 : 적절한 평균값으로 결측값 대치 단순확률 대치법 : 평균대치법에서 표준오차의 과소추정 문제를 보완, 적절한 확률값 부여 후 대치 다중 대치법 : 통계량 효율성 및 일치성 문제 보완, 과소 추정 문제는 여전   complete.cases() : 행의 모든 값이 na아닌 경우 True  이상값 : boxplot 보기\n통계분석 통계학개론 확률적 추출\n 단순 무작위 추출 : 임의로 개수 뽑기 계통추출 : 일정 간격으로 표본 추출 층화추출 : 집단, 층으로 나누고 집단 내 원하는 크기의 표본 무작위 추출 군집추출 : 집단을 나눠 집단 선택해 표본 추출  비확률적 추출\n 판단추출 : 연구자의 판단으로 추출 할당추출 : 여러 집단으로 나눠 각 집단에서 연구자의 판단으로 추출 편의추출 : 쉽게 접근할 수 있는 표본 추출  자료 : 명목 서열 등간 비율\n좋은 추정량 조건 불편성, 효율성, 충족성, 일관성\n검정 방법  모수적 검정   가정된 분포의 모수에 대해 가설 설정 표본평균, 분산 등을 구해 검정을 실시  비모수적 검정   분포에 제약을 가정x, 특정 분포를 따른다고 가정할 수 없는 경우 가설은 단지 분포의 형태가 동일하다 아니다로 분포의 형태에 대해 설정 순위나 부호 등을 이용해 검정 부호검정,윌콕슨, 부호순위합, 스피어만 순위상관, 만 위트니  회귀분석 가정\n 선형성 독립성 등분산성 비상관성 정상성(잔차항이 정규분포)   Residuals vs Fitted는 y축의 잔차를 보여줌, 기울기가 0인 직선이 이상적 noraml Q-Q는 잔차가 정규분포를 따르는지 확인, 직선 상에 있어야함 Scale Location은 y축의 표준화 잔차를 나타냄, 기울기가 0인 직선이 이상적 Residuals vs Leverage에서 cook’s distance가 1이 넘어가면 영향점이라 판단  다중공선성  변수들이 상관되어 있을 때 발생, vif가 4가 넘으면 다중공선성이 존재한다고 봄  최적으 회귀방정식 선택  aic, bic로 적합성을 봄 단계적 변수선택법  1  step(lm(y~1,df),scope=list(lower=~1,upper=~x1+x2),direction=\"forward\")   릿지회귀 : l2 norm 최소화 라쏘회귀 : l1 norm 최소화 엘라스틱넷 : 위의 두 개 절충\n다변량 분석  상관분석 서열척도 - 스피어만 상관분석 등간, 비율척도 - 피어슨 상관, 편상관분석  cor.test() : 상관계수 검정\n다차원 척도법(MDS)   유사성을 측정해 2, 3차원 공간에 표현  주성분 분석  차원 축소 기법 biplot : 2개의 주성분만 2차원의 그래프로 표현  시계열 분석  정상성   분산과 수준에 체계적 변화가 없고 주기적 변동이 없음, 미래는 확률적으로 과거와 동일  비정상성시계열을 정상성으로 만들기   평균이 일정하지 않은 경우 차분을 하면 됨 계절성을 가질 경우 계절차분 사용 분산이 일정하지 않은 경우 로그변환 등 진행  백색잡음 과정 : 평균이 0, 분산이 일정, 자기공분산 0 자기상관 : t, t-1간 상관 관계\n시게열 모형  자기회귀모형(AR) : 현시점의 자료에 몇 번째 전 자료까지 영향을 주는가   AR(1) 모형은 백색잡음값과 1스텝 과거의 자기 자신의 값만의 가중합임 자기상관함수 : 점차적 감소 부분자기상관함수 : 급격히 감소해 절단  이동평균모형(MA)   데이터의 평균을 예측치로 사용, 동일한 가중치 항성 정상성 만족 자기상관함수 : 급격히 감소해 절단  자기회귀누적이동 모형(ARIMA)   차분과 변환을 통해 정상화 ARIMA(p,d,q)에서  d=0 -\u003e ARMA(p,q) p는 AR, q는 MA와 관련   두 개의 상관함수가 지수적 감소  분해 시계열   추세요인 : 특정한 형태 계절요인 : 고정된 주기에 따라 변화 순환요인 : 알려지지 않은 주기를 가지고 자료가 변화 불규칙요인 : 설명할 수 없는 요인(오차)  1 2 3 4 5 6 7 8 9  diff(data,differences=1) # 한번 차분 decompose(data) # 시계열을 4가지 요인으로 분해 acf(data,lag.max=20) pacf(data,lag.max=20) # 자기상관함수와 부분자기상관함수 auto.arima(data) # 적절한 ARIMA모형 결정   정형 데이터 마이닝 분류분석 로지스틱 회귀  오즈비 : 성공율/실패율     구분 선형 회귀분석 로지스틱 회귀분석     종속변수 연속형 이산형   모형 탐색 방법 최소자승법 최대우도법, 가중최소자승법   모형 검정 F-test, t-test 카이제곱 test    로짓변환 : log(p/(1-p))\n최대우도 추정법\n1  glm(pmale~x,family='binomial',weight=total)   estimate값의 exp값이 오즈의 배수가 됨\n신경망 모형 활성함수 : 시그모이드, 부호, 소프트맥스\n의사결정나무 부모마디 : 상위마디 자식마디 : 하위마디 뿌리마디 : 맨 위의 마디 최종마디 : 더 이상 분할되지 않음\n분류나무  지니지수 : 1-p^2의 합으로 계산 엔트로피 지수 : -plogp의 합으로 계산  회귀나무  F통계량의 p값, 분산감소량이 분류 기준값의 선택 방법이 됨  기준변수의 선택법\n   구분 이산형 연속형     CHAID 카이제곱통계량 ANOVA 통계량   CART 지니 지수 분산 감소량   C4.5 엔트로피 지수 X     장점  해석이 용이. 수학적 가정이 불필요한 비모수적 모형 계산 비용 낮음, 상호작용 및 비선형성 고려가능   단점  경계선 부근에서 오차가 큼 각 예측변수의 효과를 파악하기 어려움    양상블 모형   배깅 : 임의 복원추출해 각 표본에 대해 분류기를 생성 후 결과를 앙상블\n  부스팅 : 동일한 확률이 아닌 분류가 잘못된 데이터에 가중치를 주어 표본 추출\n  랜덤 포레스트 : 배깅 + 랜덤\n  SVM  데이터 간 간격이 최대가 되는 선을 찾아 기준으로 데이터 분류 장점  에러율 낮고 결과 해석 용이   단점  파라미터 선택에 민감, 이진 분류만 가능   COST로 비용의 합 최소화하는 선 찾음  나이브 베이즈  사후확률은 사전확률을 통해 예측할 수 있다. 장점  TRAINING 데이터가 적어도 사용가능 multi-class를 쉽고 빠르게 예측   단점  한 쪽에 없는 경우 정상적 예측 불가 확률적으로 독립이라는 가정이 위반되면 오류 발생    모형평가 홀드아웃  train과 test 나눠서 실행  교차 검증  K개로 나눠 K-1를 훈현, 1개를 테스트로 하여 K번 반복  붓스트랩   오분류표 : 분류에서 사용\n  ROC그래프\n   X축에는 FP Ratio(1-특이도), y축에는 민감도를 나타냄 면적이 넓을 수록 좋은 모형  이익도표와 향상도   이익 : 개체들이 각 등급에 얼마나 분포하는가, 이익값을 누적으로 연결하면 이익도표 향상도 곡선 : 모델의 성과가 얼마나 향상되었나  군집분석  계층적 군짐   단일 연결법 : 짧은 거리로 고립된 군집을 찾음 완전 연결법 : 거리의 최댓값, 내부 응집성 중심 평균연결법 : 거리 평균으로 군집화, 계산량이 많음 중심연결법 : 중심간 거리, 가중 평균 와드연결법 : 오차제곱합 기초  거리 측정 유클리드 : 거리 제곱합의 제곱근 맨하튼 : 절대값의 합 민코프스키 거리 : q=2면 유클리드, q=1이면 맨하튼\n마할라노비스 : 표준화와 상관성을 고려한 통계적 거리\n비계층적 군집 k-mean  k개 임의 선택 군집의 중심점으로부터 오차제곱합이 최소가 되로록 각 자료 할당 군집 내 평균을 계산해 군집 중심 갱신 군집 중심 변화가 없을 때까지 2,3 반복     장점  단순, 많은 양 처리 사전적 정보 없이 의미있는 자료 분석 가능   단점  k값을 정해야 함 잡음이나 이상값에 영향받기 쉬움(평균 대신 중앙값을 사용하는 k-medoids 사용)    혼합분포 군집    EM 알고리즘 : 혼합분포에서 잠재변수를 추정할 때 사용\n K개의 클러스터 초기화 포인터가 클러스터에 포함될 확률 계산 MSL이 최대화 되기 위한 파라미터 계산    kmean은 중심거리 EM은 MSL로 거리를 측정\n  SOM(자기조직화지도)    인공신경망의 종류, 차원축소와 군집화를 동시에 시행\n  SOM 프로세스\n 연결 강도 초기화 입력 벡터와 경쟁층 노드 간의 유클리드 거리 계산 선택 노드와 이웃 노드 가중치 수정 2로 가서 반복, 입력 패턴과 가장 유사한 경쟁층 뉴런이 승자가 됨    승자 독식 구조로 경쟁층에는 승자 뉴런만이 나타남\n  신경망은 에러 수정, SOM은 경쟁 학습\n  SOM은 비지도 학습\n  연관분석 지지도 : 교집합 신뢰도 : 조건부 확률 향상도 : 교집합/a확률, b확률\n 향상도가 1보다 크면 양의 관계, 1이면 연관성 없음  절차\n 최소 지지도 설정 최소 지지도를 넘는 두 가지 품목 찾음 최소 지지도를 넘는 세 가지 품목 찾음 반복 수행  Apriori 알고리즘\n  데이터 간의 연관관계\n  구매 패턴 등 분석\n  장점\n 결과 이해 쉬움, 비목적성 분석 기법 사용 편리, 계산 간편    단점\n 품목 수가 증가하면 계산량 증가 너무 세부화되면 의미없는 결과 도출 상대적 거래량이 적으면 제외되기 쉽다.    ","description":"","tags":null,"title":"ADSP 복습 2","uri":"/posts/certificate/2020-02-16-adsp_remind2/"},{"categories":["Certificate"],"content":"데이터의 이해 데이터와 정보 데이터 유형   정성적 : 언어, 문자\n  정량적 : 수치, 도형, 기호\n  암묵지 : 학습과 체험을 통해 개인에게 습득되지만 겉으로 드러나지 않는 상태의 지식\n  형식지 : 암묵지가 문서 등으로 표출되어 공유할 수 있는 지식\n  공통화 -\u003e 표출화 -\u003e 연결화 -\u003e 내면화 공통화 : 경험 공유를 통한 새로운 암묵지 창조 표출화 : 암묵지에서 구체적 개념 도출 연결화 : 형식지의 완성도를 높여 지식체계로 전환 내면화 : 형식지를 학습해 구체화된 개인 지식\n 위와 같은 과정을 거치며 지식의 발전을 기반으로 한 경영을 지식경영이라 함  데이터와 정보 관계 데이터 : 가공하기 전 순수한 수치나 기호 정보 : 상관관계 간 이해를 통해 패턴 인식, 의미부여(ex a마트 연필 가격이 더 싸다) 지식 : 정보 패턴을 이해하여 이를 토대로 예측한 결과물(ex 더 저렴한 a마트에서 연필을 삼) 지혜 : 근본 원리에 대한 깊은 이해를 바탕으로 도출되는 것(ex 다른 상품들도 쌀 것이라 판단)\n데이터베이스 정의와 특성 데이터베이스 특징  통합된 데이터(중복x), 저장된 데이터, 공용 데이터, 변화되는 데이터  데이터베이스 특성  기계가독성, 검색가능성, 원격조작성 정보 이용, 관리 정보기술 발전, 경제 산업적 측면  데이터 베이스 활용 기업 내부 데이터베이스 1980년대  OLTP : 온라인 거래처리, 트랜잭션을 컴퓨터에서 처리하여 결과를 사용자에게 돌려줌 OLAP : 온라인 분석처리, 통계적 요약 정보를 제공하는 기술  2000년대  CRM : 고객으로부터 수익창출, 장기적 고객관계 SCM : 제조 등 유통공급망에 참여하는 모든 업체들이 협력을 바탕으로 정보기술 활용, 재고 최적화  분야별 기업 내부 데이터베이스  제조부문  DW : 데이터 웨어하우스, 정보검색 목적 ERP : 제조업 등 비즈니스 분야 BI : 기업의 DW에 접근해 경영활동에 활용 CRM   금융부문  EAI : CRM, ERP, SCM등이 상호 연동 가능하게 함 EDW : 기존 DW확장 블록체인 : 데이터 분산처리 기술 ERP, e-CRM   유통부문  KMS : 지식관리시스템 RFID : 무선 주파수 이용 CRM, SCM    DW 4대 특성 데이터 주제지향성, 데이터 통합, 데이터 시계열성, 데이터 비휘발성\n사회 기반 구조 데이터베이스  EDI : 전자문서를 만들어 교환 CALS : 광속 상거래 물류 : VAN, 의료 : EDI, 교통 : ITS, 교육 : NEIS, 지리 : GPS,NGIS  BI, BA\n   구분 BI(Business Intelligence) BA(Business Analytics     목적 과거의 성과를 측정,비즈니스 계획 데이터와 통계 기반 성과 이해, 통찰력 중심 분석   응용 데이터 기반 의사결정 사전에 예측, 최적화, BI보다 진보    데이터 가치와 미래 빅데이터 정의 크기, 다양성, 속도 1tb = 1024gb 1pb = 1024tb 1eb = 1024pb 1zb = 1024eb\n빅데이터 기능  석탄,철 : 차세대 산업혁명, 혁명적 변화 원유 : 정보를 제공해 생산성 향상 렌즈 : 데이터가 산업 전반에 영향 플랫폼 : 공동 활용의 목적으로 구축된 유무형 구조물  본질적 변화 사전 -\u003e 사후 표본 -\u003e 전수 질 -\u003e 양 인과 -\u003e 상관\n빅데이터 활용 테크닉  연관규칙학습 유형분석(분류) 유전 알고리즘 : 최적화의 메커니즘을 찾음 기계학습 : 학습 후 예측 회귀분석 : 영향 감정 분석 소셜 네트워크 분석(sna)  위기 요인, 통제 방안  사생활 침해 : 동의제 -\u003e 책임제 책임 원칙 훼손 : 책임 원칙 강화 데이터 오용 : 데이터 알고리즘 접근권 허용, 인증 방안  빅데이터 활용 3요소 데이터, 기술, 인력\n데이터 사이언스와 전략 인사이트 일차적 분석 애플리케이션 사례  금융 : 신용점수, 사기탐지, 고객 수익성 분석 소매업 : 재고 보충, 수요예측 제조 : 맞춤형 상품, 신상품 개발 에너지 : 트레이딩 공급, 수요예측 온라인 : 웹 매트릭스, 고객 추천, 사이트 설계  데이터사이언스 구성 요소  IT Analytics 비즈니스 분석  데이터 사이언티스트 요구 역량  hard skill  이론적 지식 분석 기술 숙련   soft skill  통찰력 있는 분석 : 창의적 사고, 호기심, 비판 설득력 있는 분석: 스토리텔링, 시각화 협력 : 커뮤티케이션    데이터 사이언스 : 과학과 인문의 교차로\n사회경제적 환경 변화  단순 세계화 -\u003e 복잡한 세계화 제품 생산 -\u003e 서비스 생산 -\u003e 시장 창조  인간을 바라보는 세 가지 관점  타고난 성향의 관점 행동적 관점 상황적 관점  가치 패러다임의 변화  디지털화 연결(사물인터넷) 에이전시 : 복잡한 연결을 얼마나 효과적으로 관리해주는가   데이터 분석 기획 분석 기획 방향성 도출 데이터 사이언스 역량 컴퓨터 사이언스, 비즈니스 분석능력, 수학통계학 지식\n분석 주제 유형  Optimization : 분석 대상, 방법을 이해 Solution- 분석 대상만 암 Insight : 분석 방법만 암 Discovery : 분석 대상, 방법 모름  분석 기획 방안    당면한 주제(과제 단위) 주제 지속적 분석 문화 내재화(마스터 플랜 단위)     Speed\u0026Test 1차 목표 Accuracy\u0026Deploy   Quick-Win 과제의 유형 Long term View   Problem Sovling 접근 방식 Problem Definition    Quick-Win : 즉각적 실행을 통한 성과 도출\n분석 기획 시 고려사항  가용한 데이터 적절한 유스케이스 탐색 장애 요소에 대한 사전 계획 수립 필요  분석 방법론 KDD 분석방법론  대상의 도메인에 대한 이해와 프로젝트 목표 설정 데이터셋 선택 데이터 전처리 데이터 변환 데이터 마이닝 데이터 마이닝 결과 평가  CRISP-DM 분석 방법론  업무 이해 : 목적 파악, 목표 설정, 계획 수립 데이터 이해 : 수집, 기술 분석, 탐색, 품질 확인 데이터 준비 : 선택, 정제, 통합, 포맷팅 모델링 : 알고리즘 선택, 파라미터 최적화 평가 전개 : 유지보수 계획, 보고서 작성  선택, 전처리 단계 -\u003e 데이터 이해 단계\n빅데이터 분석 방법론  분석 기획 데이터 준비 데이터 분석 시스템 구현 평가 및 전개  프로토 타입 : 제품의 원형, 검증을 거쳐야 시제품이 됨\n분석 기획 단계  비즈니스 이해 및 범위 설정  진행 방향 설정 후 프로젝트 범위 정의서인 SOW 작성   프로젝트 정의 및 수립  프로젝트 정의 : KPI(핵심성과지표), 목표 수준 구체화 프로젝트 수행 계획 : WBS 작성(일정별 계획)   프로젝트 위험 계획 수립  위험 대응계획 수립 : 회피, 전이, 완화, 수용    데이터 준비  필요 데이터 정의  데이터 정의 : 메타데이터 정의서, ERD   데이터 스토어 설계  정형 : RDBMS 사용, 데이터 매핑 비정형 : NoSQL, 하둡 사용   데이터 수집 및 정합성 점검  ETL, API, 크롤링으로 수집 API : 제공하는 기능을 제어할 수 있게 만든 인터페이스 ETL : 데이터 추출,변환, 적재의 약자, BI구현을 위한 구성요소    데이터 분석  분석용 데이터 준비 텍스트 분석 EDA MODELING : 분할, 모델링, 적용 방안 평가 및 검증  시스템 구현 - 설계, 구현, 시스템 테스트 및 운영\r 평가 및 전개 - 발전 계획 수립 및 평가 보고\r 분석 과제 발굴 하향식 접근 방법, 상향식 접근 방법 최적화 -\u003e 솔루션 발견 -\u003e 통찰\n하향식 접근 방법  문제 탐색 단계    비즈니스 모델 기반 탐색\n 업무, 제품, 고객, 규제와 감사, 지원 인프라    분석 기회 발굴의 범위 확장\n 거시적 관심의 요인  사회, 기술, 경제, 환경, 정치   경쟁자 확대 관점  경쟁사 영역, 대체재 영역, 신규 진입자 영역   시장의 니즈 탐색  고객 영역, 채널 영역, 영향자들 영역   역량의 재해석 관점  내부 역량, 네트워크 역량      외부 참조 모델 기반 탐색\n Quick\u0026Easy방식    분석 유즈 케이스\n 상세한 설명 및 해당 문제를 해결했을 때 발생하는 효과를 명시    문제 정의 해결 방안 탐색 타당성 검토  상향식 접근 방식  비지도학습 과정  분석 프로젝트 관리 방안 분석 과제 5가지 특성 관리 영역  data size data complexity speed analystic complexity accuracy \u0026 precision  agile : 과거의 방식(워터폴 모델)과 달리 일정한 주기를 가지고 끊임없이 프로토타입을 만들어내 필요할 때마다 요구사항을 더하고 수정\n분석 마스터 플랜 마스터플랜 수립 프레임워크 우선 순위 고려 요소  전략적 중요도 비즈니스 성과/ROI 실행 용이성  적용 범위/방식 고려 요소  업무 내재화 적용 수준 분석 데이터 적용 수준 기술 적용 수준  ISP : 정보전략계획, 정보를 포착해 전사적 관점의 정보 구조를 도출해 전략 및 실행 계획을 수립하는 전사적 종합정보 추진 계획\nROI 관점  VALUE : 비즈니스 효과, 나머지 투자비용 요소  과제 우선순위  시급성 : 3-4-2 난이도 : 3-1-2  나선형 모델 : 여러번의 개발 과정을 거쳐 점진적으로 프로젝트를 완성시키는 모델\n분석 거버넌스 체계 수립 분석 거버넌스 체계 구성요소  Process(과제 기획, 운영), System(IT 프로그램), Data(데이터 거버넌스), Human resource(분석 교육), Organization(조직)  빅브라더 : 정보의 독점으로 사회를 통제하는 권력, 체계\n분석 성숙도 모델(CMMI)  도입 : 환경과 시스템 구축 활용 : 결과를 실제 업무에 적용 확산 : 분석을 관리하고 공유 최적화 : 혁신 및 성과 향상에 기여  샌드박스 : 외부 접근을 차단해 제한된 영역 내에서 프로그램을 동작시킴(IT 최적화 단계) COE : 조직 내 새로운 역량을 만들어 확산하기 위한 전문가들 조합(조직 확산 단계)\n 높은 성숙도, 높은 준비도 -\u003e 확산형  데이터 거버넌스 체계 요소  데이터 표준화 : 표준용어 설명, 명명 규칙, 메타데이터 구축 관리 체계 : 메타 데이터, 데이터 사전 관리 원칙 저장서 관리 : 전사 차원 저장소 구성 표준화 활동 : 구축 후 주기적으로 점검  데이터 조직 및 인력 방안 수립  집중구조 : 별도의 분석 전담 조직에서 담당, 이중화/이원화 가능성 높음 기능 구조 : 별도 조직이 없고 해당 업무 부서에서 진행, 전사적 핵심 분석이 어려움 분산 구조 : 분석 조직 인력들을 현업부서로 배치, 신속한 ACTION가능, 역할 분담 명확히 해야함  ","description":"","tags":null,"title":"ADSP 복습 1","uri":"/posts/certificate/2020-02-14-adsp_remind1/"},{"categories":["Certificate"],"content":"다축 생성 다축 생성 절차  첫 번째 그래프 생성(축을 지정하지 않은 그래프) 점 추가 y축 생성 y축 이름 지정 두번째 그래프 생성 점 추가 y축 생성 y축 이름 지정 세 번째 그래프 생성 y축 생성 점 추가 y축 이름 지정 x축 생성 및 이름 지정 사용자화  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  plot(time,pop,axes=F,xlim=c(7000,3400),ylim=c(0,max(pop)), xlab=\"\",ylab=\"\",type=\"l\",col=\"black\",main=\"\") points(time,pop,pch=20,col=\"black\") axis(2, ylim=c(0,max(pop)), col= \"black\", lwd=2) mtext(2, text=\"Population\", line=2) par(new=T) plot(time,med,axes=F,xlim=c(7000,3400),ylim=c(0,max(med)), xlab=\"\",ylab=\"\",type=\"l\",lty=2,lwd=2, col=\"black\",main=\"\") points(time,med,pch=20,col=\"black\") axis(2, ylim=c(0,max(med)), col= \"black\", lwd=2,line=3.5) mtext(2, text=\"Median Group Size\", line=5.5) par(new=T) plot(time,grp,axes=F,xlim=c(7000,3400),ylim=c(0,max(grp)), xlab=\"\",ylab=\"\",type=\"l\",lty=3,lwd=2, col=\"black\",main=\"\") points(time,grp,pch=20,col=\"black\") axis(2, ylim=c(0,max(grp)), col= \"black\", lwd=2,line=7) mtext(2, text=\"Number of Groups\", line=9)   그 외 다양한 그래프  aplpack 패키지 : 줄기잎 그림, 체르노프 페이스, 스타차트 등 제공   줄기 잎 그림  1  stem.leaf(score)   얼굴 그림  1  faces(worldplace)   별 그림  1  stars(worldplace)    공간 분석 구글 비즈 모션 차트\n 구글 비즈를 사용하기 위해서는 그래프 축과 관련된 시간과 id변수를 지정한 후 plot으로 그림  1 2  m1 = gvisMotionChart(Fruits, idvar=\"Fruit\",timevar=\"Years\") plot(k)   지오차트\n 지도와 그 위에 데이터를 표시  1  gvisMotionChart(data, locationvar=\"\", colorvar=\"\",sizevar=\"\",howervar=\"\",options= list(), charid)    색상 구분  1 2 3 4  G1 = gvisGeoChart(exports, locationvar='Country', colorvar='Profit') # 전 세계 지도에 수익크기를 색상으로 구별 G1 = gvisGeoChart(exports,'Country','Profit',option=list(region=\"150\")) # 유럽 지역으로 한정해 구분   표시 방식 및 해상도 지정  1 2  G1 = gvisGeoChart(states,\"statename\",\"illiteracy\",option=list(region=\"US\"),displayMode=\"regions\",resolution=\"provinces\", width=600,height=400) # 주별 문맹률 정보가 나타나도록 option표시 방식과 해상도 수준 지정   속도 표시  1 2 3 4  G1 = gvisGeoChart(Andrew, \"Latlong\", colorvar='Speed_kt',option=list(region=\"US)) # 위치별 속도를 각각의 색상으로 표시함 G1 = gvisGeoChart(Andrew, \"Latlong\",sizevar= \"Speed_kt', colorvar='Pressure_mb',option=list(region=\"US)) # 색깔이 아닌 원의 크기로 표현   깊이 표시  1 2  G1 = gvisGeoChart(quake, \"Latlong\",\"depth\",\"mag\", option=list(displayMode = \"Markers\", region=\"009\",colorAxis=\"{color:['red','grey']}\",backgroundColor=\"lightblue\")) # 깊이와 진도정보로 표시   모자이크 플롯\n 복수의 categorical variable 분포 파악이 도움이 되는 시각화  1 2  mosaic(titanic,shade=T,legend=T) # 색상 추가   1 2 3  strucplot(titanic,pop=F) grid.edit(\"rect:Class=1st,SEx=Male,Age=Adult,survived=Yes\",gp = gpar(fill = \"red\")) # 특정 집단의 색상 지정    샤이니 사용  R에서 인터렉티브하게 웹 앱을 만들 수 있는 패키지 동적 시각화 자료를 웹으로 쉽게 배포 가능 독립형 앱을 호스트하거나 R Markdown문서에 포함하거나 대시보드 작성 css, html, javascript 작업 가능  샤이니 기본 구성  구조   header, body, footer 구조를 지닌 html과 유사 headerPanel : 제목과 주제 sidebarPanel : mainPanel에서 다룰 수 있는 컴포넌트가 들어감 mainPanel : 실질적으로 보여지는 부분  ui.R, server R code   샤이니를 실행하기 위해 ui.R, server R code 파일이 동일 디렉토리 안에 있어야 함 ui.R : 화면 구성, component class 설정 server R code : 코드들이 들어가는 곳, id값을 설정해 ui.R에 input, output값으로 작동  hello_shiny(ui.R)\n1 2 3 4 5 6 7  shinyUI(pageWithSidebar( headerPanel(\"hello shiny\"), sidebarPanel( sliderInput(\"obs\",\"Number of observation: \", min=1, max = 1000, value=500)) mainPanel(plotOutput(\"distPloy\")) )) # obs를 컴포넌트로 나타내 값은 1부터 1000까지, 기본값은 500   hello_shiny(server.R)\n1 2 3 4 5 6 7  shinyServer(function(input,output){ output$distPlot = renderPlot({ dist = rnorm(input$obs) hist(dist) }) }) # input, output만듬, distplot이라는 함수를 output으로 보내 renderplot 출력   샤이니 기본 사용법 시작과 종료   일반적인 방법으로 c:/test/shiny로 디렉터리를 만들고 각각의 ui.R, server R파일을 폴더에 넣어 관리함(동일폴더에 있어야 함)  1 2  setwd(\"c:/test/shiny/hello\") runApp() # 샤이니 실행    샤이니는 r server에서 브라우저로 별도로 운영되기 때문에 브라우저 종료 후 반드시 세션을 끝내줘야 함  input, output\n input, output으로 id를 만들고 안에 설정된 데이터나 그래프 등을 주고받는다.  1 2 3 4 5 6 7 8 9 10 11  shinyUI(pageWithSidebar( headerPanel(\"hello shiny\"), sidebarPanel( selectInput( \"Variable\",\"Variable: \", list(\"Cylinders\" = \"cyl\", \"Transmission\"=\"am\", \"Geers\"=\"gear\")) checkboxInput(\"outliers\",\"Show outliers\", FALSE)) mainPanel(h3(textOutput(\"caption\")), plotOutput(\"mpgPlot\")) )) # 세션 종료 후 재실행하면 server.r 코드가 mainpanel에 나타남   Slider\n 슬라이드 바는 inputID 지정 후 label, min, max, value, step, format을 지정 후 눈금 표시 여부를 ticks를 T/F값으로 지정하고 움직임에 따라 animate를 T/F로 지정  Tabsets\n 한 화면에 tab을 만들어 탭별로 다른 그래프나 테이블을 보여줄 수 있음  dataTable\n 자바스크립트 사용, 코드를 두 개로 나누지 않고 한번에 코딩 가능, 하지만 관리 등을 위해 나눠서 하는게 좋음  라이브러리 기반 시각화 구현(d3.js) d3.js특징  자바스크립트 기반 데이터 시각화 라이브러리 SVG객체, ,canvas객체 등을 기반으로 동작 css를 통해 객체의 레이아웃과 속성을 변경해 디자인적 요소를 조작할 수 있음 firefox, chrome, safari opera 에서 모두 테스트되어 한 동일한 코드에 일관적인 결과를 얻을 수 있다.  시각화 구현 절차  데이터 획득   로컬에 저장된 파일, DB, 웹에 공개된 데이터  데이터 파싱   csv, xml, json등의 형식을 파싱할 수 있는 API 제공  데이터 필터링   필요하지 않은 데이터 제거  데이터 표현   중요한 사항은 매핑의 scale scale이라는 객체로 데이터와 시각적 요소 간의 관계 정의 한 번의 구현으로 다양한 화면의 크기에서 동작해야하는 시각화에서 매우 유용 다양한 크기의 화면에 동일한 차트나 지도를 그릴 수 있다. 또한 동적으로 변경되어도 차트나 지도가 깨지지 않음  상호작용 추가   마우스 클릭, 키보드 입력 등을 인지, 처리할 수 있도록 함 상세하게 보여주기, 지역 포커싱 등 가능  시각화 구현을 위한 기본 개념  객체지향 언어라 객체를 생성해야함 d3.js는 데이터를 svg이미지로 시각화하는데 사용되는 함수를 모아놓은 파일과 같은 것   SVG   그림을 그리기 위한 HTML태그 각각의 모양을 일일이 함수로 정의 후 표현 해상도와 독립적, 이벤트 핸들링을 지원해 사용자와 상호작용이 필요한 시각화 구현  scale   시각화 그림들이 화면에 출력되는 과정에서 부자연스럽게 표현되는 것을 방지 크기와 컬러를 자동으로 조정해 ‘시각화의 최적화’를 도움 데이터 값을 건드리지 않고 데이터 값에 맞는 크기와 컬러 범위를 출력 장치에 맞도록 시각화 domain : scale 입력값 범위 지정 range : scale 출력값 범위 지정 .scale : domain, range로 설정된 scale을 통해 원하는 위치에 무언가를 놓는 것  막대차트로 시각화 구현  객체 생성 데이터 입력 스케일 정의 차트에 막대 추가   rect 객체 사용  레이블 추가   text 객체 사용  축 추가  파이 차트  d3.svg.arc : 파이 모양 구현  스캐터 플롯 히트맵으로 비교 시각화 구현  색상의 차이를 통해 데이터 표현 canvas 객체 필요 drawimage : canvas에 준비한 이미지를 출력  svg와 canvas 차이\n    svg canvas     용도 시각화를 구현하기 위해 사용    객체에 정보 저장 O X   다시 그리기 유리 불리   성능 낮다 높다     svg 객체는 화면에 출력한 모든 정보를 담고 있기 때문에 event handler를 연결할 수 있다. 사용자의 행위에 따라 필요한 객체만 화면에 그릴 때 유리하지만 모든 정보를 객체로 저장하고 있어 성능 문제가 발생할 수 있음  지도로 시각화 구현  좌표 정보를 데이터로 입력하고 path객체를 할당하는 방법으로 구현할 수 있다. path 객체를 통해 좌표 정보를 픽셀로 변환해 화면에 도형을 그릴 수 있다.  ","description":"","tags":null,"title":"ADP 공부하기 14","uri":"/posts/certificate/2020-02-13-adp_study14/"},{"categories":["Certificate"],"content":"시각화 구현 개요 빅데이터 시각화 구현  시각화함으로써 데이터의 분포와 성격에 대해 한 눈에 알기 쉬워 인사이트를 얻기 좋다  대표적 시각화 방법  시각화 플랫폼   전문 시각화, 시각적 분석 플랫폼은 주로 BI, 인텔리전스 분야에서 사용  기업별 대표 제품\n IBM : 코그노스 인사이트, 인포메이션 빌더스 MS : 파워피벗, 파워뷰 마이크로스트레터지 : 비주얼 인사이트 오라클 : 오라클 비즈니스 인텔리전스 엔터프라이즈 에디션 클릭테크 : 클릭뷰 SAP : 비주얼 인텔리전스 SAS : SAS 인터프라이즈 비즈니스 인텔리전스 그외 : 타블로, 팁코 스폿파이어 애널리틱스  기존 BI 플랫폼 : 주로 데이터 분석, 마이닝 기법을 통해 일정한 방식의 결과리포트를 생성하기 위해 시각화 기술을 활용 전문 시각화 플랫폼 : 지식 시각화 관점에서 데이터 시각화 기능 지원 적용 방법 : 플랫폼 설치, 구축 필요\n Gephi : 수많은 edge와 노드로 이루어져 복잡한 네트워크 형태를 시각화  시각화 라이브러리   라이브러리를 설치해 제공하는 API로 코드 작성 도구 리스트  인포그래픽스   웹서비스 형태로 제공, 제공되는 템플릿으로 구현 ICHART, Visual.ly, Visualize FREE 등   \n분석 도구를 이용한 시각화 구현 그래프 작성  ggplot을 통해 다양한 시각화  xy그래프  기본 XY그래프   전체적 내용 파악, 수많은 데이터가 있을 때 파악하기 어려움 데이터를 넣고 x,y축 지정 후 color구분하는 코드  1  ggplot(chickweight, aes(x=Time,y=weight, colour = Diet, group=Chick))+geom_line()   - aes : xy축 지정, 색과 그룹별 지정 가능\r- geom_line : 선그래프를 그리는 함수\r 포인트 그래프  1 2  h = ggplot(chickweight, aes(x=Time,y=weight, colour = Diet)) h + geom_point(alpha=.3)   - 위에서 투명도를 0.3으로 조정\r 스무스 그래프  1 2  h = ggplot(chickweight, aes(x=Time,y=weight, colour = Diet)) h + geom_smooth(alpha=.4, size=3)   개선된 그래프(포인트+스무스)  1  ggplot(chickweight, aes(x=Time,y=weight, colour = Diet)) + geom_point(alpha=.3) + geom_smooth(alpha=.4, size=3)   히스토그램  도수분포표를 그래프로 나타냄  1 2  ggplot(subset(chickweight, Time=21), aes(x=weight,fill= Diet)) + geom_histogram(colour=:black,bidwidth=50) + facet_grid(Diet ~.)    Time변수가 21인 것만 선택, weight 간격 50 facet_grid(Diet ~.)는 가로로 출력, facet_grid(.~ Diet)는 세로로 출력  포인트 그래프   데이터를 정적으로 보여주고 색상으로 특성을 파악할 수 있다.\n  기본 포인트 그래프\n  1 2 3 4  p = qplot(wt,mpg,colour=hp, data=mtcars) p+coord_cartesian(ylim=c(0,40)) p+scale_colour_continuous(breaks=c(100,300)) p+guides(colour = \"colourbar\")   -\u003e y축 범위 지정, hp범위 지정, hp수치에 따른 칼라바\n 치환 데이터를 이용한 포인트 그래프  일정 데이터만 그릴 때, 데이터가 많으면 복잡성이 올라가고 파악이 불가능한 경우가 발생 10건 만 추출, p에 m을 설정    1 2  m = mtcars[1:10,] p% + %m   막대 그래프  기본 막대 그래프 범주형 데이터를 factor로 변환  1 2  c = ggplot(mtcars,aes(factor(cyl))) c+geom_bar()    다양한 옵션 적용  1  c+ geom_bar(fill=\"white\",colour=\"red\")     막대 내부는 white 테두리 색은 red\n  히스토그램 형식에 적용\n  1 2 3  m=ggplot(movies, aes(x=rating)) m+geom_histogram() m+geom_histogram(aes(fill=..count..))   선그래프  시계열에서 많이 쓰임  1 2  b = ggplot(economics,aes(x=date,y=unemploy)) b+geom_line()    다양한 옵션 적용  1 2  b = ggplot(economics,aes(x=date,y=unemploy)) b+geom_line(colour=\"blue\",size=0.3, linetype=0.3)   linetype : 선의 종류\n효과주기  기본 효과 주기   히스토그램 : 그래프화 할 때 히스토그램으로 커트 등급 별로 나타냄  1 2  k = ggplot(diamonds, aes(caret,..density..)) + geom_histogram(binwidth=0.2) k+facet_grid(.~cut)   facet_grid(.~cut) : caret종류를 그래프 위쪽에 표시\n 막대 그래프  1 2 3  w = ggplot(diamonds, aes(clarity, fill=cut)) w= geom_bar() w=geom_bar(aes(order=desc(cut)))    선 그래프  1 2 3  f = ggplot(df,aes,(x=x,y=y)) f + geom_line(linetype=2) f + geom_line(linetype=\"dotdash\")   \n포인트 그래프  임의의 선 삽입(수평선)  1  p+geom_point(size=2.5) + geom_hline(yintercept=25,size=3.5)    포인트 모양 할당  1  p+geom_point(shape = 5)    포인트 모양 (문자) -\u003e k라는 문자 지정  1  p+geom_point(shape = 'k', size=3)    포인트 모양 없애기  p+geom_point(shape = NA)\r 25가지 SHAPE사용  1 2 3  df2 = data.frame(x= 1:5, y=1:25, z=1:25) s = ggplot(df2,aes(x,y)) s + geom_point(aes(shape=z),size=4) + scale_shape_identity()    선형 모델링  1 2 3 4  dmod = lm(price~cut, data=diamonds) cuts = data.frame(cut=unique(diamonds$cut),predict(dmod,data.frame(cut=unique(diamonds$cut)),se=TRUE)[c(\"fit\",\"se.fit\")]) se = ggplot(cuts, aes(x=cut,y=fit,ymin=fit-se.fit,ymax=fit+se.fit,colour=cut)) se + geom_pointrange()    박스로 강조  1 2  p = ggplot(mtcars,aes(wt,mpg)) + geom_point() p + annotate(\"rect\",xmin=2,xmax=3.5, ymax=25,fill = \"dark grey\", alpha=.5)    축 범위 지정  1 2  p = qplot(disp, wt, data=mtcars) + geom_smooth() p+scale_x_continuous(limit=c(325,500))    boxplot  1  qplot(cut,price,data=diamonds, geom=\"boxplot\")   -\u003e 가로로 눕히려면 아래 코드 추가\n last_plot() + coord_flip()\n  qplot  1  qplot(cut, data=diamonds, geom=\"bar\")   ","description":"","tags":null,"title":"ADP 공부하기 13","uri":"/posts/certificate/2020-02-12-adp_study13/"},{"categories":["Certificate"],"content":"시각화 방법 시각화 방법 개념 정보 구조화  정보 조직화   데이터를 수집, 정제하는 과정이 적절히 배분되지 않는다면 제대로 된 결과물을 도출하기 어려움 데이터 수집, 분류, 배열, 관계맺기의 과정을 거침 조직화해 배치할 때 정보의 가치와 유용성은 증가하고 전하는 이야기도 달라진다. 데이터 munging : 원 데이터의 구문을 분석, 정리하고 집단으로 묶거나 변환해 패턴을 식별  데이터 수집 및 탐색   원 데이터를 바탕으로 필요한 데이터를 추출하고 활용하는 절차를 거쳐야 함 데이터 editing : 유의미, 무의미한 데이터 선별   분류\n 구분 텍스트   줄 바꿈으로 행을 구분자로 열을 구분하는 텍스트 데이터임 csv는 쉼표, tsv면 탭으로 구분자는 공백, 쉼표 등 어떤 것이든 가능  json   자바스크립트로 표현된 데이터를 쉽게 전달할 수 있는 스트링으로 변형 가능함 자바스크립트에 의해 쉽게 인터프린팅됨, 복잡한 구조로 표현됨 배열과 복합 개체들을 나타낼 수 있다.  xml   확장마크업 언어, 수많은 종류의 데이터 기술 xml은 구조적 데이터를 설명함 html의 한계를 극복할 목적 스프레이트시트, 구성파일 등 네트워크 프로토콜에 일반적으로 포함되는 정보가 구조 데이터의 예시임    배열\n    래치방법 : 위치,알파벳, 시간, 카테고리, 위계 이상 5가지가 정보를 정리, 조직화\n 위치 : 정보를 공간적 위치에 배열   다양한 출처나 장소에 기반을 둔 정보를 조사하고 비교할 때 좋음 지도 뿐만 아니라 안내도, 학문 영역의 범위를 포함하는 것도 해당  알파벳 : 사전, 전화번호부 등을 정렬   1차로 분류하고 하위 분류에서 가나다 순으로 조직화 데이터 속성이 다양하면 알파벳 순이 보편적  시간 : 연도별 시간 순서   일정 기간을 조직화하는 최적의 원리 정보의 변화를 발견하고 비교할 때 좋음  카테고리 : 정보의 속성에 따라 분류   중요도나 주제가 서로 유사한 정보에 적합, 수치보다 색상 등으로 표현을 달리함 상품 분류, 서적 분류 등  가중치(위계) : 정보의 변화에 따라 데이터 값이나 중요도 순서로 조직화   단위나 수치 표현 가능    관계 맺기(재배열)   데이터에 의미를 부여하는 기본적인 과정, 시각화와 밀접함 분류된 데이터를 정보 수용자가 인식하기 쉽게 패턴을 만듬  정보 시각화    시간 시각화 분포 시각화 관계 시각화 비교 시각화 공간 시각화     막대그래프, 점그래프 파이차트, 트리맵, 누적 연속그래프 스캐터 플롯, 버블차트, 히스토그램 히트맵, mds, 스타차트,체르노프페이스,평행 좌표계 지도 매핑     시간 시각화    변화를 표현, 트랜드(경향성)으로 장기간에 걸쳐 트랜드 추적\n  분절형 : 데이터의 특정 시점, 시간 구간\n  연속형 : 기온 변환 같은 데이터\n 막대그래프   막대를 배치함으로써 상대적인 차이를 알 수 있음 색상 표시 : 값들의 차이가 미미하거나 막대의 수가 많은 때, 막대가 서로 다른 범위나 상태일 경우 색상 표시x : 모든 막대가 동일한 범위  누적 막대그래프   전체의 합이 의미가 있는 경우 사용 단어들의 바차트 : 단일 소프트웨어 봇이 모은 많은 단어와 이미지를 갖고 있는 편집 역사를 시각화한 것  점그래프   면적을 표시할 필요가 없어 더 적은 공간에 그려짐 점의 집중정도와 배치에 따라 흐름을 파악하기 용이함 두 변수의 연관관계를 볼 때 많이 씀  연속형 그래프   점그래프를 선으로 연결, 끊임없이 변화하는 현상의 추이를 볼 수 있음. 기울기가 급할 수록 변화가 큼 데이터의 포인트 수에 따라 점, 선을 결정해야함    분포 시각화    최대, 최소, 전체분포로 나뉨\n  최대와 최소는 순서 정렬에서 양 끝\n  분포정도라 전부 합치면 1또는 100%\n 원그래프   부분과 전체, 부분과 부분을 비율을 알아봄 조각의 합은 전체 인접하지 않은 조각을 비교하기 힘듬 텍스트와 퍼센티지를 포함시키는 게 좋음 면적으로 값을 보여주고, 수치를 각도로 표시  도넛차트   조각에 해당하는 수치는 면적이 아닌 길이로 표시  트리맵   영역 기반 시각화, 시각형이 수치임 사각형을 포함한 바깥의 영역은 대분류, 내부 사각형은 세부 분류를 의미 위계 구조가 있는 데이터나 트리 구조의 데이터를 표시할 때 활용 뉴스맵 : 구글 뉴스를 시각화, 내부 사각형을 선택하면 뉴스에 대한 내용을 이미지와 텍스트로 노출  누적 연속 그래프   시계열을 쌓아올린 형태 가로축은 시간, 세로축은 데이터 값 한 시점의 세로 단면을 가져오면 분포를 볼 수 있음 네임 보이저의 그래프를 통해 어느 시기에 얼마나 선택됐는지 알 수 있다.     관계 시각화\n  스캐터 플롯\n 시간적 변화를 볼 때 쓰지만 관계를 알아볼 때도 씀 포인트들의 관련성 여부를 시각적으로 알 수 있음 포인트가 많을 때 유용    버블 차트\n 세가지 요소의 상관관계를 표현 버블의 크기가 변수 면적이나 지름으로 판단 갭 마인더 : 유엔의 데이터를 바탕으로 인구 예측, 이동에 관한 정보를 공유    히스토그램\n 한쪽으로 치우친 것이 없다면 균일한 분포 가로와 세로축은 연속적      비교 시각화\n    시작점을 찾는 것이 중요, 모든 데이터를 한 번 훑고 흥미로운 것을 찾고 다른 점을 찾아가는 과정이 더 도움이 될 수 있음.\n  히트맵\n 여러가지 변수를 비교 한 칸의 색상으로 데이터를 표현 데이터가 많으면 적당한 색상과 약간의 정렬과정을 거쳐야 함 감정 히트맵 : 주식시장에 대한 전망을 sns의 사회적 주식 지수로 보여줌    체르노프 페이스\n 데이터를 사람 얼굴 이미지로 표현 보통 사람들에게는 혼란, 전문가의 흥미가 목적    스타차트\n 중앙에서 외부 링까지 이어지는 몇 개의 축을 그리고 전체 공간에서 하나의 변수마다 축위의 중앙으로부터의 거리를 수치로 나타냄 중심점은 축이 나타내는 값의 최솟값, 먼 끝 점은 최댓값    평행 좌표계\n 여러 축을 평행하게 배치 y축에서 윗부분은 값 범위 최댓값, 아래는 최솟값 측정대상은 위아래로 이어지는 연결선으로 그려짐    다차원척도법\n 개별 데이터 간의 유사도를 바탕으로 시각화 거리행렬을 포함하는 데이터의 시각화에 유용 유사성이 작으면 멀리, 크면 가까이      공간 시각화   지도를 만들어 위치 비교 여러 장의 지도를 통해 시간의 여러 단면을 표현할 수 있음 구글 차트의 지오 차트 : 매핑 포인트를 모르고 지명만 알아도 시각화 작업할 수 있음  그래프 그리기  그래프 유형 선택   범주와 측도(차원)의 수에 좌우됨, 최소한의 것으로 최대한 것을 전달해야 함  그래프 단순화  배경을 지우기 : 배경은 데이터를 강조하는 데 방해가 됨 범례 지우기 : 보는 사람이 직접 매칭해야 되서 해석에 방해 테두리 지우기 : 답답한 느낌, 디자인에 방해 색깔 지우기 : 다양한 색은 핵심이 무엇인지 파악하기 어렵게 함 특수효과 : 디자인 통일성파괴, 핵심 전달 방해 굵은 글씨 : 시선을 분산 라벨을 흐릿하게 처리 : 처음 보는 사람이 데이터의 핵심에 집중하게 해줌 보조선을 흐릿하게, 지우기 : 데이터를 표현하는 부분이랑 겹쳐 처리 라벨을 직접 표시 : 보조선을 없애고 라벨을 데이터에 직접 표시하면 즉각적인 해석 가능    정보 시각 표현  그래픽 요소 : 뇌는 먼저 비슷한 물체와 조금 달라보이는 것을 구분한 다음에 나머지를 자세히 탐색함  자크베르탱의 그래픽 7요소  위치   위치의 변화로 하나의 요소를 강조할 수 있음 수치로 표현할 수 있음, 정보의 상하구조를 효과적으로 전달  크기   하나만 작게 만들면 작은 요소에 집중 주위 크기와 다른지가 중요  모양   하나만 다른 모양으로, 전혀 다른 형태로 바꾸기 형태만으로 큰 대비 효과는 힘듬  색   하나만 다른 색으로, 대개 보색을 씀 수치 표현이 힘들어 순서를 매기기엔 적합하지 않음  명도   하나만 명도를 다르게 함, 색상보다 더 명시성에 영향을 줌  기울기   시선은 반복에서 벗어나 변화를 감지해 강조한다고 느낌  질감   지나치게 쓰면 좋지않음  시각화를 위한 그래픽 디자인 기본 원리  타이포그래피    1~2가지의 서체의 크기나 스타일의 변화를 줌\n  한글과 영문을 비슷한 느낌으로 주는 게 좋음\n서체\n 서체는 글의 형태를 총칭, 타이포그래피에서 가장 어려운 일 세리프는 가독성이 높아 본문용, 산세리프는 주목성이 높아 제목용  무게\n 두께를 의미,무게감으로 위계표현  크기\n 글자가 배치되는 금속 활자판의 높이 의미 서체에 따라 크기가 다를 수도 있음  스타일\n 가로 세로 비율, 각도에 따라 달라짐 글자 폭을 조정, 기울기  색채\n 정보의 중요도나 종속 관계 표현 가능 바탕색에 영향을 받고 청색은 후퇴돼 보여 자제  간격\n 가독성에 영향, 다음 글자가 다른 글자보다 밀접해야 함 글자 사이 \u003c 낱말 사이 \u003c 글줄 사이    색상    색채학 원칙을 알고 지킴, 균형을 깨서는 안됨\n  보색을 이용, 명도와 채도는 같게\n  컬러 스킴 : 적절한 보색 및 배색 색상 팔레트 추출\n  어도비 쿨러 : 공유된 단어와 관련된 배색 팔레트를 가져다 쓸 수 있음\n  스네이크 오일\n구분 표현\n 정보를 구분하고 묶음, 색은 사용 숫자를 제한할 필요가 있음 보통 사람이 구분할 수 있는 색상은 8가지  순서 표현\n 명암 단계, 스펙트럼 단계 등을 이용해 구분 섬세한 순서를 표현할 때 무채색의 단계가 정보를 더 명확히 전달 명도와 채도를 복합 개념이라 할 수 있는 톤은 선형적 단계를 표현 -\u003e 정보의 순서와 위계 표현  비율 표현\n 시각적 구별할 정도로 표현 가능 0을 중심으로 0을 중립적 명도로 표시하고 위, 아래 수치들은 상반되는 두 가지 색을 사용  색채 사용과 인지\n 색을 통해 이해할 때 인간의 지각와 인지 작용이 관여함 정보들이 충돌없이 인지될 때 정보의 해석이 빠름    그리드    디자인 안에 여러요소를 복합적으로 배치할 때 반드시 그리드를 계획하고 지켜야 함\n  모션 인포그래픽, 인터렉션 정보 디자인에서도 그리드는 중요한 요소\n  블록 레이아웃을 잡고 그 위에 요소를 효율적으로 놓아 전체적 조화 추구\n하나의 화면 읽기\n 눈이 움직이는 방향을 생각 습관적으로 상단 왼쪽의 입구를 보고 오른쪽 하단으로 내려감 색의 농도는 가장 강하게 주목하는 초점이 어디인지를 보여줌  정보의 역피라미드\n 가장 중요한 정보가 위로, 밑으로 갈 수록 중요도 낮아짐 보는 사람이 모든 텍스트를 읽지 않아 맨위에 중요한 것을 배치  망 그리드\n 수평선과 수직선의 연속이 개체를 배치하는 지침 일관성이 생기고 실험의 여지도 남겨 놓아 역설적으로 디자인이 쉬워짐  3등분 법칙\n 3*3 그리드를 포개 교차하는 곳을 적극적 핫스팟으로 삼아 역동적 결과를 배치 비례 간격을 끌어들여 미학적으로 만족스러운 균형이 잡힘 핵심 요소를 핫스팟 가까이에 배치하면 구성에 역동성을 더함    아이소타이프   많은 양의 데이터를 쉽게 지각함 국제적 그림언어 체계로 갖가지 지식을 조직적으로 시각화 정보, 자료, 의미를 나타내기 위해 상징적 도형이나 정해진 기호를 조합해 나타냄 단순한 픽토그램은 아님, 하나의 기호가 일정한 수량을 대표 인류의 전통에 기대고 있어 아이소타이프 도표의 기호들은 시공간을 초월해 읽혀야 함 이미지 활용, 최근들어 아이콘으로 발전  인터렉션  인터렉션은 사용자 스스로 정보를 탐색, 필터링하는 과정에서 인사이트를 얻을 기회 제공 인터렉션 위 정보 디자인은 비선형적 구조, 사용자가 임의로 정보에 접근해 선택적 탐색 가능 시간 제약이 없어 능동적, 전달 효과 높음 메시지도 다양하게 조직화 비선형적 구조에서 인터렉션 개념 적용이 중요 요점을 제시해 사용자들이 스스로 정보를 탐구해 이해하도록 유도 정보와 정보 사용자간 관계를 확장하고 심화  강조하고 디테일을 보여주는 방식\n 웹의 진화라는 시각화 프로젝트는 사용자의 적극적 개입 유도  사용자가 콘텐츠를 선택\n 사용자는 데이터 변환 컨트롤을 통해 다른 데이터세트를 불러오는 템플릿 위에 자신이 필요한 데이터만을 취사선택해 볼 수 있음 통계 그래프보다 더 많은 데이터 세트를 관찰할 수 있도록 함 변경의 경우 즉각적으로 반영됨 위계적 원 모양의 드릴다운 내비게이션 버블로 구성  여러가지 방법으로 데이터 보여주기\n 지도는 위치와 시간 흐름의 타임라인 강조(축소/확대 기능) 시각화는 버블차트의 콘텐츠 조정을 위해 선그래프 사용 사용자는 애니메이션으로 시각화를 실행하고 직접 인터렉션 해볼 수 있음  사용자 지정으로 시각 맵핑 변화\n 멀티 조정 시각화는 작은 공간이라는 제약을 벗어나 시간대 데이터의 다양한 관점을 보여줌 시각 데이터 재매핑을 지원하고 시각화 크기를 극대화 하도록 함 데이터가 맵 위의 시각 레이어를 프로젝션하는 방식  사용자 관점과 의견이 반영\n 사용자 주관적 관점과 데이터 표현을 혼합하는 시각화는 주제를 표현하는 사용자 반응 프로세스의 가장 중요한 부분 주제 측정이 사용자가 생각하는 주관적 지표에 의해 결정됨 개인적으로 중요하게 생각하는 것은 결과치를 소셜 미디어를 통해 공유할 수 있음  시각 정보 디자인 7원칙  시각적 비교를 강화 : 연관된 변수와 트랜드를 비교할 수 있는 도구 제공 인과관계 제시 : 디자인할 때 원인과 결과를 제시 다중변수 표시 : 연관된 변수를 활용해 정보 표현 텍스트, 그래픽, 데이터를 조화롭게 배치 : 라벨, 범례가 도표에 녹은 다이어그램이 효과적 질과 연관성, 진실성 : 정보가 과연 사용자의 특정 목적을 달성하는데 도움이 되는지 고민 시간순이 아닌 공간순 나열 : 사용자의 이해가 쉬움 정량성을 제거하지 않기 : 정량적 정보를 한 눈에 파악하게 하기   \n빅데이터 시각화 디자인  기업에서 빅데이터 시각화를 통해 제공하는 것  내부적 : 인사이트로 도출하는 시각적 분석 도구, 정보 전달 및 상황 진단 프로세스 개발 외부적 : 정보를 고객에게 전달   빅데이터 시각화는 데이터 또는 정보를 탐험할 수 있는 기회를 사용자에게 주는 형태여야 함 이미지 형태보다 인터렉션 형태의 결과물로 제공 ex) 페이스북 인기 지도  빅데이터 시각화 디자인 사례  2D 이미지   인쇄물이나 온라인 이미지 색상 및 그래픽 형태로 표현, 시각화 툴과 프로그래밍 기술 이용  모션 영상   시각화를 순차적으로 보이거나 자동 애니메이션 제공 모션 인포그래픽 ex)윈드맵, think 뉴욕 설치 광경  인터렉티브 애플리케이션   결과물은 인터렉티브 형태가 주류임 많은 양의 정보를 다양한 레이어나 필터를 통해 사용자가 접근하도록 함 ex) 갭 마인더, GBCS, 트룰리아, 에코매지네이션 챌린지  빅데이터 시각화 디자인의 방향  개인의 능력을 통해 최신의 기술과 도구를 사용해 정보를 제시하고 분석하는 것 비주얼 인식의 심리적인 부분을 알고 특정 시각화 기술이 줄 수 있는 한계에도 이해해야 함 궁극적으로 정보 디자인의 의도와 방향이 목적과 어긋나지 않아야 함 범주 안에서 정보를 보고 사용자를 위한 시각화 목적을 설정하고 이를 끝까지 고수해야 함 적합한 데이터 수집, 가공, 그래프 처리 과정이 진행되어야 하고 전문성이 단절되어선 안된다. 시각화에서 정보성이 결여되면 효율성과 참신성이 떨어지는 문제가 발생  ","description":"","tags":null,"title":"ADP 공부하기 12","uri":"/posts/certificate/2020-02-11-adp_study12/"},{"categories":["Certificate"],"content":"시각화 디자인 시각화의 정의 1.데이터 시각화의 중요성 시각화란?\n 매우 광범위하게 분산된 방대한 양의 자료를 분석하여 한 눈에 볼 수 있도록 도표나 차트 등으로 정리 통찰력을 얻기 위해서는 시각화한 서비스가 필요  2.데이터 시각화의 목적  데이터 분석, 의사소통  3.효과  정보를 습득하는 시간을 절감, 즉각적인 상황 판단 흥미를 유발하고 정보의 빠른 확산 기대 자료를 기억하기 쉬움  시각 이해와 시각화 1. 시각 이해의 위계 2. 데이터  사전적 정의 : datum의 복수형, 근거가 되는 사실이나 참고 자료를 의미, 정보와 혼용, 미디어에 저장된 형태 연구나 조사 등의 결과인 일종의 기초 자료, 정보를 만들기 위한 원자재 정보로서 가치가 부족해 분석이 대상은 되도 디자인의 대상은 될 수 없다. 불완전, 비연속적, 정보 전달 가치 없음  3. 정보  그 자체로 의미, 관점에 따라 다르게 전달될 수 있고 나름대로 형태와 형식을 가짐 패턴을 가시화, 의미를 전달 가치를 갖기 위해서는 변형과 조직화 필요 콘텍스트 : 데이터의 환경, 이해하는 사람의 환경과 태도가 무엇인지 설명 자기 조직화되지 않은 일반적인 의미만을 내재  4. 지식  다른 영역의 정보가 자기 조직화해 획득할 수 있는 것 경험을 통해 정보를 통합, 인위적으로 습득하는 고도의 논리적 상식 경험을 통해 형성된 지식은 세부 사항을 설명할 뿐만 아니라 다양한 상황에 적용할 수 있도록 일반화한 것  5. 지혜  고차원 방법으로 충분하고 이상적인 패턴을 이해하는 정보의 최종 단계 지식이 자기 내면화가 되서 개인적 맥락 안에 포함될 때 지혜가 됨 자기 내면화된 지식이라 상대방에게 전달하기 어려움 추상적이고 철학적, 인위적으로 전달하거나 공유할 수 없음  6. 정보 인터렉션 디자인  공급자는 데이터와 정보에 속하고 수용자는 정보와 지식 단계에 속함 정보 : 글로벌 콘텍스트, 지식 : 로컬 콘텍스트  시각화 분류와 구분 1. 데이터 시각화  그래픽 의미를 이용해 명확하고 효과적으로 의사소통하기 위함 복잡한 데이터보다는 직접적인 관점을 제공 연결과 그룹핑에 초점 두 가지 관점 : 통계적 그래픽,주제 지도학 마인드 맵, 데이터 표현, 관계 표현, 기사, 리소스, 툴과 서비스  2. 정보 시각화  시각적 표현 방법의 간학문적 연구 영역 대규모 비수량 정보를 시각적으로 표현 시각적 표현 방법과 인터렉션 기술을 통해 정보를 직관적인 방법으로 전달하기 위해 접근 방법을 창조 표현 : 분기도, 수지도, 히트맵 , 트리맵  3. 정보 디자인  사람이 사용할 수 있는 효과적인 정보를 시각적으로 표현 데이터, 정보 시각화도 정보 디자인에 속한다고 할 수 있다. 인포그래픽, 다이어그램  4. 인포그래픽  중요한 정보를 한 장의 그래픽으로 표현해 사람들이 손쉽게 정보를 이해할 수 있도록 하는 그래픽 메세지 패턴이나 트렌드를 봄, 기초, 지도, 기술문서 등에서 이용 뉴스 그래픽이라고도 불리고, 원 데이터를 취급하지 않음 차트, 다이어그램, 일러스트레이션 등 사용 정보형 메세지  객관적인 정보 전달 지하철 노선도와 같이 실제 지도를 왜곡하더라도 보기 쉽도록 구현   설득형 메세지  주장하는 바를 알리는데 목적 정보 전달보다는 시각적으로 강렬하게 주장하는 바를 전달 사회 계층별 분포 데이터를 옷에다 극단적으로 함축한 예시가 있음    빅데이터 시각화 영역  메시지 전달 관점에서 시각화  데이터 시각화 : 많은 데이터에 의미부여해 효율적으로 전달 정보 시각화 : 큰 범주에 해당하는 정보를 시각화   정보 디자인은 데이터의 디테일보다는 그래픽을 적극적으로 이용해 시각 스토리텔링 형식의 설득형 메시지를 전달하는 것에 초점 객관적 표현에 초점 직접적으로 전달하는 기능성에 초점을 맞춘 정보형 메시지를 전달하기 위한 데이터 시각화를 하는 경향이 강함. 설득형 메시지인 경우 인포그래픽에 해당하는 결과물이 도출될 수 있음  정보 디자인에서 빅데이터 시각화 영역\n 양적 정보 디자인은 정보 시각화와 겹치면서 데이터를 객관적으로 비교해 인과관계를 왜곡없이 전달하는데 초점을 둠 정보의 내용과 환경이 복잡하므로 표현도 다차원적이어야 함 어떤 식으로 해석하는 가에 대한 통계적 차원의 시각화 방법 및 이에 따른 시각 표현이 병행되어야 함.   시각화 프로세스 정보 디자인 프로세스 인포그래픽 디자인 10단계  프로젝트 수주\u0026니즈 파악 메타데이터 읽기 보충자료 요청 자료분석\u0026이야기 찾기 초안 작성 글쓰기\u0026이미지 취합 디자인 시안 작성 검토\u0026수정 납품  정보 디자인 프로세스 10단계   데이터 자체를 수집하는 단계\n 스토리를 시작하는 단서를 찾음 큰 그림은 떨어진 차트 안에서가 아닌 흩어져 있는 다양한 리소스들로부터 발견됨 시각화 전문가가 원 데이터를 직접 수집하기는 어려움    모든 것을 읽기\n 에코시스템 안에서 정보의 작은 조각들을 큰 그림으로 맞추는 것이 중요 정보가 빠졌는지, 근거를 확인하는 등의 노력 필요    내러티브 찾기\n 내러티브 : 스토리텔링, 실화나 사건을 묘사, 이야기를 조직하고 전개하기 위해 이용되는 각종 전략, 형식을 포괄 인포그래픽은 복잡한 데이터를 명료화하고 프로세스를 설명하고 트렌드를 창조, 논란의 부분을 보조하는 의도와 함께 시작된다.    네레티브를 찾기 위한 질문\n 제공하고자 하는 스토리를 만들어 내는 것이 가능한가? 이 주제에 관심이 가는가? 주목할 만한 사실, 가치를 말하고 있는가?   문제의 정의\n 결과에 대한 논리성을 검토 컬러, 타이포그래피 등의 주관적인 관점에서 디테일을 만들어감 수용자에게 정보의 진실을 알아가는 경험을 하게 해야함    계층 구조 만들기\n 이야기의 중심을 찾으면 프로젝트를 정리하고 개별 자료를 정리 중요한 것은 주인공으로, 나머지는 보조적인 요소로 배열, 해당 요소들이 리서치 단계에서 콘셉트 보드 역할을 함 이 단계에서 최종 결과물이 나타나기 시작    와이어프레임 그리기\n 계층 구조가 결정되면 와이어프레임이 창조됨 시각표현을 만들어내 정보의 계층 구조를 이해하게 만듬    포맷 선택\n 가장 좋은 접근 방법은 전통적인 파트와 그래프를 이용하는 것 프로세스를 설명하기 위해 다이어그램, 흐름도 등이 필요 간단한 숫자를 나열하는 것도 충분 충분한 예산이 있다면 인터렉션을 시도 결정은 이러한 포맷들의 복합이거나 한 가지 종류의 포맷을 불문하고 그것이 갖고 있는 데이터에 의해 선택되야됨    시각 접근 방법 결정하기\n 차트와 그래프를 일러스트와 함께 보여주거나 전통적인 데이터 표현과 시각 표현을 함께 사용하기도 함 정보, 매체, 클라이언트, 브랜드, 주제는 궁극적인 해결 방법을 결정하는 요소들 직관적이고 효과적인 인포그래픽을 결정하기 위해서는 두 가지 시각적 접근 방법 필요 초기 데이터의 아름다움을 만들어내는 방법 : 컬라나 타이포그래피, 각 조각들을 연결한 구조들은 추상화 느낌 일러스트레이션이나 메타포를 이용한 방법 : 사진 등 다양한 자료로 시각화, 어떤 시각적 접근 방법이 목적에 맞는지 결정    정제와 테스트\n 최종 결과물 디자인이 원래 의도와 목적에 맞게 데이터와 시각적 스토리텔링이 잘 되었는지 확인 쉽게 이해되는지의 여부 확인 평가하고 가능하면 디자인을 간단하게 개발하고, 반복 테스트 과정이 진행되어야 함    세상에 선보이기\n 온라인을 통해 대중들에게 배포 모든 사실 조사와 상상이 스토리의 모든 관점을 드러내는 것은 아님. 새로운 방식으로 해석될 수 있어 프로젝트가 결코 끝난 것으로 보는 게 아님 새로운 데이터가 나타나면 프로젝트는 프로세스 안에서 지속됨    빅데이터 시각화 프로세스 시각화 방법론  정보 디자인 교과서 : 4단계 방법론  조직화된 데이터, 시각적 매핑, 시각적 형태, 전달 방식   마티아스 샤피로 : 3단계  질문 만들어내기, 데이터 수집, 시각적 표현 분석보다 적당한 주제 선별 어느 정도 정해진 범주를 두고 시작하는 것이 아니라 시각화를 다루는 사람에 의해 좌우됨 질문과 수지의 단계가 바뀔 수도 있다.   벤프라이 : 7단계  프로세싱을 통해 프로그래밍으로 시각화 데이터를 모으고 분석하는 단계가 세분화       단계 단계 설명 관련 분야     1. 획득 파일, 디스크 등에서 정보 수집 컴퓨터공학   2. 분해 의미를 바탕으로 구조적으로 카테고리화 컴퓨터공학   3. 선별 위 과정을 바탕으로 필요 없는 정보 제거 수학,통계학, 컴공   4. 마이닝 데이터를 분석해 추출 알고리즘 도출 수학,통계학, 컴공   5. 표현 정보를 효율적으로 표현할 수 있는 방법 연구 그래픽 디자인   6. 정제 규칙을 바탕으로 정보를 시각적으로 정제 그래픽 디자인   7. 상호작용 다양한 시각에서 시뮬레이션 할 수 있는 방법을 반영 정보 시각화,HCI    방법론 연계    정보 구조화\n 수집 및 탐색, 분류, 배열, 재배열의 4단계로 나뉨 구조화 방법이 미리 학습되어야 함 기계학습 알고리즘으로 파악 후 자동 시각 추출하는 방법도 연구 중임 통계적 접근으로 시각화하는 것과 시각화 목적으로 정보 구조화에 접근하는 것은 다름.    정보 시각화\n sas, 하둡, 타블로 등 툴 사용 그래프를 왜, 어떻게 표현하는지 설명    정보 시각 표현\n 시각 표현을 극대화하고 다듬는 방안을 실험 데이터 시각화를 탐험할 수 있게 하는 다양한 벙법을 습득할 필요가 있음    빅데이터 시각화 프로세스    단계 단계 설명     1. 정보 구조화 수집하고 정제 과정, 분석 도구 필요   2. 정보 시각화 의미를 바탕으로 구조적으로 카테고리화   3. 정보 시각 표현 분석 도구에서 결과물에 별도 그래픽 요소를 추가해 완성    빅데이터 시각화 도구  엑셀 구글 차트  속도 빠르고 모바일에서 잘 작동 구글 스프레드 시트 저장, 초보자 위한툴 제공 차트 api가 있음   infogr.am  30종 차트, 무료 사용 pnf, pdf 추출 가능, 온라인 공유 용이   매니아이즈  11개 등을 제한된 범위 내 사용 데이터 셋 올리고 차트 선택   D3.js  시각화 프레임워크, html, css 사용   파이썬  대규모 데이터, 큰 계산 다룸 작은 코드로 많은 기능 가능, 다양한 라이브러리 탐색 단계라면 훌륭한 툴임   processing  디자이너와 데이터 아티스트의 활용 목적인 언어 몇줄의 코드로 애니메이션과 인터렉티브 그래픽을 만듬 자바로 만들어져 느리지만 최근 자바스크립트로 만들어주는 프로세싱 버전이 공개됨   R  데이터 통계분석 위주, 패키지가 많음 대다수 통계학자와 분석가들이 선호하는 프로그램 인터랙티브 그래픽과 애니메이션이 취약, 한 번 더 수정해야하는 단점이 있음   YFD  온라인 애플리케이션 시각화 툴 트위터 데이터 수집하여 시각화 도구로 패턴 및 관계를 찾는다. 개인적인 데이터를 다루기 위해 만들어짐   일러스트 레이터  벡터 기반 그래픽을 제작할 때 편리 PDF포맷으로 추출된 것을 편집하는데 이용       수준, 종류 구분 시각화 도구     기초 엑셀, 구글 차트, d3, visual.ly, cvs/json, Raphael   인터랙티브 GUI컨트롤 crossfilter, Tangle   매핑 Modest Maps, Openlayer, kartograph, polymaps   전문가 Processing, R, Weka, Gephi, NodoBo    ","description":"","tags":null,"title":"ADP 공부하기 11","uri":"/posts/certificate/2020-02-08-adp_study11/"},{"categories":["Certificate"],"content":"활용  내부에서 적용   활용되는 과정에서 새로운 통찰을 찾을 수도 있고 기존 통찰에서 부족한 점을 보완할 수 있다. 새로운 문제 해결 방식 도입과 구체적인 탐색과 발전의 과정 새로운 변인을 추가하거나 관련된 상수값을 보정, 서비스 개선 요소의 모델을 발견해 실행에 옮길 수도 있음 통찰은 보통 형태가 없어 시각화하는 것이 중요하다. 실행에 옮길 때는 현실적인 여건을 충분히 반영했는지 검토함  외부에 대한 설명,설득화 시각화 도구   쉽게 받아들이기 위해 일단 쉽고 간결해야함 통찰을 보다 효과적으로 전달하기 위해 시각화한 그림이나 그래프 활용 상대방이 공감해야 하므로 좀 더 강력한 상호 작용 필요 -\u003e 디자인 중요 직접 조작하며 메세지를 받아들이는 인터렉티브 인포그래픽과 정보 디자인을 시각화 도구로 이용하면 효과를 높일 수 있다. 탐색의 내려다보기와 올려다보기와 같은 조작을 통해 인터렉티브 인포그래픽은 메시지 생산자가 정해 놓은 범위 안에 수용자가 정보를 구체적으로 이해할 수 있게 함  인사이트의 발전과 확장 1. 탑다운vs보텀업\n 처음으로 무언가 살펴볼 때는 보텀업 의미있는 것을 파악해 추가로 얻어낸 정보를 토대로 탑다운으로 검증  2. 2차 잘라보기, 달리보기, 내려다보기, 올려다보기\n 기존에 도출한 데이터의 현실성 및 분석에서 활용한 모델의 적정성 체크 실세계에서 활용한 뒤 추가적으로 정보를 얻을 수 있다. 과정을 통해 시도해보지 않은 차원들 간 조합이나 특정 차원을 특정 값으로 고정해 보면서 인사이트를 고도화하고 확장할 수 있다.  3.실시간 vs 비실시간\n 일정한 시간이 지난 뒤 그것이 어떠한 영향을 가져왔는지 검증하는 과정의 반복이 필요함 반복 주기에 따라 실시간으로 탐색하고 분석할 수 있는 환경을 구축하는 것이 나은지 비실시간이라도 주기적으로 새로운 데이터를 구축해 환경을 구축하는 것이 나은지 결정해야 함. 데이터가 클수록 실시간으로 보는 것이 어렵다. 변화와 경향을 주기적으로 보는 것이면 굳이 실시간 환경을 구축할 필요는 없다.  4. 지표의 운영\n 지표를 활용한다는 것은 여러 가지 관계를 다 살펴보는 부담을 덜어준다 몇 가지 지표만 집중해도 전체적인 흐름을 알 수 있다. 인사이트 프로세스에서 추출한 지표를 중심으로 운영할 경우 문제점이 발생할 수도 있다.(환산된 값 중심이라 어떤 변화요인이 지표 흐름에 영향을 미쳤는지 찾기 어려움) 지표의 장점과 단점에 대해 명확히 이해하고 인사이트의 발전과 확장 효율성을 높일 수 있는 방향으로 지표를 끌고 갈 필요가 있다.  5. 추가 데이터에 대한 필요성\n 기존에는 살펴볼 생각도 하지 못한 관계들이 어떠한 데이터를 통해 파악될 수 있을 것만 같을 때 추가 데이터가 필요함 기존의 인사이트를 발전, 확장시키는 새로운 인사이트 프로세스에 추가 데이터를 반영할 계획이라면 일단 그 데이터가 정말로 필요한지 어떻게 사용할 것인지를 명확하게 짚어보아야 한다.  6. 시각화 문제\n 시각화 도구의 장단점과 적용 구조를 제대로 이해하지 못하면 치명적인 독이 됨 눈의 착각 : 사람의 시각이 물리적인 자극에 대해 있는 경우 그대로 정확히 받이들이지 못함 특히 인포그래픽 등으로 설명, 설득하는 경우에는 여러 가지 디자인 요소가 결합되어 오류가 발생할 여지가 크다 여러 관점에서 신중하게 고려해야 함  7. 사람의 문제\n 세부적인 방힉과 도출된 결과물은 질과 방향 등에 있어서 개인차가 발생할 수 밖에 없다. 특히 눈여겨 봐야 할 것은 전통적인 접근 방식과는 다른 생각이다. 새로운 가치와 통찰은 서로 다른 것들을 연결하는 것에서 태어난다는 것을 주목해야 한다.  ","description":"","tags":null,"title":"ADP 공부하기 10","uri":"/posts/certificate/2020-02-01-adp_study10/"},{"categories":["Certificate"],"content":"시각화 인사이트 프로세스 시각화 인사이트 프로세스 의미 사전적 의미로 정보, 인과관계, 본질 , 이해\nDIKW피라미드 데이터 : 개별적 기초 자료(원자료) EX 강수량 정보 : 데이터 간의 관계(상관,인과 관계) EX 지역별 연간 강수량 지식 : 다양한 정보가 상위 관계를 맺고 조직화 EX A마을의 수해대책 지혜 : 개인화된 지식,경험 등과 관계를 맺을 때 구조화되어 나타남 EX A마을 주민 개개인의 생활 노하우\n시각화와 인사이트 관찰 : 대상들 사이의 상호작용을 바탕으로 의미있는 관계를 찾아냄 성찰 : 자신의 내면 세계를 살펴봄, 자신의 사고와 행동에 의문을 제기하고 해결 통찰 : 관찰과 성찰을 기반으로 요인들 간의 관계를 통해 살펴봄 위의 삼찰을 바탕으로 대상들 사이의 숨겨진 관계를 찾아내는 과정을 통해 인사이트 얻음\n통찰 과정과 시각화   통찰과 시각화\n 통찰은 살펴보고 이해하는 과정 인사이트는 활용 과정에서 검증이나 보완할 수 있다. 통찰 과정의 시각화 : 눈에 확 띄게 만듬, 추상적 개념을 보이게 함 시각화 인사이트 프로세스 : 시각화를 통해 통찰을 추출하는 과정    1단계 탐색 - 관계 발견\n 어떤 관계가 있는지 최초로 살펴보는 단계 지혜를 통해 도출, 데이터에서 정보를 도출, 정보에서 지식을 도출 시각화로 객관적인 패턴을 발견하고 개괄적 패턴 찾기 검증 : 결과가 얼마나 효율적으로 도출되었는가    2단계 분석 - 관계 규명\n 관계들의 형태를 명확하게 규명하고 형태가 지니는 의미를 찾아냄 구체적 관계를 찾거나 관계를 보다 잘 설명하는 다른 요인을 찾는 작업 필요 방향성, 명제, 모델링, 지표 개요가 명확해야 함 정성적 기법, 정량적 기법 사용 시각화로 관계의 구체적인 모델링 및 적용, 조정 검증 : 분석의 결과의 효율성    3단계 - 활용 - 통찰 검증 및 보완\n 실제로 활용함으로써 얼마나 의미가 있고 가치를 인정받을 수 있는지 검증 부적절한 부분은 다시 탐색과 분석을 함 내부 : 직접 활용 외부 : 타인에게 설명 시각화로 타인에게 효과적으로 설명, 메시지 전달 검증 : 수용자가 제대로 이해했는지, 예상한 반응을 보이는지    탐색 사용 가능한 데이터 확인   데이터 명세화 : 차원과 측정값\n 모든 데이터는 기본적으로 하나 이상의 측정값과 차원을 가짐 EX\u003e 국가별 남성 평균 수명 -\u003e 차원 : 국가,성별/측정값 : 평균수명 연속적인 데이터로 구성된 차원은 구간 형태로 제시되기도 함 동일한 데이터 항목이라도 차원이 될 수도 있고 측정값이 될 수도 있다.    데이터 구성 원리1 : 이벤트 기록으로서 접근\n 원본 데이터는 특정 이벤트가 발생했을 때 발생한다. 로그 데이터와 로그 데이터를 한 번 정제한 데이터는 구분할 수 있어야 함 데이터가 어떤 원리로 생성,구성되었는지를 항상 염두에 두어야 함 관계는 시각화 도구로 찾아낼 수 있다.    데이터 구성 원리2 : 객체지향 관점에서의 접근\n 데이터의 구성과 생성 배경에 대해 고민함 데이터의 대략적 범위가 주어지면 데이터의 구조 자체를 설계,생성 하여 이를 토대로 통찰을 뽑아낼 수 있어야함 기본적으로 대상을 객체화 하고 모든 객체들은 행위와 고유속성값을 가짐 구조와 행위를 통해 구조 전체를 파악하는 것이 객체지향 관점 구조 전체를 파악해 그 구조가 제대로 이벤트 로그 데이터로 기록되고 있는지를 검증해 보완할 수 있다. 다양한 통찰을 위해선 데이터의 구성을 밝히고 추가 자료, 인사이트 프로세스의 목표 및 방향성을 조정하는 것이 필요    연결 고리의 확인 2개 이상 데이터를 활용할 수 있을 때는 연결고리를 살펴 관계의 범위와 방향을 정하고 확장할 수 있다. 이 때 연결 고리는 시각화 도구가 아는 데이터의 태성을 정리한 명세서에서 확인\n 공통 요소 찾기   서로 다른 데이터 명세서에서 공통 항목을 찾음 항목명이 아닌 항목의 정의와 데이터형을 보고 찾아야 함. 항목명이 달라도 같은 데이터형으로 되어 있고 기록된 규칙이 같다면 공통 요소이다.  공통 요소로 변환하기   데이터형이 다른데 공통 요소로 만들 수 있음 계층이나 기준으로 묶인 데이터의 대부분은 형태를 변환해 연결 고리를 찾음 자세한 자료를 덜 자세하게 묶인 자료 변환은 가능하지만 반대는 불가능 만드는 과정도 인사이트 프로세스 현실세계의 거의 모든 데이터는 구성 원리에 의해 시간과 공간 관점의 연결고리를 기본적으로 가짐  시간 데이터 변환\n 초 단위 데이터는 손쉽게 시간 단위, 날짜 단위, 분기 및 연 단위 등으로 전환 가능 날짜 시간 데이터가 문자열로 지정된 경우도 있음 -\u003e 시간 형으로 변환 DATE, YEAR, MONTH 등의 함수 이용  공간 데이터 변환\n 주소/주소를 세부적으로 구분한 행정구역(시,도), 가장 구체적인 좌표값 데이터에 따라 경위도 좌표계가 아닌 다른 기준의 좌표계로 구성된 경우도 있다. 텍스트 나누기, 문자열 함수 등 사용     함수명 함수 사용 형태 함수 기능 설명     SPLIT split(문자열, 구분자) 문자열을 구분 문자 기준으로 분리해서 제공   FIND find(찾는 문자, 문자열) 찾는 문자가 왼쪽에서부터 몇 번째에 위차하는지 숫자값   LEFT left(문자열,개수) 왼쪽부터 정해진 개수만큼 제공   MID mid(문자열,시작 위치,개수) 시작 위치부터 정해진 개수만큼 제공     지오코딩 : 좌표계를 주소 및 행정구역으로 변환하거나 반대 과정 코로플레스 지도 : 미국이나 유럽을 분석하기에 유용한 시각화 도구 X-Ray Map : 비즈 GIS가 무료로 제공하는 웹 GIS 도구, 한국 지역 유용  일정한 규칙을 가진 분류형 데이터로 변환\n 어떤 데이터는 하위 수준에서 기록되어 있고 다른 데이터는 상위 수준으라면 상위 수준이라는 공통 요소로 반환해 연결고리를 만들 수 있음 replace : 전체를 일괄적으로 바꿈 lookup, vlookup : 전체를 일괄적으로 바꾸지 않고 원하는 영역만 바꿈  탐색 범위의 설정   보유한 데이터를 조합을 고민, 명세화 해야함 여러 개의 데이터 명세를 보유한 경우 연결 고리를 확인해 탐색할 수 있는 차원과 측정값의 조합을 정리해야 함 각 조합 하나하나가 통찰을 추출하는 관점이 됨, 전체 조합 종류가 탐색의 범위  탐색 범위 설정 시 고려 사항\n 여러 개의 데이터를 보유한 경우 개별 데이터 안에서 먼저 탐색 측정값에 하나의 차원만 연결해 탐색 같은 데이터 안에서 차원과 측정값을 맞바꾸면 다른 통찰을 찾아낼 가능성 있음 목표와 관련있을 법한 조합을 만듬 상식적으로 의미나 연계성 없는 조합은 배제  관계의 탐색 1. 이상값 처리\n 측정 오류로 오차가 들어간 경우 제거 대상이 됨. 하지만 의미있는 이유일 수도 있어서 우선적으로 시각화 도구로 전체 구조를 파악하고 패턴을 찾아봄 기록 관리 과정에서 문제 -\u003e 보완, 대체, 제거 의미있는 이유 -\u003e 구체적으로 파고들어야할 대상  2. 차원과 측정값 유형에 따른 관계 파악 시각화\n 시각화 도구 선정  차원과 측정값이 어떤 유형인지 봄 1차원 선형, 2차원 평면, 3차원 공간에서 표현 시각화 도구 선정 시 고려 사항     차원은 반드시 축으로만 표현되는 것은 아님 2차원 평면에서는 x,y축 이외에 도형의 면적도 연속값으로 된 차원을 처리할 수 있는 도구로 사용 3차원은 입체의 부피나 단멱의 면적을 연속값으로 처리 색상 : 차원을 구분, RGB값으로 나눠 차원을 그라데이션 변화로 표현 가능  시각 데이터 관계 탐색   변화하는 패턴을 분리하는 것이 핵심 모션 차트 : 구글 스프레드 시트에서 제공, 움직임을 통해 보여주는 동적인 시각화 도구  공간 데이터 관계 탐색   실제 지도를 활용하는 것이 가장 직관적이고 효과적 Arc GIS : 유료화된 전문 지리정보 분석 도구 X-Ray Map : 무료 도구, 실제 지역 데이터 관계 볼 수 있음 파워 맵 : 엑셀 2013 도구, 모션 차트까지 결합해 제공  비정형 데이터 관계 탐색   우선 텍스트 문장들 안에 어떤 의미를 지니는 단어들이 어떤 빈도로 분포하는지를 살펴야한다. 워들 : 텍스트 데이터에서 형태소 단위를 추출해 빈도에 따라 색상, 크기를 결정하고 시각적으로 겹치지 않게 적절히 배치  3. 잘라보고 달리보기\n slice : 패턴을 탐색 후 일정 기준으로 일부분만 보는 것 dice : 차원들을 기준으로 잘라내 서로 다른 관점의 단면들을 살펴보는 것 피벗, 피벗 테이블 파워뷰 : 엑셀 2013기능 시각화 탐색을 적용하는 것에 비해 훨씬 강화되고 확장된 기능 OLAP : 기업에서 쓰는 BI도구, 실시간 기업 다차원 데이터에 접근에 slice, dice하며 분석, 리포팅 하는 도구  4. 내려다보기 올려다보기\n drill down : 하위계층으로 기준을 세분화 reverse drill down : 상위 계층의 관점으로 보는 것 상위하위 계층의 패턴을 살피고 그 차이점을 토대로 다시 하위 계층을 살펴보는 구조 트리맵 : 면적을 이용해 차원을 표현한 도구, 하이퍼볼릭 트리  5. 척도의 조정\n 정량적 데이터를 뿌려 놓을 때도 척도를 어떻게 설정하느냐에 따른 다름 측정값 범위가 너무 달라 패턴이 제대로 나타나지 않는 경우가 종종 있다. 실제 값을 변형해 같은 공간에 표시해도 각각의 패턴이 명확하게 보이게끔 조정해야 함 스파크라인 차트 : 계열별로 다른 범위의 측정값들을 동일한 공간 범위 내에서 패턴변화를 비교해 볼 수 있도록 자동으로 조정해 주는 시각화 도구  분석 분석 대상의 구체화  1차 탐색   어떤 패턴이 좀 더 중요하고 더 제대로 뜯어봐야 하는지 우선순위를 결정해야 함 찾아낸 단서들을 기반으로 우선순위를 조정해 볼 수도 있다. 궁극적 목적 : 충분히 살펴보지 못한 것들을 보고, 차원과 측정값들의 조합을 적절하게 바꿔가면서 관찰했는지 한 번 더 점검  분석 목표에 따른 분석 기법     분석 목표 설명 통계적 분석 기법     평균에 대한 검정, 추정 평균에 대한 모델링 T검정   비율에 대한 검정, 추정 비율에 대한 모델링 직접확률계산, F분포   비율에 대한 검정, 추정 2개 이상 차원이 있고 하나의 측정값 -\u003e 분류 조합에 따라 측정값에 유효한 차이가 있는지 검정 카이 제곱 검정, fisher의 직접 확률 검정, 멕네마 검정, 잔차 분석   상관관계 강도 도출 독립적으로 움직이는 변수들 사이 관계의 강도를 상관계수로 나타냄 상관분석   선형/비선형 인과관계의 형태, 강도 추출 독립적으로 움직이는 변수들 사이 관계의 강도를 상관계수로 나타냄 회귀분석,로지스틱, 판별분석   요인들 사이의 관계와 핵심 요인 선별 변화 요인이 되는 값들이 3개라 할때 어떤 것이 측정값에 가장 영향을 미치는지, 다른 차원의 영향력과 어느 정도 겹치는지 분석 요인분석,주성분 분석   대상들을 여러 기준으로 분류, 다차원 공간 배치 차원들의 값 기준으로 측정값들 사이 거리를 계산해 그룹을 짓고 다차원 공간에 측정값 배치 군집분석, 다차원척도법(MDS)   패턴이 비슷한 측정값과 그젛지 않은 측정값 분류 답변들의 패턴에 따라 비슷한 답변을 한 응답자와 그렇지 않은 응답자 분류 대응분석   흐름에 따라 변하는 데이터 분석 모델 도출 추세요인, 계절요인, 순환요인, 불규칙요인으로 분해해 모델을 만들어 미래 예측 시계열분석     차원이 많거나 불연속 데이터가 많은 경우 통계적 분석법 활용 통계적 분석 기법의 결과물 : 구체적 계수, 설명계수, 그래프, 걸러진 변수 시각적 도구와 통계적 도구는 상보적 관계  분석과 시각화 도구  회귀분석에서 적합한 함수식을 찾는데 보조도구로서 사용됨 회귀분석을 통해 인과관계를 살펴볼 수도 있고 전체 형태의 추세를 통해 미래 또는 축 상의 다음 측정값에 대한 예측을 할 수도 있다. 만약 시각화 해보지 않으면 도출된 예측값만으로만 보면 현실적인 가정 및 조건을 놓칠 수 있다. 통계적 분석 기법과 시각적 분석 기법은 밀접한 관계임  지표 설정과 분석  지표의 기본 개념   KPI : 기업에서 업무성과 평가 목표설정 등의 활동에 활용, 세부적인 활동 결과물 추진 정도나 수준을 측정하고 평가 도출되는 결과값을 지표로 활용할 수 있다. 의미가 있고 직관적으로 이해되는 수치들을 지표로 만드는 것이 가치가 있음  지표의 기본 구조   지표는 인사이트를 커뮤니케이션에 활용, 분석할 때도 유용 관계를 지표로 축약해 표현하면 다른 관계를 살펴보는 기준으로 삼기 편해짐  지표 활용시 주의점   단위를 잘 살펴야 함 시각화 도구에 적용할 때 적적하게 단위가 표현될 수 있는지 체크해야 함. 척도와 관련된 문제는 없는지 봐야함 지표로 분석할 때 다른 변수들이 이 지표와 어떤 관계에 있는지 봐야한다. 지표가 통계적 모델을 만들 때 포함된다면, 모델 설명력이 과대평가될 수 있다. 요인 분석 : 지표가 지표를 만든 다른 요인들과 상당 부분 설명력이 겹치는지 확인  ","description":"","tags":null,"title":"ADP 공부하기 9","uri":"/posts/certificate/2020-01-31-adp_study9/"},{"categories":["Certificate"],"content":"분산 컴퓨팅 기술 MapReduce 개념\n 구글에서 분산 병렬 컴퓨팅을 이용하여 2004년 논문에서 공개됨 분할정복 방식으로 대용량 데이터를 병렬로 처리할 수 있는 모델  분할정복 : 성질이 같은 여러 부분으로 나눠 해결한 뒤 원래 문제의 해를 구함   c++,JAVA 적용, 아파치 하둡의 Hadoop MapReduce가 동일한 기능 클라이언트의 작업 단위는 맵리듀스 잡 map, reuce task로 나뉨 map task 하나가 1개의 블록을 대상으로 연산, 사용자가 지정한 개수에 해당하는 reduce task들이 받아 정렬 및 필터링 작업을 거침  구글 맵리듀스  복잡성을 추상화시켜 핵심 기능 구현에만 집중하게 함 map에는 key와 value 쌍들을 입력으로 받음 map함수를 거치면서 다수의 새로운 key, value로 변환 reduce로 전동됨. 이 과정에서 shuffle과 group by 정렬 과정을 거쳐 reduce의 입력 레코드로 들어가게 되는데 형식은 key, value의 리스트다 reduce 함수를 통해 최종 output 산출, 사용자는 map과 reduce 함수만 작성  실행 과정  마스터는 입력 데이터소스를 가지고 스케줄링함 각 split이 map 프로세스들의 할당 단위, split은 64~128mb(블록 단위), split 수만큼 map task들이 워커로부터 fork됨 output값은 partitionar라는 reduce번호를 할당해 주는 클래스를 통해 보낼지 정함.정해지지 않으면 동일한 key들은 같은 reduce로 배정 = map단계가 끝나면 원격의 reduce 워커들이 자기에 할당된 map의 중간 값들을 네트워크로 가져, 사용자의 reduce로직을 통해 산출물 보통 reduce의 개수는 map의 개수보다 적고, map의 중간 데이터 사이즈에 따라 성능이 좌우됨 적합한 경우 : 분산grep이나 빈도수 계산 등의 작업  map단계를 거치며 데이터 사이즈가 크게 줄어들고 줄어든 크기만큼 reduce의 오버헤드도 줄어듬 = 적합하지 않은 경우 : 정렬과 같은 작업 사이즈 줄지 않고 오버헤드에 따라 수행 성능이 저하    폴트톨러런스  각 프로세스에서는 master에게 task진행 상태를 주기적으로 보냄 마스터는 워커들의 task 상태 정보를 가지고 있다가 특정 워커가 진행하지 않고 정보를 받지 못하면 task에 문제가 있다고 판정 복구를 할 때 map, reduce task들이 죽은 경우 해당 task가 데이터 정보만 다른 워커에게 전하면 새로운 task를 실행하면 됨. mapreduce는 shared nothing 아키텍쳐  Hadoop MapReduce  아파치 오픈소스 프로젝트, java로 구현 HDFS와 Hadoop MapReduce가 하둡의 핵심 구성요소  아키텍쳐  하둡은 데몬 관점에서 4개의 구성 요소를 가짐     구분 설명     네임노드 하둡을 이루는 필수적인 데몬, 마스터 역할 수행   데이터노드 분산 파일 시스템의 데몬, 데이터 입출력에 대한 처리 수행   잡트래커 시스템에서 job이라는 작업을 관리하는 마스터에 해당   태스크트래커 작업을 수행하는 워커 데몬, 슬레이브에 해당(각 노드에 1개의 태스크 트래커)     클라이언트에서 잡이라 부르는 하둡 작업을 실행 -\u003e 환경 정보들이 jobtracker에 전송 jobtracker는 작업을 다수의 task로 쪼개고 데이터 지역성을 보장하기 위해 task를 어떤 tasktracker에게 보낼지를 감안해 내부적으로 스케줄링해 큐에 저장 이 때 task는 맵퍼나 리듀서가 수행하는 단위 작업 tasktracker는 jobtracker에게 3초에 한 번씩 주기적으로 하트비트 보냄 tasktracker에서 하트비트를 보내면 jobtracker는 할당된 task가 있는지 큐에서 확인 후, 있으면 response메세지에 task정보를 실어 tasktracker에 보냄 tasktracker는 메시지의 내용을 분석해 프로세스를 fork함  실행 절차  스플릿 : 파일 스플릿 생성, 파일 스플릿 하나당 map task 하나씩 생성 맵 : 각 split에 대해 레코드 단위로 map함수 적용, key-value쌍 생성 컴바인 : 리듀스와 동일한 프로그램 적용, 데이터의 크기를 줄임 파티션 : key를 기준으로 데이터를 디스크에 분할 저장, 정렬 수행, 분할된 파일들은 각각 다른 reduce task에 저장 셔플 : 맵퍼들의 결과 파일을 각 리듀서에 할당, 할당된 파일을 로컬 파일 시스템으로 복사 정렬 : 병합 정렬 방식으로 맵퍼의 결과 파일을 key기준으로 정렬 리듀스 : 리듀스 함수 적용   기본적으로 output format은 key,value를 탭으로 구분하며, mapred.textoutputformat.separator 속성을 사용해 구분자를 원하는 문자로 변경할 수 있음 대표적 예제인 WordCount  하둡의 성능, 사용현황  sort : map에서 reduce로 넘어가는 과정에서 항상 발생하는 내부적 프로세스 sort 작업이 데이터가 커질수록 선형적으로 증가 구성 서버를 늘린다고 처리 시간이 줄어들진 않음, 플랫폼이 자체적으로 선형 확장성을 가지고 있어야함 sort는 플랫폼의 성능과 확장성을 동시에 측정할 수 있음     구분 설명     야후 -하둡 프로젝트의 주요 후원자-4만대 이상의 컴퓨터에 하둡 설치, 가장 큰 클러스터는 약 4,500만개의 노드로 구성   야후의 WebMap - 야후의 대표적 그래프 기반 검색 엔진-모든 edge 및 링크 정보를 계산해 결과를 다양한 애플리케이션에서 사용할 수 있도록 해주는 거대한 그래프-100개 이상의 MapReduce 작업들을 체인 형태로 묶어 실행, 압출해서 300TB가 나올 정도를 다루고 있음   국내 - NHN과 다음 등의 포털에서 하둡 사용-삼성SDS, SK등의 IT회사에서 하둡 활용    ---\r병렬 쿼리 시스템 개요\n 일부 사용자들에게는 mapreduce가 쉽지 않음 병렬 처리 시스템 개발, 구글의 sawzall, 야후의 pig 등  구글 Sawzall  MapReduce를 추상화한 최초의 스크립트 형태 병렬 쿼리 언어 MapReduce 생산성을 높임, 쉬운 병렬 프로그래밍 Pig나 Hive도 Sawzall와 유사  아파치 Pig  Hadoop MapReduce 위에서 동작하는 추상화된 병렬 처리 언어, 아파치의 서브 프로젝트 전체 MapReduce작업의 약 30%에 Pig사용  개발 배경\n 실제 대부분의 업무가 한 번의 MapReduce로 끝나진 않음 또한 MapReduce를 이용하는 개발자들이 유사한 알고리즘을 중복 개발하는 경우가 많지만 의미 파악이 어려워 공유는 잘 이루어지지 않음 의미적으로 SQL과 비슷하지만 새로운 언어인 Pig를 정의  사용\n MapReduce는 무공유 구조 -\u003e join연산을 매우 복잡하게 처리(400라인) Pig를 사용하면 10라인으로 가능 검색 인프라, 광고 연관성 분석, 사용자 의도 분석, 검색엔진 쿼리 분석, 호프만 plsi 등 다양한 분야에서 이용  아파치 Hive = 페이스북에서 개발, pig와 마찬가지로 하둡 플랫폼 위에서 동작\n SQL기반 언어와 JDBC지원, Hadoop-Streaming을 쿼리 내부에 삽입해 사용 맵리듀스의 모든 기능을 지원  개발 배경\n 페이스북은 초기에 DBMS기반의 시스템을 운영했으나 데이터가 수백TB규모로 늘어나 관리 및 비용 절감의 필요성 느낌 DBMS를 하둡으로 교체하는 과정에서 필요한 기능들을 하나씩 구현하면서 만들어짐  아키텍쳐\n Metastore는 raw file들의 콘텐츠를 테이블 내 칼럼처럼 구조화된 형태로 관리할 수 있게 해주는 스키마 구조 별도의 DBMS를 설정하지 않으면 Embedded Derby를 기본 DB로 사용 앞 단에는 커멘트 라인 인터페이스(CLI)가 있는데 이걸로 SQL쿼리 사용 파서에서 쿼리를 받아 구문 분석을 하고 Metastore에서 정보를 참조해 Execution Plan을 만든다. Execution Engine은 하둡의 jobtracker와 네임 노드와 통신을 담당하는 창구 역할을 하면서 Mapreduce작업을 실행하고 파일을 관리함 Serde라는 것은 Serilizer와 Deserializer의 줄임말, 테이블의 로우나 칼럶의 구분자 등 저장 포멧을 정의하는 컴포넌트  하이브의 언어모델    DDL DML Query     - 테이블 생성,삭제, 변경 명령-테이블 스키마 변경-테이블, 스키마 조회 -로컬에서 DFS로 데이터 로드-쿼리 결과를 테이블이나 로컬파일 시스템, DFS에 저장 SELECT, GROUP BY, SORT BY, JOINS, SAMPLING, TRANSFORM, SUB QUERIES, UNION     \rSQL on 하둡 개요\n 실시간 처리라는 측면에서 하둡의 제약사항을 극복하기 위한 시도, 실시간 SQL질의 분석 기술 대화형식의 SQL질의를 통해 처리하고 분석  임팔라  SQL on 하둡 기술 중 먼저 대중에게 공개된 기술 분석과 트랜잭션 처리를 모두 지원 하둡과 Hbase에 저장된 데이터를 대상으로 SQL질의를 할 수 있다. 자바 대신 C++사용, 맵리듀스를 사용하지 않고 실행 중 최적화된 코드를 생성해 데이터 처리  임팔라 구성요소    구분 설명     클라이언트 ODBC/JDBC 클라이언트, 임팔라쉘 등에 해당, 임팔라에 접속해 테이블 관리, 데이터 조회 등의 작업 수행   메타스토어 임팔라로 분석할 대상 데이터들의 정보 관리, 하이브의 메타데이터를 같이 사용   임팔라 데몬 시스템에서는 ImpalaD로 표시되며 클라이언트 SQL 질의를 받아서 읽기/쓰기 작업 수행, 질의 실행계획기, 질의 코디네이터, 질의 실행엔진으로 구성   스테이트 스토어 데몬들의 상태 체크하고 건강정보를 관리하는 데몬, 장애가 생기면 다른 데몬들에게 알려서 장애가 발생한 데몬에 질의가 가지 않도록 함   스토리지 분석할 데이터의 저장소, 현재는 Hbase, HDFS 지원    임팔라 동작 방식  모든 노드에 임팔라 데몬이 구동되고 사용자는 구동된 임의의 노드에 JDBC,ODBC, 임팔라쉘을 이용해 질의를 요청할 수 있다. 사용자의 질의는 데이터의 지역성을 고려해 노드 전체로 분산되어 수행 질의 요청을 받은 코디네이터 데몬은 분산되어 수행된 각 임팔라 노드들의 부분 결과를 취합해 결과값을 만들어 사용자에게 제공 실제 운영 환경에서는 라운드 로빈 방식으로 질의를 분산시켜 질의에 대해 전 노드들이 코디네이터 역할을 고르게 수행하도록 해야함  라운드 로빈 : 여러 프로세스들이 돌아가며 처리되는 스케줄링 방식    임팔라 SQL 구문 -임팔라는 기본적으로 하이브의 SQL을 이용하나 모든 하이브 SQL을 지원하는 것은 아니라 어떤 구문이 지원되는지 확인해야함\n   항목 설명     DDL CREATE TABLE/DB, ALTER TABLE, DROP DB/TABLE, SHOW DB/TABLE(조회)   DML SELECT, WHERE, GROUPBY, ORDERBY, INSERT, OVERWRITE (변경,삭제 구문은 지원 안함)   내장 함수 ABS, ACOS(코사인값 반환), DAY, FROM_UNIXTIME, IF, CASE,ASCII, CONCAT    임팔라 데이터 모델  임팔라는 하둡 분산 파일시스템에 데이터를 저장하며, 어떤 저장포맷을 사용하느냐에 따라 처리 성능이 다름     항목 설명     로우 단위 저장 -하둡의 기본 파일 포맷인 텍스트나 시퀀스 파일은 로우 단위 데이터 저장 방식-하나의 칼럼을 읽든 전체를 읽든 동일한 디스크 입출력 발생   칼럼 단위 저장 - 읽고자 하는 칼럼만큼의 디스크 입출력 발생 -\u003e 성능 개선(전체 칼럼을 읽을 땐 개선X)-처리 시간이 로우보다 적게 걸림, 다만 파일이 처음부터 칼럼 파일 포맷을 사용하지 않았을 때 파일 포맷 변경 작업을 해주어야 함칼럼 단위의 파일 저장 포맷인 RCFILE을 사용할 경우, 디스크 입출력 양을 현저하게 줄일 수 있다.    \n클라우드 인프라 기술 클라우드컴퓨팅  가상화 자원들을 인터넷으로 서비스하는 기술 Iaas, SaaS, PaaS의 3유형 Iaas : 네트워크 장비, 서버와 스토리지 같은 IT인프라 자원을 빌려줌 SaaS : 소프트웨어를 웹에서 사용할 수 있게 함 PaaS : 애플리케이션이나 소프트웨어 개발 및 구현 시 필요한 플랫폼 제공 VMware, Xen, KVM등과 같은 서버 가상화 기술은 IaaS에 주로 활용 아마존은 S3, EC2 환경을 제공함으로써 플랫폼을 위한 클라우드 서비스르 최초로 실현, AWS의 EMR은 하둡을 온디맨드로 이용할 수 있는 클라우드 서비스  서버 가상화의 개념 및 특징 정의 : 물리적인 서버와 운영 체제 사이에 적절한 계층을 추가해 사용자에게 물리적인 자원은 숨기고 논리적인 자원만을 보여줌 특징\n 서버 가상화는 하나의 서버에서 여러 애플리케이션, 미들웨어, 운영체제들이 서로 영향을 미치지 않으면서 동시에 사용하도록 함. 서버 가상화를 가능하게 하는 기술은 다양하고 메인프레임, 유닉스서버, X86서버 등에 따라 다른 기술,분류체계가 사용됨  서버 가상화 기술의 효과  가상 머신 사이의 데이터 보호  다른 가상머신들 사이의 접속은 정상적인 네트워크 접속만 허용   예측하지 못한 장애로부터 보호  장애가 다른 가상머신에는 전혀 영향을 미치지 않음   공유자원에 대한 강제 사용의 거부  할당된 자원 이상을 가져가는 것을 차단함, 다른 가상머신에 할당된 자원 부족 현상을 차단함   서버 통합  동일한 데이터 센터의 물리적 자원을 이용하면서 더 많은 서버를 운영할 수 있다.   자원할당에 대한 증가된 유연성  전체 시스템 자원을 재배치해 자원 활용도 극대화   테스팅  새로운 서버를 추가하지 않아도 테스트 환경을 구성할 수 있음.   정확하고 안전한 서버 사이징  사이징 예측이 불확실한 서버르 구성할 때도 일단 확보된 리소스를 이용해 할당 후 쉽게 추가로 할당할 수 있다.   시스템 관리  마이그레이션 기능을 이용할 경우 운영 중인 가상머신의 중지 없이 다른 물리적 서버로 이동시킬 수 있다. 하드웨어 장애, 로드 밸런싱, 업그레이드 업무를 쉽게 수행할 수 있음    CPU 가상화 하이퍼 바이저의 개념 및 특징  물리적 서버 위의 가상화 레이어를 통해 필요한 하드웨어 환경을 가상으로 만듬 하이퍼 바이저 : 호스트 컴퓨터에서 다수의 운영체제를 동시에 실행하기 위한 논리적 플랫폼 일반적인 가상머신은 하이퍼바이저(VMM) X86 계열에선 소프트웨어 기반  기능  하드웨어 환경 에뮬레이션 실행환경 관리 시스템 자원 할당 소프트웨어 스택 보존  하이퍼바이저 관련 기술 분류  플랫폼별 분류 X86 : VMware,MS Virtuall Server, Xen 유닉스 계열 : IBM - POWER Hypervisor 메인 프레임 계열 : z/VM, PR/SM 위치와 기능에 따른 분류   가상화를 제공하는 하이퍼바이저가 물리적 하드웨어 또는 호스트 운영체제와 관계에서 어디 위치하는지에 따라 베어메탈, 호스트 기반으로 나뉨 베어메탈은 하드웨어와 호스트 운영체제 사이에 위치, 호스트는 호스트 운영체제와 게스트 운영체제 사이에 위치 베어메탈은 반가상화, 완전 가상화로 구분  privileged 명령어 처리 방법에 따른 분류   최근에는 새로운 가상화 방법이 계속 나와 정확한 분류가 어려움 x86 운영체제는 모든 하드웨어에 대한 제어 소유권을 가지고 있다는 가정 아래 하드웨어에 직접명령을 수행하는 방식으로 디자인됨 x86 아키텍쳐는 Ring 0,1,2,3 등 4개 레벨로 구성, 운영체제는 0레벨, 사용자는 3레벨 운영체제가 3레벨로 수행될 경우 복잡한 문제 발생 3이 수행된 운영체제에서 0 수준 명령을 호출하면 이를 0 수준의 명령어로 다시 변환해 실행해야함 반가상화, 완전 가상화 용어도 privileged명령어를 어떻게 처리하느냐를 기준으로 분류  가상화 방식 분류  완전 가상화   하이퍼바이저보다 우선 순위가 낮은 가상머신에서는 실행되지 않는 privileged명령어에 대해 trap을 발생시켜 하이퍼바이저에서 실행하는 방식 VMware ESX Server, MS Virtual Server 최근 Xen에서 Intel vt-X, AMD-V환경에서 지원 장점  CPU뿐만 아니라 모든 자원을 하이퍼바이저가 직접 제어,관리하기 때문에 어떤 운영체제라도 수정하지 않고 설치 가능 MS윈도우와 같은 게스트 OS가 변경되지 않은 상태로 실행 가능   단점  하이퍼바이저가 직접 자원 제어 -\u003e 성능에 영향 자원들이 하이퍼 바이저에 너무 밀접하게 연관되어 있어 동적변경 작업이 단일 서버내에는 어려움 동적변경을 하기 위해서는 VMware의 VMotion과 같은 솔루션의 도움을 받아야 함 Para Virtualization에 비해 속도가 느림    하드웨어 지원 완전 가상화   메모리와 CPU 등 하드웨어에 명령을 내릴 수 있는 반가상화 수준의 성능을 발휘 CPU에 Ring-1 계층 추가, 하이퍼바이저가 ring-1에서 수행되고 가성머신의 os는 ring-0에서 수행되어 previleged명령어에 대한 변환과정이 필요없다. 빠른 성능, 윈도우2008의 Hyper-V는 반드시 가상화 지원 CPU만 써야함 인텔에서는 CPU사용률이 높아져 서버 통합을 목적으로 할 경우 비효율적이라고 제시함. 인텔에서 반가상화와 하드웨어 지원 완전 가상화를 모두 사용하는 하이브리드 가상화 제시 Xen의 하이브리드 가상화의 경우 명령어의 종류에 따라 반가상화와 완전 가상화를 선택함  반가상화   previleged 명령어를 게스트 운영체제에서 hypercall로 하이퍼바이저에 전달하고 하이퍼바이저는 hypercall에 대해 previleged 레벨에 상관없이 하드웨어로 명령 수행 hypercall : 게스트 os에서 요청하면 하이퍼바이저에서 바로 명령을 실행하는 call hypercall을 요청하기 위해서는 게스트os 일부분이 수정되어야 함(Xen에서 20% 커널이 수정됨) 반가상화 기반에서는 CPU와 메모리 자원의 동적 변경이 서비스 중단 없이 이루어질 수 있고 완전 가상화보다 성능이 뛰어남. 속도는 빠르나 커널을 변경해야하고 완전 가상화는 커널 변경은 없다. VMware같은 상용 솔루션은 완전 가상화와 반가상황의 단점을 보완해 뚜렷한 차이가 없음 VMI라는 표준 인터페이스를 제시해 모든 게스트OS를 지원하는 체계로 반가상화 지원 VMI는 아직 정식은 아니지만 리눅스 진영에서 도입하려는 움직임이 있음.  Monolithic vs Microkernel   드라이버가 어느 계층에 있느냐로 나뉨     Monolithic 방식 Microkernel 방식     -가상머신이 I/O를 위해 하드웨어에 접근할 때 드라이버를 하이퍼바이저 계층에서 모두 갖고 있는 방식\n-VMware의 경우 하이퍼바이저가 드라이버를 갖고 있고 모든 I/O요청은 하이퍼바이저가 수행\n-성능은 조금 향상될 수 있지만 많은 코드를 가져서 장애가 발생할 가능성이 높다. -I/O를 위해 하드웨어에 접근할 때 드라이버를 각 가상머신에서 가지는 방식\n-Xen에서 하이퍼바이저는 드라이버가 없고 호스트OS가 가지고 있음. I/O 요청을 위해선 호스트OS를 거쳐야 함\n-게스트와 호스트 OS는 서로 격리되어 있어 하이퍼바이저를 이용해 요청을 주고받음\n속도는 느리지만 하이퍼바이저 계층이 간단하여 하이퍼바이저 변경이 필요없고 장애 확률이 낮다.    하이퍼바이저 기반 가상화 기술 비교    구분 완전 가상화\nCPU 기술 이용X 완전 가상화\nCPU 기술 이용 반가상화     사용기술 바이너리 변환\nDirect Execution Privileged Instruction은 Ring-1로 처리 hypercall가능하게 게스트os변경\n호환성 안좋음   게스트os\n반응/호환성 게스트os 변경 없음\n호환성 뛰어남 게스트os 변경 없음\n호환성 뛰어남 hypercall가능하게 게스트os변경\n호환성 안좋음   성능 좋음 Fair\n(바이너리 변환 방식의 성능에 근접) 특정 경우에 좋음   성능 VMware, Microsoft, Parllels VMware,Microsoft,Parllels,Xen VMware,Xen    호스트 기반 가상화   완전한 os가 설치되어 하이퍼바이저가 호스트 os위에 탑재되는 방식 제약 사항이 많고 단일 os의 취약성이 있다.(신뢰성 문제) VMware, Workstation, Microsoft Virtual PC 테스트용 환경, 최근 사용x  컨테이너 기반 가상화   운영체제만을 가상화한 방식 가상화 지원계층을 하이퍼바이저가 아닌 가상 운영환경이라 부름 Virtuozzo, Solaris Containers, Linux-VServer 장점  하이퍼바이저 가상화 방식에 비해 훨씬 적게 가상화 가상화 수준이 낮아 빠른 성능 한 대의 서버에서 더 많은 컨테이너를 실행할 수 있음   단점  격리 수준이 낮아 다른 가상 운영체제가 영향받음 보안 취약성에 의해 모든 가상 os에 문제가 생길 수 있음 호스트os를 공유하기 때문에 호스트 os문제가 전체 가상 os에도 영향 미침    메모리 가상화 : VMware 기법 개념\n 가상의 공간을 만들어주는 프로그램 물리주소 : 0부터 실제 물리적인 메모리 크기까지를 나타냄 가상주소 : 하나의 프로세스가 가리킬 수 있는 최대 크기(32비트에서 4GB) 프로그램에서 주소는 가상주소값 -\u003e 가상주소값 위치와 물리적 주소값 위치 매핑 과정 필요 TLB : 매핑 연산을 하드웨어적으로 도와주는 것 하이퍼바이저 내에 Shadow Page Table을 따로 두어 중간 변환 과정을 가로챔 모든 가상머신들이 자신만의 메모리 주소 공간을 갖도록 함 메모리 할당 문제를 해결해야함  가상머신 메모리 할당의 문제 해결 방법  Memory ballooning  VMkernel은 가상머신의 메모리 영역을 빈 값으로 강제로 채워 가상머신os가 자체적으로 swapping하도록 함 물리적인 메모리가 채워지고 있다는 것을 감지한 가상머신os는 swap파일에 메모리 영역을 page out시키고 자리를 비우게 됨. 하이퍼바이저는 page out된 메모리 영역을 다른 가상머신에 할당함   Transparent page sharing  하나의 물리적 머신에 여러 개의 가상머신이 운영되는 경우 각 가상머신에 할당된 메모리 중 동일한 내용을 담고 있는 페이지는 물리적 메모리 영역에 하나만 존재시키고 모든 가상머신이 공유하도록 함   Memory Overcommitment  2GB 메모리를 가진 물리적 장비에 512GB를 Mininum reserved를 가질 수 있는 가상머신 5개를 수행할 수 있음 앞의 2가지 기법으로 가능하지만 모든 가상머신이 메모리 사용이 많은 업무를 수행하는 경우면 심각한 성능저하 현상이 발생할 수 있어 권장하진 않음.    I/O가상화  I/O병목현상이 가장 문제가 됨 -\u003e I/O자원의 공유 및 파티셔닝이 필요 또한 가상머신 간에도 통신이 이루어져야 함. 이를 위해 다양한 기술이 사용  이더넷 : IEEE가 표준 사양으로 택한 LAN에 사용되는 모델로 근거리 통신망 하드웨어, 프로토콜, 케이블 표준      가상 이더넷\n 가상 이더넷은 물리적으로 존재하지 않는 자원을 만들어내는 에뮬레이션 기능 사용 각 가상머신 사이에 네트워크 어댑터 없이도 메모리 버스를 통해 고속 및 고효율 통신이 가능 가상 LAN기술을 기반으로 한 네트워크 파티션도 가능하게 함, 각 가상 LAN 사이에는 통신을 할 수 없음 사용자들은 별도의 물리적 어댑터와 케이블을 사용하지 않고도 네트워크 이중화, 네트워크 안전성 단절 등의 효과를 얻을 수 있음    공유 이더넷 어댑터\n 여러 개의 가상머신이 물리적 네트워크 카드를 공유할 수 있게 하고 외부 네트워크와 통신이 가능하게 함 가상 머신 개수보다 물리적 어댑터 개수가 적은 경우 가상머신들이 물리적 이더넷 어댑터를 공유할 수 있게 해줌 하나 자원을 여러 가상 머신이 공유해 병목현상을 피할 수 없음 최근에는 네트워크 어댑터 내에서 가상화를 지원하게 함    가상 디스크 어댑터\n 파이버 채널 어댑터와 같은 I/O어댑터의 부족    가상화된 환경에서 가상 디스크를 이용해 가상머신이 디스크 자원을 획득하는 방법\n   내장 디스크 외장 디스크     -가상 I/O레이어가 내장 디스크를 소유하고 있고 이 것을 논리적 디스크 드라이브로 나눈다.\n-나누어진 드라이버는 LUN으로 각 파티션에 가상 디스크 어댑터를 통해 분배됨\n-이렇게 획득한 논리적 디스크 자원을 물리적 자원처럼 인식 -먼저 가상 I/O레이어가 파이버 채널 어댑터를 통해서 외장 디스크의 LUN을 획득\n-내장 디스크와 달리 가상 I/O레이어가 바로 각 가상머신에 가상 디스크 어댑터를 통해 분배\n-가상 I/O레이어를 통해 제공도니 논리적 디스크 볼륨은 이를 이용하는 다른 가상머신에게는 SCSI 디스크로 나타냄    ","description":"","tags":null,"title":"ADP 공부하기 8","uri":"/posts/certificate/2020-01-30-adp_study8/"},{"categories":["Certificate"],"content":"데이터 처리 기술 분산 파일 시스템 개요  저장 기술은 분산 파일시스템, 클러스터, DB, NOSQL로 구분됨 사용자 중심의 인터넷 서비스와 유비쿼터스 컴퓨팅 환경은 대규모 클러스터 시스템 플랫폼의 필요성을 부각시킴. 최근에는 파일의 메타데이터를 관리하는 전용 서버를 가지고 있는 ‘비대칭형 클러스터 파일 시스템’이 활발히 개발  구글 파일 시스템 (GFS) 개념\n GFS는 구글의 대규모 클러스터 서비스 플랫폼의 기반이 되는 파일 시스템 파일을 고정된 크기(64MB)의 CHUNK들로 나누고 각 CHUNK에 대한 여러 개의 복제본과 CHUNK를 청크서버에 분산저장함 기본 64MB로 정하고 해시 테이블 구조 사용 -\u003e 효율적인 메타데이터 처리 지원 CHUNK는 마스터에 의해 생성/삭제, 유일한 식별자에 의해 구분됨  GFS 설계의가정  서버의 고장이 빈번히 발생할 수 있다 가정 작업 부하는 주로 연속적으로 많은 데이터를 읽는 연산이거나 임의의 영역에서 적은 데이터를 읽는 연산에서 발생 쓰기 연산은 주로 순차적으로 이루어지며, 갱신은 드물게 이루어짐 동기화 오버헤드를 최소화할 수 있는 방법이 요구됨 낮은 응답 지연시간보다 높은 처리율 중요  GFS 구성요소  여러 클라이언트, 하나의 마스터 청크서버들     클라이언트 - 파일에 대한 읽기 쓰기 동작을 요청하는 애플리캐이션, POSIX인터페이스를 지원하지 않고 자체 인터페이스 지원- 원자적인 데이터 추가 연산을 지원하기 위한 인터페이스 지원     마스터 - 단일 마스터 구조, 이름 공간, 파일과 CHUNK의 매핑정보, 청크서버들의 위처정보 등의 모든 메타데이터를 메모리상에서 관리- 청크서버의 하트비트 메시지를 이용해 CHUNK의 상태에 따라 CHUNK를 재복제하거나 재분산하는 것 같은 회복동작 수행- 하나의 청크서버를 primary로 지정해 복제본의 갱신 연산을 일관되게 처리 가능- 마스터에 대한 장애 처리와 회복을 위해 이름 공간과 매핑 변경 연산을 로깅하고 마스터의 상태를 여러 셰도 마스터에 복제   청크서버 - 로컬 디스크에 CHUNK 저장,관리 클라이언트로부터 CHUNK 입출력 요청 처리- 하트비트 메세지를 통해 청크서버의 상태에 대한 정보를 주기적으로 마스터에게 전달    GFS에서 파일 읽기  클라이언트는 파일에 접근하기 위해 마스터로부터 해당 파일의 CHUNK가 저장된 CHUNK 서버의 위치와 핸들을 받아온 뒤, 직접 청크서버에 파일 데이터를 요청  하둡 분산 파일 시스템(HDFS) 개념 : 아파치 너치의 파일 시스템으로 개발, 클로닝 프로젝트\n 마스터와 유사한 네임노드, 청크서버와 유사한 데이터 노드 HDFS에서 파일 데이터는 블록 단위 , 여러 데이터 노드에 분산,복제,저장됨 파일은 한번 쓰이면 변경되지 않는다고 가정 순차적 스트리밍 방식 낮은 응답 지연시간보다 높은 처리량 중요 통신을 위해 TCP/IP에서 RPC사용  HDFS 구성 요소    네임 노드 - 파일 시스템의 이름 공간 등 HDFS 상의 모든 메타 데이터를 관리, 마스터 역할- 파일이 블록 단위로 나누어져 있고 어떤 노드에 특정 블록이 있는지 시스템 전반 상태를 모니터링- 데이터 저장, 애플리케이션 실행은 하지 않음-클라이언트로부터 파일 접근 요청 처리-데이터노드로부터 하트비트를 받아 상태체크, 블록 정보를 가지고 블록 상태 체크     데이터 노드 - HDFS의 ㅡ슬레이브 노드, 데이터 입출력 요청 처리- 데이터 유실을 방지하기 위해 3중 복제 저장-파일의 체크섬 정보를 별도 저장-주기적으로 데이터노드의 상태를 나타내는 하트비트와 자신이 관리하는 블록의 목록인 blockreport를 네임노드에 전송   보조네임노드 - HDFS 상태 모니터링을 보조- 주기적으로 네임 노드의 파일 시스템 이미지를 스냅샷해 생성    \rHDFS 파일 저장 과정  64MB, 128MB 단위의 블록으로 분리 첫 번째 데이터노트로부터 세 번째 데이터노드까지 저장 완료 -\u003e 각 데이터 노드들은 순차적으로 클라이언트에게 저장이 완료되었다는 신호를 보냄 모든 블록의 저장이 완료될 때까지 반복 모든 블록의 저장이 완료되면 네임노드는 블록들이 저장된 데이터노드의 주소(메타데이터) 저장  HDFS 파일 읽기 과정  클라이언트가 읽고자 하는 파일의 정보를 네임노드에게 요청 네임노드는 모든 블록의 목록과 블록이 저장된 데이터 노드의 위치를 클라이언트에 반환  러스터 개념\n 클러스터 파일 시스템에서 개발한 객체 기반 클러스터 파일 시스템 고속 네트워크 연결 클라이언트 파일 시스템, 메타데이터 서버, 객체 저장서버들로 구성 계층화된 모듈 구조, TCP/IP, 인피니밴드, 미리넷과 같은 네트워크 지원  구성요소    클라이언트 파일시스템 - 리눅스 VFS에서 설치할 수 있는 파일 시스템- 메타데이터 서버와 객체 저장 서버들가 통신하며 클라이언트 응용에 파일 시스템 인터페이스 제공     메타데이터 서버 - 파일 시스템의 이름 공간과 파일에 대한 메타데이터 분리   객체 저장 서버 - 파일 데이터 저장, 클라이언트로부터 객체 입출력 요청 처리- 데이터는 세그먼트라는 작은 단위로 분할해 복수의 디스크 장치에 분산시키는 ‘스트라이핑 방식’    구동 방식\n 라이트백 캐시 지원 클라이언트에서 메타데이터 변경에 대한 갱신 레코드 생성, 나중에 메타데이터 서버에 전달 메타데이터서버는 전달된 갱신 레코드를 재수행해 변경된 메타데이터를 반영 클라이언트에서 라이트백 캐시 지원, 메타데이터 서버에서 메타데이터를 처리하는 방식을 적용 동시 접근이 적으면 클라이언트 캐시를 위용한 라이트백 캐시 사용, 많으면 클라이언트 캐시 사용 -\u003e 오버헤드 줄임 동시성 제어를 위해 별도의 잠금 사용 인텐트 기반 잠금 프로토콜 : 네트워크 트래픽 최소화 위해 잠금 요청 시 접근 의도를 같이 전달  라이트백 캐시 : 데이터를 캐시에만 저장하고 어쩔 수 없이 캐시영역에서 밀려나는 경우 하위저장소에 저장    데이터베이스 클러스터 개념\n 하나의 DB를 여러 개의 서버 상에 구축 파티셔닝 : DB를 여러 부분 분할, 분할된 요소는 파티션 각 파티션은 트랜잭션 수행 데이터를 통합할 때 성능과 가용성의 향상을 위해 데이터베이스 차원의 파티셔닝 또는 클러스터링 이용  효과    병렬처리 파티션 사이의 병렬 처리를 통한 빠른 데이터 검색 및 성능     고가용성 특정 파티션에서 장애가 발생해도 서비스가 중단되지 않음   성능 향상 성능의 선형적인 증가효과    데이터 베이스 클러스터의 구분 형태에 따라 단일 서버 내 파티셔닝과 다중 서버 사이의 파티셔닝으로 구분 리스크 공유 관점에서는 공유 디스크, 무공유 디스크로 구분\n무공유 디스크\n 무공유 클러스터에서 각 DB 인스턴스는 자신이 관리하는 파일을 자신의 로컬 디스크에 저장, 노드 간 이 파일들은 공유X 각 인스턴스나 노드는 완전히 분리된 데이터 서브 집합에 대한 소유권을 가짐, 소유권을 가진 인스턴스가 처리 노드가 처리 요청을 받으면 데이터를 가진 노드에 신호를 보냄 Oracle RAC을 제외한 대부분 DB 클러스터가 무공유 방식 장점 : 노드 확장 제한X 단점 : 장애가 발생할 경우를 대비해 별도의 폴트톨러런스 구성  폴트 톨러런스 : 고장이 발생해도 일부를 유지하는 기술    공유 디스크\n 파일은 논리적으로 모든 DB 인스턴스 노드들은 논리적으로 공유, 각 인스턴스는 모든 데이터에 접근할수 있다 공유하려면 SAN과 같은 네트워크가 있어야함 모든 노드가 데이터를 수정할 수 있음 -\u003e 별도의 커뮤니케이션 채널 필요 장점 : 높은 수준의 폴트톨러런스 제공 -\u003e 하나의 노드만 살아도 서비스 가능 단점 : 클러스터가 커지면 디스크 영역에서 병목현상 발생  데이터 베이스 클러스터 종류   Oracle RAC DB 서버\n 공유 클러스터, 모든 노드에서 실행 특정 노드가 데이터를 소유하는 개념이 없다 파티셔닝 필요X, 하지만 성능 향상을 위해 하는 경우 빈번 응용 프로그램은 RAC클러스터에 연결, RAC는 클러스터 모든 노드에 로드를 고르게 분산 장점 : 가용성, 확장성, 비용 절감    IBM DB2 ICE\n 무공유 클러스터 데이터가 어느 파티션에 존재하는지 알 필요가 없다. 데이터와 사용자가 증가해도 시스템의 성능과 용량을 일정하게 유지할 수 있다. 파티셔닝 구성에 따라 성능 차이가 있다 별도의 페일오버 메커니즘 필요 -\u003e DB2를 이용해 클러스터링 구성할 때는 공유 디스크 방식 사용해 가용성 보장 장애 상황이 발생하면 다른 노드가 해당 데이터에 대한 서비스를 처리하는 방식  페일오버 : DB의 최신 버전을 백업해두어 장애가 발생했을 때 장애 극복      마이크로소프트 SQL 서버\n 연합 DB 형태 -\u003e 여러 노드로 확장 기능 독립된 서버에서 실행되는 다른 DB간 결합 수평 분할, 모든 파티션에 대해 UNION ALL로 논리적인 뷰(DPV)를 구성 마이크로 소프트 SQL 서버 구성 문제점  DBA개발자가 파티셔닝 정책에 맞게 테이블과 뷰를 생성해야됨 전역 스키마 정보가 없어서 모든 노드를 액세스해야 함 노드가 많아지거나 노드의 추가/삭제가 발생할 경우 파티션을 새로 구성해야함 페일오에 대해 별도로 파티션 구성해야함   Active-Standby 방법 사용    MySQL\n 비공유형, 메모리 기반 DB 클러스터링 지원 병렬 서버구조 확장 가능, 관리 노드, 데이터 노드, MySQL노드로 구성 관리 노드 : 클러스터 관리, 시작과 재구성 시에만 관여 데이터 노드 : 클러스터의 데이터 저장 MySQL 노드 : 클러스터 데이터에 접근을 지원 가용성을 높이기 위해 다른 노드에 데이터를 복제 복구되어 투입되어도 기존 데이터와 변경된 데이터에 대한 동기화 작업이 자동 수행 동기화 방식 복제 -\u003e 데이터 노드 간 별도의 네트워크를 구성 최근 버전에서는 디스크 기반 클러스터링, 인덱스가 생성된 칼럼은 기존과 동일하게 메모리에 유지, 생성하지 않은 칼럼은 디스크에 저장  제한 사항\n LINEAR KEY 파티셔닝만 가능 클러스터 참여 노드 수는 255로 제한, 데이터 노드는 최대 48개 문제가 발생하면 트랜잭션 이전으로 롤백해야함 여러 개 트랜잭션으로 분리해 처리하는 게 좋음 칼럼명 길이 31자,, 테이블명 길이 122자, 메타데이터 2만320개 클러스터 테이블 2만 320개, 로우 8KB, 테이블 키 32개 최대 모든 클러스터 기종은 동일해야 함. 운영 중 노드를 추가 삭제할 수 없다. 디스크 기반일 경우 tablespace $2^{32}$, tablespace당 파일 개수 $2^{16}$ 파일 크기 32GB    NoSQL 개념\n 분산 데이터베이스 기술, 비관계형 DB 관리 시스템 구조에 따라 key-value, Document, Graph, Column 모델로 구분 key, value의 형태 자료저장 스키마 없이 작동, 구조 정의 변경 없이 추가 가능 join 지원X, 대규모 수평적 확장성 대부분이 오픈 소스 구글 빅테이블, 아파치 base, 아마존 SimpleDB, 마이크로소프트 SSDS   구글 빅테이블 개념   구글의 개발, 공유 디스크 방식 모든 노드가 데이터 인덱스 파일 공유 유사한 솔루션 : Neptune  모델\n 모든 데이터는 row-key의 사전적 순서로 정렬,저장 파티션도 row-key로 이루어지고 Tablet이라 불리는 파티션은 분산된 노드에서 서비스됨 100~200MB row는 n개의 column-family를 가질 수 있고 column-key, value, time stamp형태로 데이터 저장 동일한 column-key에 대해 timestamp가 다른 여러 버전의 값이 존재할 수 있음 빅테이블 정렬 기준은 ‘rowkey + column-key + timestamp’  페일오버\n 장애가 발생할 때 Tablet을 다른 노드로 재할당, GFS에 저장된 것을 이용해 초기화 작업 수행 후 다시 서비스를 함 SPOF는 마스터다 분산 락 서비스를 제공하는 Chubby를 이용해 마스터를 모니터링 하다가 장애가 발생하면 가용한 노드가 마스터 역할을 함 Chubby는 폴트톨러런스 구조라 절대 장애 발생하지 않음 빅테이블은 별도 클러스터 구성하기 보다는 파일시스템, 맵리듀스 컴퓨팅 클러스터와 동일한 클러스터 위에 구성됨  AppEngine\n 구글 클라우드 플랫폼의 일부, 빅테이블 사용 추상 계층을 두고 API 직접 공개x, 데이터 모델도 추상화 생성되는 것이 아닌 특정 한 테이블에 대한 한 영역만 차지하게 됨 쿼리를 분석해 자동으로 인덱스 생성 인덱스가 빅테이블의 특정 테이블, 테이블 내 칼럼으로 저장됨  \rHBASE   HDFS를 기반으로 구현된 칼럼 기반 분산 데이터베이스 관계형 구조X, SQL 지원X 비구조화된 데이터에 적합, 실시간 읽기/쓰기에 용이 선형 확장 가능 구조, 복제 기능, 수평적 확장성 큰 테이블에 적합, 트랜잭션 보장, Zookeeper를 이용한 고가용성  아마존 SimpleDB   아마존의 다른 플랫폼 서비스와 같이 사용 사용자는 EC2에서 수행되는 웹 서버로 접근하고 웹 서버에서 SimpleDB의 데이터를 조회해 적절하게 가공 후 사용자에게 제공 관계형, SQL 지원 X, 전용 쿼리 언어 사용 데이터 모델은 Domain, Item, Attribute, Value로 구성, 스키마 없음     도메인 테이블과 동일한 개념, 최대 10GB 저장, 100개 도메인 최대1000GB데이터 저장 가능     Item 레코드와 동일한 개념, 독립적 객체, 1개이상 256개 이하 어트리뷰트 가짐   Attribute 칼럼과 동일한 개념, 정의할 필요가 았음\n특정 어트리뷰트에는 여러개의 값 저장 가능     한 번에 하나의 도메인에 대해서만 쿼리 수행해야 함 1:N관계의 모델을 갖는 두 개의 도메인으로부터 조회할 경우 쿼리가 여러번 수행되어야 함 다음과 같은 API 제공     CreateDomain 도메인 생성     DeleteDomain 도메인 삭제   ListDomains 모든 도메인 목록 가져옴   PutAttributes 아이템 생성후 Attributes에 값 추가   DeleteAttributes Attributes값 삭제   GetAttributes Attributes값 조회   Query 쿼리를 이용하여 조건에 맞는 아이템 조회\n5초 이내 수행되어야하고 최대 item수는 256개    마이크로소프트 SSDS   컨테이너, 엔티티로 구성 컨테이너 : 테이블과 유사한 개념, 하나의 컨테이너에 여러 종류의 엔티티 저장 가능 엔티티 : 레코드 유사 개념, 여러개의 property 가질 수 있음. property는 name-value 쌍으로 지정 정보를 하나의 컨테이너에 저장 이런 방식으로 컨테이너를 구성하면 많은 컨테이너가 생성됨, 이들은 여러 노드에 분산, 관리됨 쿼리는 하나의 컨테이너만을 대상으로 함 컨테이너 생성,삭제 엔티티의 생성, 삭제 , 조회, 쿼리 등의 API를 제공, SOAP/REST 기반 프로토콜을 지원  ","description":"","tags":null,"title":"ADP 공부하기 7","uri":"/posts/certificate/2020-01-29-adp_study7/"},{"categories":["Certificate"],"content":"데이터 처리 프로세스 데이터 통합 및 연계 기법 데이터 연계 및 통합 유형(동기화 기준)   연계 통합시 일괄(BATCH) 작업, 비동기식 근접 실시간(NRT), 또는 동기 실시간 방식 혼용\n  실시간 통합 : 관심 대상 영역 상태에 대한 빠른 파악 및 대응 가능\n  일괄 작업 : ETL기능을 통해 정기적,반복적으로 대량의 데이터를 획득해 ODS 구성, 이후 데이터 웨어하우스나 마트를 구성 후 OLAP 정형/비정형 질의를 통해 경영 분석\n  동기식 실시간 데이터 통합 : 생산 및 운송 장비 센서들로부터 데이터를 실시간으로 획득해 상태를 모니터링, 작업을 통제(Complex event Processing)\n  최근 데이터 중복을 허용하는 분산 저장 환경구성을 통해 높은 확장성을 확보하는 빅데이터 저장 인프라스트럭처의 활용과 병행 설계되는 사례도 등장\n  ETL기술은 최근 ODS,MDM 허브, 플랫폼, 하둡, 클라우드 환경 등 다양한 데이터 통합 메커니즘 지원\n  최근 비정형, 준정형 데이터 중요성 부각 -\u003e 정형 데이터로 변환은 빅데이터의 주요한 기술적 특성\n  빅데이터 기술을 사용하지 않으면 확장성과 유연성을 확보하기 어려움, 기업 IT투자를 중장기적으로 보호할 수 없음.\n  대용량의 비정형 데이터 로그  로그는 기업의 대표적 비정형 데이터 수집 시스템 : 아파치 Flume-NG,Chukwa, 페이스북 Scrive  대용량 비정형 데이터 수집 시스템 특징   초고속 수집 성능과 확장성\n 실시간으로 발생하는 대용량 데이터를 놓치지 않고 수집, 서버 수만큼 에이전트 수를 늘리는 방식으로 쉽게 확장    데이터 전송 보장 메커니즘\n 수집된 데이터는 분산 파일시스템, DB, NoSQL 등에 저장, 전송 안정성 수준 제어 가능 여러 단계를 거치는데 단계별로 신호를 주고 받아 이벤트의 유실 방지 각 방식은 성능과 안정성이라는 트레이드 오프가 존재    다양한 수집과 저장 플러그 인\n 데이터 저장소의 경우 하둡 저장 기능, NoSQL을 포함한 다양한 DB저장 플러그인 제공    인터페이스 상속을 통한 애플리케이션 확장\n 비즈니스 용도에 맞게 수정할 수 있어야 한다.     \r대규모 분산 처리 하둡  MapReduce시스템과 HDFS를 핵심 구성요소로 가짐 여러 대의 컴퓨터를 하나의 시스템인 것처럼 묶어 빅데이터를 저장 처리하는 자바 기반 오픈소스 프레임워크 수십GB에서 수십TB에 이르거나 대규모의 컴퓨팅 및 연산 작업이 필요하다면 하둡 사용 비공유 분산 아키텍처 제공  하둡 특징  선형적인 성능과 용량 확장  여러 대의 서버로 클러스터를 만들어 하둡을 구축할 때 서버의 대수에 제한 없고, 최소 5개 비공유 분산 아키텍처 시스템 서버를 추가하면 연산 기능과 저장 기능이 서버의 대수에 비례   고장 감내성  HDFS에 저장되는 데이터는 3중복제가 되어 데이터 유실 방지 맵리듀스 작업 중 장애가 생기면 장애가 발생한 특정 테스크만 재실행 가능   핵심 비즈니스 로직에 집중  맵리듀스는 맵과 리듀스라는 2개의 함수만 구현 알고리즘 및 비즈니스 로직 개발자는 분석 방식만 이해하고 목적에 맞게 간단한 코드만 작성하면 데이터의 대소에 신경 안써도됨 오직 비즈니스 로직에 집중하도록 장애에 자동복구, 확장성 및 성능도 하둡이 내부적으로 최적화함   풍부한 에코시스템  zookeeper: 서버들 간에 상호 조정이 필요한 다양한 서비스 제공 oozie : 작업을 관리하는 WORKFLOW 및 코디네이터 시스템 Hbase : HDFS 기반의 컬럼 NoSQL Pig : 복잡한 맵리듀스 프로그래밍을 대체할 Pig Latin 제공 Hive : 데이터 웨어하우스, 테이블 단위 저장, SQL쿼리 지원 Mahout : 데이터 마이닝 알고리즘을 구현한 오픈 소스 라이브러리 Hcatalog : 테이블 및 스토리지 관리 Avro : RPC와 데이터 직렬화를 지원하는 프레임 워크   RPC(Remote Procedure Call)  Chukwa : 분산 환경에서 생성된 데이터를 HDFS에 안정적으로 저장하는 플랫폼 Flume : 소스서버에 에이전트가 설치, 에이전트로부터 데이터를 전달받는 콜렉터로 구성 Scribe : 페북에서 개발된 수집 플랫폼, Chukwa와 달리 중앙집중서버로 전송 Sqoop : 대용량 데이터 전송 솔루션, HDFS, RDBMS, DW, NoSQL 등 다양한 저장소에 신속하게 전송할 수 있는 방법 제공 Hiho : Sqoop과 같은 대용량 데이터 전송 솔루션, SQL지정, JDBC 이넡페이스 지원     다양한 응용기술들이 오픈소스 프로젝트의 형태로 제공, 이를 바탕으로 하둡 에코시스템 구성 맵리듀스와 HDFS는 빅데이터 처리와 분산을 위한 기반 기술로 에코시스템의 코어 프로젝트 YARN은 맵리듀스의 단점을 극복하기 위해 하둡2.0부터 제공되는 프로젝트로 자원 관리 프레임워크 지원 Flume-NG : 데이터가 발생하는 애플리케이션 단계, 데이터 수집, 데이터 저장, 저장소 보관 단계로 이루어져 설정하지 않으면 네번째 단계는 하둡이 저장소로 사용  \r데이터 연동 개요 : DB를 대상으로 대규모 분산 처리를 하는 것은 심한 부하를 야기 -\u003e 데이터를 하둡으로 복사 후 하둡에 대규모 분산 처리를 함 이 때 데이터 연동 기능을 수행하는 대표적인 오픈 소스 솔루션이 Sqoop\nSqoop  MYSAL, PostgreSQL, 사이베이스 등 JDBC를 지원하는 대부분의 관계형 DB와의 연동 지원 일부 NOSQL DB와도 연동 가능 맵 인풋 포맷터 사용 데이터 이동을 맵리듀스로 처리, 장애 허용 능력과 병렬 처리 기능 IMPORT명령어로 RDBMS의 데이터를 HDFS로 옮기고 EXPORT명령어로 HDFS의 데이터를 RDBMS로 옮길 수 있다. 스크립트 문법을 이용해 하둡의 결과 데이터를 다시 관계형 DB로 적재할 수 있다.  대용량 질의 기술 개요 : 친숙한 SQL을 이용해 쉽게 처리하고 분석하는 HIVE 등장 하둡과 하이브는 대용량 데이터를 배치 처리하는데 최적화되어 있지만 실제 업무에서는 데이터를 실시간으로 조회하거나 처리해야 하는 요구사항이 많음 -\u003e 실시간 SQL 질의 분석 기술인 SQL on 하둡 등장\n스쿱 스크립트  데이터를 가져올 데이터베이스 정보 입력 데이터에 대한 SQL 입력 동시에 몇 개의 프로세스를 실행하여 데이터를 가져올지 지정, 적절한 개수 지정해야 함 데이터 베이스의 키 칼럼 입력 가져운 데이터를 저장할 하둡상의 경로 지정  -- connect jbbc:mysql://192.168.10.100:3306/sakila\r-- username Hadoop\r-- password hadoop00\r- query 'select * from city where city like 'k%' '\r# k로 시작하는 행에 대한 모든 열을 출력\r- m2\r- split-by city_id\r- target-dir/user/hadoop\rSQL on 하둡  아파치 드릴 : 맵알이 주축인 프로젝트, 드레멜의 아키텍처와 기능을 동일하게 구현한 오픈 소스 버전 드레멜 아파치 스팅거 : 호튼웍스에서 개발, 기존의 하이브 코드 최대한 이용 임팔라 : 클라우데라에서 개발 주도 샤크 : 인메모리 기반의 대용량 데이터웨어하우스 시스템, 하이브와 호환 아파치 타조 : 고려대 대학원에서 시작, 그루터가 합류해 개발 진행 호크 : EWC에서 분사한 피보탈에서 개발, 상용과 커뮤니티 2가지 버전 프레스토 : 페북에서 개발, 데이터웨어 하우징 엔진, 아파치 라이선스로 공개됨  ","description":"","tags":null,"title":"ADP 공부하기 6","uri":"/posts/certificate/2020-01-28-adp_study6/"},{"categories":["Certificate"],"content":"데이터 처리 프로세스 ETL  데이터의 이동 및 변환 절차와 관련된 용어 데이터 스토어, 웨어하우스, 마트 등에 데이터를 적재 데이터 통합, 이동, 마스터 데이터 관리(MDM)에 활용, 이동과 변환이 목적 대용량 데이터 처리(MPP) 다수 시스템 간 대용량 데이터 교환 Batch, ETL, Real Time등으로 구분  ETL 기능 Extraction : 데이터 소스로부터 데이터 획득 Transformation : 데이터 클렌징, 변한, 형식 변환, 표준화, 통합 등의 비즈니스 룰 Loading : 변형이 완료된 데이터를 특정 시스템에 적재\nETL 작업 단계    step 0\ninterface 다양한 이기종 dbms 및 스프레드시트 등 데이터 소스로부터 데이터를 획득하기 위한 인터페이스 메커니즘 구현     step 1\nStaging ETL 일정에 따라 소스로부터 트랜잭션 데이터 획득 작업 후 획득된 데이터를 스테이징 테이블에 저장   step 2\nProfiling ETL 스테이징 테이블에서 데이터 특성을 식별하고 품질 측정   step 3\nCleansing ETL 다양한 규칙들을 활용해 프로파일링된 데이터의 보정 작업 수행   step 4\nIntegraion ETL 이름, 값, 구조 데이터 충돌을 해소하고 클렌징된 데이터를 통합   step 5\nDemoralizing ETL 운영 보고서 생성, 데이터 웨어하우스, 마트에 대한 데이터 적재를 위해 비정규화 수행     ODS 구성  ODS는 데이터에 대한 추가 작업을 위해 다양한 데이터 소스로부터 데이터를 추출, 통합한 데이터베이스 ODS 내 데이터는 타 정보 시스템이나 데이터 웨어하우스로 이관 ODS를 위한 데이터 통합은 데이터 클렌징, 중복제거, 비즈니스 룰 대비 데이터 무결성 점검의 작업이 포함 일반적으로 Real Time, Near Real Time 트랜잭션 데이터 혹은 가격 등의 원자성을 지닌 하위 수준 데이터를 저장하기 위해 설계  ODS구성 단계  인터페이스 단계   데이터를 획득하는 단계 프로토콜 : OLEDB, ODBC, FTP 등이 사용 데이터 웨어하우스에 대한 RT, NRT OLAP질의를 지원하기 위해 실시간 데이터 복제 인터페이스 기술들이 함께 활용  OLAP : 데이터 웨어하우스 상의 데이터에 대해 다양한 방식으로 다차원 분석 진행\n데이터 스테이징 단계   데이터 소스로부터 트랜잭션 데이터들이 추출되어 하나 또는 그 이상의 스테이징 테이블들에 저장 정규화가 배제되고 스키마는 소스의 구조에 의존적이다. 소스와 스테이징 테이블과의 데이터 매핑은 일대다, 일대일 구조 적재 타임스탬프, 데이터 값에 대한 체크 섬 등의 통제 정보가 추가 다양한 데이터 소스로부터 데이터를 획득해 스테이징 테이블에 적재, 이 때 일괄(BATCH)작업 형태인 정기적 ETL과 실시간 ETL을 혼용할 수 있음.  데이터 프로파일링 단계   데이터 품질 점검의 단계 스테이징 테이블 데이터에 대한 프로파일링 수행 -\u003e 결과 통계 처리 -\u003e 품질 보고서 생성 및 공유  데이터 클렌징 단계   프로파일링 단계에서 식별된 오류 데이터 수정 단계 클렌징 스토어드 프로시저 실행 -\u003e 클렌징 ETL 도구 실행  데이터 인티그레이션 단계   수정 완료한 데이터를 ODS 내의 단일 통합 테이블에 적재 통합 스토어드 프로시저 실행 -\u003e 통합 ETL 도구 실행  익스포트 단계   익스포트 ETL기능을 수행해 익스포트 테이블 생성 다양한 DBMS 클라이언트, 데이터 마트, 웨어하우스에 익스포트 테이블 적재 해당 데이터는 OLAP 비정형 질의에 활용될 수 있음.   데이터 웨어하우스 ODS를 통해 정제, 통합된 데이터가 분석과 보고서 생성을 위해 적재되는 데이터 저장소\n특징\n   주제 중심성\nSubject Oriented 데이터 웨어하우스의 데이터는 실 업무 상황의 특정 이벤트나 업무 항목을 기준으로 구조화 되므로, 최종사용자도 이해하기 쉬운 형태     영속성, 비휘발성\nNON Volatile 최초 저장 이후에는 읽기 전용의 속성, 삭제되지 않는다.   통합성\nIntegrated 기관,조직이 보유한 대부분의 운영 시스템에 의해 생성된 데이터들의 통합본임   시계열성\nTime Variant 운영 시스템은 최신 데이터르 보유하지만 데이터 웨어하우스는 시간 순에 의한 이력 데이터 보유    데이터 웨어하우스의 테이블 모델링 기법  스타 스키마    조인 스키마, 가장 단순\n  단일 사실 테이블을 중심으로 다수의 차원 테이블로 이루어짐\n  전통적인 관계형 데이터베이스를 통해 다차원 데이터베이스 기능 구현\n  사실 테이블은 보통 제 3정규형으로 모델링, 차원 테이블들은 보통 비정규화된 제 2정규형으로 모델링\n  장점 : 스노우 플레이크에 비해 이해하기 쉽고, 쿼리 작성 용이, 조인 테이블 수 적음\n  단점 : 차원 테이블들의 비정규화에 따른 데이터 중복으로 데이터를 적재할 때 많은 시간 소요\n  스노우 플레이크 스키마   차원 테이블을 제 3정규형으로 단점 : 조인 테이블 개수 증가, 쿼리 작성 난이도 상승  ODS DW 비교    구분 ODS DW     데이터 내용 현재, 최신 데이터 오래된 상세 데이터, 현재 상세 데이터, 요약, 2차로 가공된 고도로 요약된 데이터   데이터 양 비교적 소규모 데이터 대규모 데이터   데이터 갱신 지속적 갱신, 현재DB 반영 데이터 축적 보관   기술적 요소 처리의 모든 기능을 사용하도록 설계 단순한 적재와 접근 중심    \nCDC  DB내 데이터 변경을 식별해 필요한 후속처리를 자동화 RT, NRT 데이터 통합을 기반 스토리지 하드웨어 계층에서부터 애플리케이션 계층에 이르기까지 다양한 계층에서 다양한 기술 단일 정보 내 다수의 CDC 매커니즘  CDC 구현 기법  Time Stamp on Rows   테이블 내 마지막 변경 시점을 기록하는 타임스탬프 칼럼을 두고 마지막 변경 타임스탬프 값보다 더 최근의 타임스탬프 값을 갖는 레코드를 변경된 것으로 식별  Version Numbers on Rows   레코드의 버전을 기록하는 칼럼을 두고 더 높은 버전을 보유한 레코드를 변경된 거승로 식별  Status on Rows   타임스탬프 및 넘버 기법에 대한 보완, 변경의 여부를 True,False 로 변경 여부 판단  Time/Version/Status   위의 세가지 특성 모두 활용, 정교한 쿼리 생성에 활용  Triggers on Tables   트리커를 활용해 사전에 등록된 다수 대상 시스템에 변경 데이터를 배포하는 형태 관리 복잡도 증가, 관리 어려움, 확장성 감소 유발 등 시스템 유지보수성을 저하 -\u003e 사용에 주의  Event Programming   변경 식별 기능을 애플리케이션에 구현, 애플리케이션 개발 부담, 복잡도 증가  Log Scanner on Database   DBMS에서 제공하는 트랜잭션 로그에 대한 스캐닝 및 변경에 대한 해석을 통해 구현 작업 규모가 증가될 수 있음 장점 : db와 애플리케이션 영향도 최소화, 식별 지연시간, 트랜잭션 무결성 영향도 최소화, 스키마 변경 불필요  CDC 구현 방식 push : 소스에서 변경을 식별하고 대상 시스템에 대한 변경 데이터를 적재 pull : 대상 시스템에서 데이터 소스를 정기적으로 살피고 필요시 데이터 다운\n\nEAI 비즈니스 프로세스를 중심으로 기업 내 각종 애플리케이션 간의 상호연동이 가능하도록 함\n 데이터 연계 -\u003e 상호 융화 내지 동기화 애플리케이션을 프로세스 및 메시지 차원에서 통합 관리 EAI를 통해 비즈니스 프로세스를 자동화하고 실시간으로 통합 연계 RT, NRT 처리 중심  데이터 연계 방식 기존 : POINT TO POINT\n 정보 시스템 개발 시 정보 시스템들 간의 데이터를 연계, 복잡함 데이터 통합과 표준화 불가능, 유지 보수성 저하, 관리 비용 상승 N(N-1)/2개의 연결  EAI의 연계방식 : Hub and Spoke\n 가운데에 허브 역할을 하는 브로커를 두고 연결 노드들의 데이터 연계 요구를 중계함으로써 구조를 단순화 각 연결의 대상이 되는 노드들은 Spoke  EAI 구성 요소 어댑터 : 각 정보 시스템과 EAI허브 간의 연결성 확보 버스 : 어댑터를 매개로 연결된 각 정보 시스템들 간의 데이터 연동 경로 브로커 : 데이터 연동 규칙 통제 트랜스포머 : 데이터 형식 변환을 담당\nEAI 구현 유형  Mediation   EAI 엔진이 중개자, 특정 정보 시스템 내의 데이터 생성, 갱신, 신규 트랜잭션 완료 등 이벤트 발생을 식별, 미리 약속된 정보 시스템에 해당 내용(데이터) 전달 Publish/subscribe Model  Federation   EAI 엔진이 외부 정보 시스템으로부터 데이터 요청들을 일괄적으로 수령해 전달 Request/reply Model  EAI 활용 효과  정보 시스템 개발 및 유지 보수비용 절감 기업 정보 시스템의 지속적 발전 기반 확보 협력사, 고객, 파트너와의 상호 협력 프로세스 연계 웹 서비스, 인터넷 비즈니스를 위한 기본 토대 확립 데이터 동기화, 데이터 표준화 기반 제공  EAI, ESB    구분 EAI ESB     기능 Hub를 이용해 비즈니스 로직을 중심으로 애플리케이션을 통합, 연계 BUS를 이용해 서비스 중심으로 시스템을 유기적으로 연계   통합 관점 애플리케이션 프로세스   로직연동 개별 애플리케이션에서 수행 ESB에서 수행   아키텍처 단일 접점인 허브시스템을 이용한 중앙집중식 연결구조 버스 형태의 느슨하고 유연한 연결구조    ","description":"","tags":null,"title":"ADP 공부하기 5","uri":"/posts/certificate/2020-01-27-adp_study5/"},{"categories":["Certificate"],"content":"비정형 데이터마이닝 텍스트 마이닝  입력된 텍스트를 구조화해 그 데이터에서 패턴을 도출 후, 결과를 평가 및 해석 다양한 포맷의 문서로부터 텍스트를 추출 자연어로 구성된 비정형 텍스트 데이터 속에서 정보나 관계를 발견  텍스트마이닝 기능 : 문서 요약, 분류, 군집, 특성 추출\nCorpus  데이터의 정제 통합 선택 변환의 과정을 거친 구조화된 단계 ‘tm’패키지에서 문서를 관리하는 기본 구조, 문서들의 집합  tm패키지 함수  VCorpus() : 문서를 Corpus class로 만들어줌. 결과는 r메모리에만 PCorpus() : 문서를 Corpus class로 만들어 R 외부 db나 파일로 관리 DirSource(), VectorSource(), DataframeSource() : 디렉토리, 벡터, 데이터 프레임으로부터 코퍼스 생성을 위한 소스를 만들어 줌 tm_map(x,FUN) : x데이터에 대해 FUN을 적용  FUN에 들어가는 함수\nas.PlainTextDocument : XML문서를 text로 전환 stripWhitespace : space 제거 removewords, stopwords(“english”) : 띄어쓰기, 시제 표준화 DocumentTermMatrix : 코퍼스로부터 문서별 특정 문자 빈도표 TermDocumentMatrix : 코퍼스로부터 단어별 문서의 빈도표\nTerm-Document Matrix 문서를 plain text로 전환, 공백 제거, lowercase변환, 불용어(stopword)처리, 어간추출(stemming) 등의 작업을 수행하고 문서번호와 단어 간 사용여부 또는 빈도수를 이용해 matrix만듬\nDirectory 텍스트마이닝 분석 시 사용하고자 하는 단어들의 집합\n감성분석 문장에서 사용된 단어의 긍정과 부정 여부에 따라 전체 문장의 긍정/부정 판별\n한글처리 KoNLP 등 사용, rJava패키지, JRE프로그램 설치해야함 명사를 추출할 때는 extractNoun(“문장”) 함수\n워드 클라우드 단어들을 크기, 색 등으로 나타내어 구름 등과 같은 형태\n ## 사회연결망 분석\rSNA  개인과 집단들 간의 관계를 노드,링크로 모델링 제이콥 마리노(개념), 바르네스(1954에 처음)  SNA 분류  집합론적 방법  객체들 간의 관계를 관계 쌍으로 표현   그래프 이론을 이용한 방법  객체를 점으로 표현, 연결은 선으로 표현   행렬  관계가 존재하면 1, 그렇지 않으면 0 행과 열이 같은 개체가 배열(1원), 다른 개체(2원) 준연결망 : 고객-상품 행렬에서 사람들 사이에 상호작용이 없어도 관계를 인위적으로 설정 고객 트랜잭션(고객이 동일한 상품을 1개 이상 구매하면 직접적인 상호작용이 있다고 표현) 상품을 동시에 구매 -\u003e 서로 상호관계에 있음     \r   연결 정도 중심성 - 한점에 직접적으로 연결된 점들의 합- 한점에 얼마나 많은 다른 점들이 관계를 맺고 있는지를 기준으로 중심에 위치하는 정도를 계량화-연결된 노드 수가 많을 수록 연결정도 중심성이 높아짐     근접 중심성 - 한점에 직접적으로 연결된 점들의 합- 근접 중심성이 높을 수록 네트워크의 중앙에 위치   매개 중심성 - 네트워크 내 한 점이 담당하는 매개자 혹은 중개자 역할- 한 노드가 연결망 내의 다른 노드 사이의 최다 연결 경로 위에 위치하면 할수록 그 노드의 매개 중심성이 높음   위세 중심성 - 자신의 연결정도 중심성으로부터 발생하는 영향력과 자신과 연결된 타인의 영향력을 합함- 위세가 높은 노드들과 관계가 많을수록 자신의 위세도 높아짐- 보나시치 권력지수 : 연결된 노드의 중요성에 가중치를 둬 노드의 중심성 측정     \r### SNA적용\r분석용 솔루션 : KXEN, SAS, XARACT,Indiro, Onalytica, Unicet, Inflow, Pagek 등\rMapReduce(분산 처리 기술)을 활용, Giraph(하둡 기반 그래프 프로세싱 프레임워크)\rRHadoop, RHIPE : R과 하둡 연동\rSNA단계  그래프 생성 그래프를 목적에 따라 가공, 분석 커뮤니티를 탐지하고 각 노드의 역할을 정의해 어떠한 ROLE로 다른 객체들에게 영향력을 더 효율적으로 줄 수 있는지를 정의 위 결과를 데이터화하여 다른 데이터마이닝 기법과 연계하는 단계   데이터화는 SNA를 통해 얻어진 커뮤니티의 프로파일을 해당 그룹의 연령,성별 등과 같은 고객 프로파일 평균값으로 산출해 그룹에 속할 개별 고객 속성에 그룹 넘버와 ROLE을 결합해 추가하는 단계임  R에서의 SNA 네트워크 레벨 통계량 degree, shortest paths, reachability, density, reciprocity, transitivity, triad census\n커뮤니티 수를 측정하는 방법 WALKRAP알고리즘\n 일련의 random walk과정을 통해 커뮤니티를 발견 각 버텍스(그래프 꼭지점)를 하나의 커뮤니티로 취급해 점차 더 큰 그룹을 병합하면서 클러스터링 코드를 실행하면 군집화 개수와 그래프 결과가 나타남  1 2  friend_comm = walktrap.community(m182,step=200,modularity=TRUE) dend = as.dendrogram(friend_comm,use.modularity=TRUE)   Edge Betweenness method\n 그래프에 존재하는 최단거리 중 몇 개가 그 edge를 거쳐가는 지를 이용해 edge-betweenness점수 측정 높은 edge-betweenness점수를 갖는 edge가 클러스터를 분리하는 속성을 가짐  1 2  edge.betweenness.community(m182) plot(as.dendrogram(friend_comm))   활용방안 몇 개의 집단으로 구성되고 집단 간 특성은 무엇이고 해당 집단에서 영향력 있는 고객은 누구이고 시간의 흐름과 고객 상태의 변화에 따라 다음에 누가 영향을 받을지를 기반으로 fraud, churn/acquisition prediction, product recommendation 등에 활용\n","description":"","tags":null,"title":"ADP 공부하기 4","uri":"/posts/certificate/2020-01-25-adp_study4/"},{"categories":["Certificate"],"content":"정형 데이터마이닝 1. 데이터 마이닝 개요 변수 선택 filter method\n 각각의 변수들에 대해 통계적 점수 부여, 점수로 순위를 매김 chi squared, information gain, correlatioin 등  wrapper method\n 변수 간 상호 작용 감지, 변수의 일부만 모델링에 사용 후 결과 평가 -\u003e 반복 recursive feature elimination algorithm  embedded method\n filter method와 wrapper method 결합, 과적합을 줄이기 위해 내부적 규제 ridge, lasso, elastic net wrapper는 학습을 마친 후 비교, embedded는 학습 과정에서 최적화된 변수 선택  머신러닝  지도학습, 비지도학습, 강화학습 지도학습 : knn, 선형회귀, svm, 의사결정 나무, 신경망 비지도학습 : 군집분석, pca, 연관분석, 사회연결망 분석, 텍스트 마이닝  딥러닝 DNN : 인공신경망(ANN)에서 은닉층이 여러개 - 암 진단 시스템, 주가지수예측, 환율예측, 기업신용평가 CNN : 다계층 퍼셉트론, 여러 개의 합성곱 계층과 인공 신경망 계층으로 이루어짐 - 자율 주행 자동차, 멀티미디어 식별 RNN : 시간의 흐름에 따른 따른 데이터 학습, 기준 시점과 다음 시점의 네트워크 연결 - 음성 인식, 번역, 의미 판단, 이미지 캡션 생성, 자연어 처리\n딥러닝 지원 라이브러리 파이썬 theano\n keras : 오픈 소스 신경망 라이브러리, dnn의 빠른 실험 lasagne : theano의 복잡성을 추상화하고 보다 편리한 인터페이스  chainer : “define-by-run\"모델을 기반으로 NLP에서 많이 이용 TENSORFLOW : 구글에서 만든 오픈소스 패키지, 플로우 그래프 CXXNET : MShadow 라이브러리, 멀티GPU지원\nC++  caffe : 이미지 분석에 특화 mxnet : 파이썬도 지원, 대규모 데이터셋에 효과적, 아마존 웹 서비스에서 딥러닝 프레임워크 지원  JAVA deepLearning4j : 비즈니스용 딥러닝 플랫폼\nR darch, deepnet 2. 분류 분석 나이브 베이즈 $$posterior = \\frac{prior \\times likelihood}{evidence}$$\n 문서를 여러 범주(스팸,스포츠) 중 하나로 판단 다른 속성들이 독립적 : 클래스 조건 독립성  K-NN 유클리디안(대표적), 맨하탄, 민코우스키 거리 사용 유클리디안 : 두 점 거리 제곱합의 제곱근 맨하탄 : 절대값\n 장점 : 사용 간단, 기준을 몰라도 데이터 분류 가능, 데이터 처리가 용이 단점 : k값 결정이 어렵, 비수치 데이터일 경우 유사도 정의 어렵, 이상치가 있으면 큰 영향을 받음  SVM 새로운 데이터가 어떤 범주에 속하는지 판단하는 비확률적 이진 선형 분류모델을 생성\n 가장 큰 폭을 가진 경계를 찾음  초평면 : 각 그룹을 구분하는 분류자 서포트 벡터 : 초평면에 가장 가까이에 붙어있는 최전방 데이터 마진 : 포여면과 서포트 벡터 사이의 수직거리\n마진을 최대화하는 초평면(MMH)을 찾아 수행\n 비선형 분류에서는 커널 트릭 사용 장점 : 분류, 예측 모두 가능, 과적합 정도 적음, 정확도가 높다, 저차원 고차원 상관없이 잘 작동 단점 : 전처리와 매개변수 설정에 따라 정확도가 달라짐, 해석이 어려움, 속도가 느리고, 할당량이 크다.   군집분석 resampling k-fold cross validation k-1개 집단으로 학습, 1개로 성능 테스트 -\u003e k번 반복-\u003e mse평균 bootstrap 표본에 대해 다시 재표본을 여러 번 추출, 단순랜덤 복원추출법 사용\n 63.2%만 선택, 나머지 OOB 데이터(OOB-error: 실제값과 예측값 사이 오차)  군집화 기법 밀도기반 군집분석 어느 점을 기준으로 반경 내에 최소 개수만큼의 데이터들은 가질 수 있도록 밀도에 의해 군집을 형성\n DBSCAN : 밀도 한계점에 따라 군집 형성(대표적) OPTICS : 군집화 구조 식별을 위해 부가적 순서를 생성 DENCLUE : 밀도 분포함수에 기초  격자기반 데이터가 존재하는 공간을 격자구조로 이루어진 유한개의 셀들로 양자화하여 셀을 이용해 군집화, 셀의 수에만 의존\n STING : 결자 셀에 저장된 통계정보를 탐색 Wavecluster : Wavelet변환 기법 사용 CLIQUE : 고차원 데이터 공간의 군집화를 위한 격자 및 밀도기반  군집 분석의 타당성 지표 Silhouette(실루엣)\n 군집 내의 응집도와 군집 간 분리도를 이용한 지표 군집 내 거리가 짧고 군집 간 거리가 멀수록 값이 커짐  dunn index\n 군집 간 거리는 멀고, 군집 내 분산은 작을수록 군집화가 잘 이루어짐 dunn index가 클수록 군집이 잘 형성됨  BMU  SOM에서는 각 학습 단계마다 입력층으로부터 하나의 표본 벡터를 임의로 선택하고 경쟁층의 프로토타입 벡터와의 거리 계산 그 후 표본 벡터와 거리가 가장 가까운 프로토타입 벡터ㄹ르 선택 BMU는 선택된 프로토타입 벡터를 나타내는 용어  ","description":"","tags":null,"title":"ADP 공부하기 3","uri":"/posts/certificate/2020-01-24-adp_study3/"},{"categories":["Certificate"],"content":"2. 회귀분석 정규화 선형회귀 선형회귀 계수에 대한 제약조건 추가, 과적합을 막음 계수의 크기를 제한하는 방법으로 제약조건 추가\n  Ridge Regression\n 가중치의 제곱합을 최소화 모든 원소가 0에 가까워짐, L2 규제    Lasso Regression\n 가중치 절대값의 합을 최소화 라쏘에서는 릿지와 다르게 가중치가 0이 되게 함, L1 규제    Elastic Net\n 릿지와 라쏘를 절충 두 개의 모수     GLM 종속변수를 적절한 함수로 변화시켜 독립변수를 선형 결합으로 모형화\n 랜덤성분(반응변수), 체계적 성분(선형식), 연결함수(랜덤과 체계적 연결)     랜덤성분 연결함수 체계적 성분 model     Normal identity(항등) 연속형 regression   Normal identity(항등) 범주형 ANOVA   Normal identity(항등) Mixed regression with Indicator Anova   Binomial Logit Mixed Logistic regression   Poisson Log Mixed log-linear   Multinomial Generalized Logit Mixed Multinomial response     회귀분석의 영향력 진단 적합된 회귀모형의 안전성을 평가, 많은 변동이 있다면 안정성이 약함\n 회귀직선의 기울기에 영향을 크게 주는 점을 영향점이라고 함  cook’s distance full model에서 i번째 관측치를 포함해 계산한 적합치와 i번째 관측치를 포함하지 않고 계산한 적합치 사이 거리 DFBETAS 이 값이 커지면 i번째 관측치가 영향치 혹은 이상치일 가능성이 높다. DFFITS i번째 관측치 제외 시 종속변수 예측치의 변화정도를 측정 Leverage H 관측치가 다른 관측치 집단으로부터 떨어진 정도\n 2 * (p+1)/n 보다 크면 영향치이거나 이상치라고 봄 $$H = X(X^`X)^{-1}X$$   더빈 왓슨  오차항이 독립성을 만족하는지를 검정 2에 가까울수록 오차항의 자기상관이 없음을 의미 0에 가까울수록 양의 상관관계가 있고 4에 가까을수록 음의 상관관계 -» 상관관계가 있어 회귀식이 부적합함을 의미  변수 선택의 기준으로 사용되는 통계량 수정된 결정계수 : 결정계수의 단점 보완 Mallow’s Cp\n 최소자승법을 사용해 회귀모형의 적합성 평가 일반적으로 cp값이 작고 p+상수(변수개수+상수)에 가까운 모형을 선택     CP값 해석     P(변수의 개수)와 비슷한 경우 bias가 작고 우수한 모델   P(변수의 개수)보다 큰 경우 bias가 크고 추가적인 변수가 필요한 모델   P(변수의 개수)보다 작은 경우 variance의 증가폭보다 bias의 감소폭이 더 크고 필요 없는 변수가 존재하는 모델     변수변환 정규성, 선형성, 등분산성을 만족하지 못하는 경우 변수를 변환함으로써 교정\n 로그, 지수 변환 더미변수 생성 box-cox 변환  정규성을 만족하도록 반응 변수를 다음과 같이 변환 $$ g_\\lambda(y) = \\begin{cases} y^\\lambda, \u0026 \\lambda \\ne 0 \\\nlogy, \u0026 \\lambda = 0 \\end{cases} $$ $\\lambda$는 우도함수를 최대화 시키는 조건으로 계산    ","description":"","tags":null,"title":"ADP 공부하기 2","uri":"/posts/certificate/2020-01-23-adp_study_2/"},{"categories":["Certificate"],"content":"내가 공부한 것을 요약하는 위주이기 때문에 아는 내용은 가볍게 넘어감.\n데이터 분석 1. 통계분석 연속형 확률분포  t분포 평균의 동일성 검정, 데이터가 연속형일때, 자유도 30미만 카이제곱 분포 두 집단의 동질성 검정,자유도 (r-1)(c-1) F분포 등분산성 검정, 자유도가 두 개고 커질수록 정규분포에 가까움  r을 활용한 one t-검정 t검정은 모두 모집단이 정규성을 만족한다고 가정\n1 2  shapiro.test(data) t.test(data, alternaive=\"two.sided\",mu=200)   p-value가 0.05보다 높으면 정규분포를 따르는 것임 -\u003e t-test 수행 가능\npaired sample t-test(대응표본) 한 모집단에 대해 두 가지 처리를 했을 때 두 가지의 평균의 차이를 검정 개체별로 짝지어진 관측값 사의 차이로 검정\n1  t.test(data$before, data$after , alternaive=\"less\",paired=\"True\")   m 변수가 따로 있지만 차이가 0인지 검정하기 때문에 따로 필요없음\npaired sample t-test(독립표본) 두 개의 독립된 모집단 검정, 모분산이 동일해야(등분산 검정 선행)\n1 2  var.test(formula , data , alternaive=\"two.sided\") t.test(data$before, data$after , alternaive=\"less\",var.equal=\"True\")    분산분석 one-way anova   하나의 범주형 변수의 영향을 알아보기 위함\n  표본의 수가 같지 않아도 되고 모집단의 수는 제한이 없다.\n  정규성, 등분산성 가정\n  사후 검정 분산분석의 결과 기각되어 평균의 차이가 있음이 통계적으로 증명되었을 경우, 어떤 집단들에 대해 평균의 차이가 존재하는지 알아보기 위함 Duncan의 Multiple Range Test(MRT), Fisher의 최소유의차(LSD), Tukey의 HSD, Scheffe의 방법이 있다.\n  r에서의 일원배치 분산분석  그룹을 구분하는 기준이 되는 변수는 반드시 factor형이어야 함.  1 2 3  result = aov(formula, data) summary(result) TukeyHSD(result,conf.level=0.95)   diff a-b로 연결되어 있을 때 양수면 a가 유의하게 큰 값을 가짐\ntwo-way anova  두 개의 범주형 변수의 영향을 알아봄 교호작용에 대한 검증이 진행되어야 함 모형 $$y_{ijk} = \\mu + \\alpha_i + \\beta_j + (\\alpha\\beta)_{ij} + \\epsilon_{ijk}$$     요인 제곱합 자유도 평균제곱합 F     요인a $$SS_a$$ $$I-1$$ $$MS_a = \\frac{SSA}{I-1}$$ $$F_a = \\frac{MSA}{MSE}$$   요인b $$SS_b$$ $$J-1$$ $$MS_b = \\frac{SSB}{J-1}$$ $$F_b = \\frac{MSB}{MSE}$$   상호 작용 $$SS_{a \\times b}$$ $$(I-1)(J-1)$$ $$MS_{ab} = \\frac{SSAB}{(I-1)(J-1)}$$ $$F_{ab} = \\frac{MSAB}{MSE}$$   오차 $$SSE$$ $$IJ(n-1)$$ $$MSE = \\frac{SSA}{IJ(n-1)}$$    전체 $$SST$$ $$IJn-1$$      귀무가설(H0)\n 변수에 따른 종속 변수의 값에는 차이가 없다. A, B변수의 상호작용 효과가 없다. 대립가설(H1) 변수에 따른 종속 변수의 값에는 차이가 있다.(a가 모두 0이라 할 수 없다) a와 b변수의 상호작용 효과가 있다.  교호작용 두 가지 이상의 특정 변수 조합에서 일어나는 효과 (상관관계가 존재할 경우 교호작용이 있다는 의미)\n 교호작용이 있다면 검정이 무의미하다   실험계획법  개념 시스템이나 프로세스의 결과에 영향을 미치는 인자를 도출, 측정 데이터를 실험적으로 설계 최소 실험 횟수로 최대의 정보를 얻는 것 목적 분산분석 및 검정과 추정 : 유의미한 영향, 요인의 영향 파악 최적 반응 조건의 결정 : 어떤 인자를 사용해야 가장 원하는 결과값을 얻을지 파악 오차항 추정의 문제 : 이해하기 어렵던 오차와 그 변동에 관한 정도  실험계획법의 원리  랜덤화의 원리, 반복의 원리, 블록화의 원리, 직교화, 교락 교락 : 2개 이상의 효과를 구별할 수 없도록 계획적으로 조합 블록 : 실험 단위가 균일할 수 있도록 단위를 모은 것 반복 : 인자들의 동일한 수준 조합에서 다회의 실험을 진행  실험계획법의 종류  요인배치법  모든 인자간의 수준 조합에서 실험이 이루어지는 완전랜덤화방법 교호효과를 포함한 모든 요인효과를 추정할 수 있다. $K^n$형 요인실험 : 인자 수가 n이고, 수준 수가 k인 실험계획법   분할법  몇 단계로 분할하여 각 단계별로 완전 랜덤하게 실험 순서를 결정 랜덤화 어려운 것을 1차 단위, 쉬운 것을 후 단위로 배치   교락법  검출할 필요가 없는 교호작용을 다른 요인과 교락하도록 배치하는 방법 실험 전체를 몇 개의 블록으로 나누어 배치, 실험 횟수를 줄일 수 있다. 교호작용을 교락시키기 때문에 주효과가 높게 추정   난괴법  실험 단위를 몇 개의 반복으로 나누어 배치 a가 모수인자. b가 변량인자일 때, a의 수준수가 1, b의 수준수가 m인 반복이 없는 이원배치 분산분석방법이다.     교차분석 범주형 자료인 두 변수 간의 관계\n 적합도 검정  1  chisq.test(data,p=c(0.2,0.8))    독립성 검정 동질성 검정 독립성 검정과 같은 방법으로 진행, 가설만 다름   중심 극한 정리 n이 커질수록(30이상) 표본평균의 분포가 정규분포에 가까워짐\n","description":"","tags":null,"title":"ADP 공부하기 1","uri":"/posts/certificate/2020-01-23-adp_study_1/"}]
